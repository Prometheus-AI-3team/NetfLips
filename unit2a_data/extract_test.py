import os
os.environ["CUDA_VISIBLE_DEVICES"] = "1" # GPU ì„¤ì •
import sys
import torch
import librosa
import numpy as np
from omegaconf import OmegaConf

# ê²½ë¡œ ì„¤ì •
standard_paths = [p for p in sys.path if "site-packages" in p or "lib/python" in p]
for p in standard_paths:
    if p in sys.path:
        sys.path.remove(p)
        sys.path.insert(0, p)

av2av_root = "/home/2022113135/av2av"
fairseq_root = "/home/2022113135/av2av/fairseq"
task_dir = "/home/2022113135/av2av/av2unit"
hubert_pretrain_path = "/home/2022113135/av2av/av2unit/avhubert"

# ì‹œìŠ¤í…œ ê²½ë¡œì— ì¶”ê°€
for p in [av2av_root, fairseq_root, task_dir, hubert_pretrain_path]:
    if p not in sys.path:
        sys.path.insert(0, p)
        
from fairseq import tasks

# íƒœìŠ¤í¬ ë³„ì¹­ ë“±ë¡
try:
    from hubert_pretraining import AVHubertPretrainingTask, AVHubertPretrainingConfig
    @tasks.register_task("av_hubert_unit_pretraining", dataclass=AVHubertPretrainingConfig)
    class AVHubertUnitPretrainingTaskAlias(AVHubertPretrainingTask):
        pass

    print("âœ… Successfully registered 'av_hubert_unit_pretraining' using class inheritance!")
except Exception as e:
    print(f"âš ï¸ Registration Bypass: {e}")

from fairseq import checkpoint_utils

CHECKPOINT_PATH = "/home/2022113135/av2av/checkpoints/mavhubert_large_noise.pt"
LIST_FILE = "/home/2022113135/av2av/selected_files.txt"
OUT_DIR = "/home/2022113135/datasets/zeroth_units"
os.makedirs(OUT_DIR, exist_ok=True)

def load_mavhubert():
    print(f"Loading checkpoint from: {CHECKPOINT_PATH}")
    
    # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
    state = checkpoint_utils.load_checkpoint_to_cpu(CHECKPOINT_PATH)
    cfg = state["cfg"]
    
    # OmegaConf ì—„ê²© ëª¨ë“œ í•´ì œ
    from omegaconf import OmegaConf
    OmegaConf.set_struct(cfg.model, False)
    
    # íƒœìŠ¤í¬ ìƒì„±
    task_dict = OmegaConf.to_container(cfg.task, resolve=True)

    task_dict["labels"] = [] 
    task_dict["label_dir"] = "/tmp" # ì•„ë¬´ ì˜ë¯¸ ì—†ëŠ” ê²½ë¡œë¡œ ì„¤ì •
    
    for k in ["pretrained_checkpoint", "noise_wav", "noise_prob", "noise_snr", "noise_num"]:
        task_dict.pop(k, None)
    task_obj = tasks.setup_task(OmegaConf.create(task_dict))
    
    # í´ë˜ìŠ¤ ë ˆë²¨ì—ì„œ dictionaries í”„ë¡œí¼í‹°ë¥¼ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ê³ ì •
    type(task_obj).dictionaries = property(lambda self: [])
    
    # state ë‚´ë¶€ì— ì§ì ‘ ì£¼ì…
    if hasattr(task_obj, 'state'):
        task_obj.state.dictionaries = []
    
    # ëª¨ë¸ ì„¤ì • ìˆ˜ì •
    model_dict = OmegaConf.to_container(cfg.model, resolve=True)
    model_dict.update({"_name": "av_hubert", "final_dim": 256, "audio_embed_dim": 104})
    
    # Fairseqì˜ ìµœì‹  Transformer/Wav2Vec2 ì½”ë“œê°€ ìš”êµ¬í•˜ëŠ” ëª¨ë“  ê¸°ë³¸ ì„¤ì •ê°’
    missing_defaults = {
        # ì°¨ì› ë¶ˆì¼ì¹˜ í•´ê²°
        "audio_embed_dim": 104, 
        "encoder_embed_dim": 1024,    
        "conv_pos": 128,
        "conv_pos_groups": 16,
        
        # ìœ ì‚¬ë„ ê´€ë ¨
        "sim_type": "cosine",
        "logit_temp": 0.1,
        "target_glu": False,
        "final_dim": 256,
        "untie_final_proj": True,
        
        # Masking ê´€ë ¨ 
        "mask_selection": "static",   
        "mask_other": 0.0,
        "mask_length": 10,
        "mask_prob": 0.8,
        "no_mask_overlap": False,
        "mask_min_space": 1,
        "mask_channel_selection": "static",
        "mask_channel_other": 0.0,
        "mask_channel_length": 10,
        "mask_channel_prob": 0.0,
        "no_mask_channel_overlap": False,
        "mask_channel_min_space": 1,
        
        # Transformer & Activation
        "activation_fn": "gelu",
        "layer_type": "transformer", 
        "layerdrop": 0.0,
        "checkpoint_activations": False,
        "offload_activations": False,
        
        # Convolution & ResNet
        "required_seq_len_multiple": 1,
        "conv_pos": 128,
        "conv_pos_groups": 16,   
        "resnet_relu_type": "prelu",
        "resnet_weights": None,
        
        # ê¸°íƒ€ í•„ìˆ˜ íŒŒë¼ë¯¸í„°
        "sub_encoder_layers": model_dict.get("encoder_layers", 24),
        "layer_norm_first": True,
        "feature_grad_mult": 1.0,
        "encoder_layerdrop": 0.0,
        "dropout_input": 0.0,
        "dropout_features": 0.0,
        "attention_dropout": 0.0,
        "activation_dropout": 0.0,
        "dropout": 0.0,
        "no_seed_provided": False, 
        "cond_on_norm": False,
        "reproducible": False,
        "encoder_layers_B": 0,
    }
    
    for k, v in missing_defaults.items():
        if k not in model_dict:
            model_dict[k] = v
    
    from hubert import AVHubertModel
    model = AVHubertModel.build_model(OmegaConf.create(model_dict), task_obj)
    
    # íŠ¹ì§• ì¶”ì¶œ í›„ [Batch, Time, Dim] -> [Batch, Time, 1024]ë¡œ ë°”ê¿”ì£¼ëŠ” ì—­í• 
    if hasattr(model.feature_extractor_audio, 'proj'):
        print("ğŸ”§ Patching audio feature extractor projection layer...")
    
    # ì²´í¬í¬ì¸íŠ¸ ë°˜ì˜ : 256ì°¨ì› ì„ë² ë”© ë ˆì´ì–´ ê°•ì œ ìƒì„±
    model.final_proj = torch.nn.Linear(1024, 256)
    
    print("--- Loading Weights & Injecting Codebook ---")
    ckpt_state = state["model"]
    model_state = model.state_dict()
    new_state_dict = {}
    
    model.unit_codebook = None
    model.label_predictor_weight = None

    for k, v in ckpt_state.items():
        # ì¼ë°˜ ë ˆì´ì–´ ë§¤í•‘
        if k in model_state and v.shape == model_state[k].shape:
            new_state_dict[k] = v
        
        # 256ì°¨ì› ì¶œë ¥ ë ˆì´ì–´ ì°¾ê¸°
        if "final_proj" in k or "label_predictor" in k:
            if v.shape == torch.Size([256, 1024]):
                new_state_dict["final_proj.weight"] = v
                print(f"ğŸ¯ Mapped {k} -> final_proj.weight")
            elif v.shape == torch.Size([256]):
                new_state_dict["final_proj.bias"] = v
                print(f"ğŸ¯ Mapped {k} -> final_proj.bias")

        # ìœ ë‹› ì½”ë“œë¶ ì°¾ê¸° ([2008, 256] ëª¨ì–‘)
        if v.shape == torch.Size([2008, 256]):
            model.unit_codebook = v.cuda() # GPUë¡œ ë¯¸ë¦¬ ì „ì†¡
            print(f"ğŸ”¥ Found Codebook: {k} (Size: 2008 units)")
        
        # final_projê°€ ì—†ì„ ë•Œë¥¼ ëŒ€ë¹„í•´ ê°€ì¤‘ì¹˜ ë³´ê´€
        if "label_predictor.weight" in k or "final_proj.weight" in k:
            if v.shape[0] == 256:
                model.label_predictor_weight = v.cuda()

    model.load_state_dict(new_state_dict, strict=False)
    
    if model.unit_codebook is None:
        raise ValueError("âŒ Critical: Could not find [2008, 256] codebook in checkpoint!")

    return model.cuda().eval()

print("\n--- Step 1: Loading Model ---")
model = load_mavhubert()

print("\n--- Step 2: Testing ---")
with open(LIST_FILE, "r") as f:
    all_files = [line.strip() for line in f.readlines()]

print("\n--- Step 3: Extracting Units (Audio-Only Mode) ---")
for i, f in enumerate(all_files):
    try:
        # --- ì „ì²˜ë¦¬ ê°•í™” ---
        y, _ = librosa.load(f, sr=16000)
        y = librosa.util.normalize(y) # ì „ì²´ ë³¼ë¥¨ ìµœì í™”
        y, _ = librosa.effects.trim(y, top_db=20) 
        y = librosa.effects.preemphasis(y, coef=0.98) # ê³ ì£¼íŒŒ ë” ê°•í•˜ê²Œ ê°•ì¡°
        
        # --- ë©œ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ í•´ìƒë„ ì¡°ì • ---
        mel = librosa.feature.melspectrogram(
            y=y, sr=16000, n_mels=104, 
            n_fft=2048, hop_length=640, win_length=1280 # FFT ì°½ì„ í‚¤ì›Œ í•´ìƒë„ í™•ë³´
        )
        log_mel = librosa.power_to_db(mel)
        
        # Instance Normalization (ê°•í™”ëœ ë²„ì „)
        log_mel = (log_mel - np.mean(log_mel)) / (np.std(log_mel) + 1e-6)
        
        mel_input = torch.from_numpy(log_mel).float().cuda().unsqueeze(0)
        x = mel_input.transpose(1, 2)

        with torch.no_grad():
            res_x = model.feature_extractor_audio.proj(x)            
            x_in = res_x.transpose(0, 1)
            
            # ë ˆì´ì–´ ì•™ìƒë¸” (4, 6, 8, 12ì¸µ - ê³ ì°¨ì› ì •ë³´ ì‚´ì§ ì¶”ê°€)
            layer_outputs = []
            target_layers = [4, 6, 8, 12]
            for idx, layer in enumerate(model.encoder.layers):
                x_in, _ = layer(x_in, self_attn_padding_mask=None)
                if idx + 1 in target_layers:
                    layer_outputs.append(x_in.transpose(0, 1))
                if idx + 1 == 12: break
            
            inter_x = torch.mean(torch.stack(layer_outputs), dim=0)
            
            # Embedding & Linear Projection
            if hasattr(model, 'final_proj'):
                emb = model.final_proj(inter_x) 
            else:
                emb = torch.nn.functional.linear(inter_x, model.label_predictor_weight)
                
            # ì„ë² ë”© í™”ì´íŠ¸ë‹: ë¶„í¬ë¥¼ ê°•ì œë¡œ ì‚¬ë°©ìœ¼ë¡œ í¼ì¹¨
            emb = (emb - emb.mean(dim=1, keepdim=True)) / (emb.std(dim=1, keepdim=True) + 1e-6)
            
            emb = torch.nn.functional.normalize(emb, p=2, dim=-1)
            codebook = torch.nn.functional.normalize(model.unit_codebook, p=2, dim=-1)
            
            # ìœ ì‚¬ë„(logits) ê³„ì‚°: [T, 256] @ [256, 2008] -> [T, 2008]
            logits = torch.matmul(emb.squeeze(0), codebook.T)
            
            logits /= 0.1
            
            units = torch.argmax(logits, dim=-1).flatten().cpu().numpy()
            
            # Median Filtering
            from scipy.signal import medfilt
            
            smoothed_units = medfilt(units, kernel_size=3) 
            
            units_tensor = torch.from_numpy(smoothed_units).to(torch.long)
            
            # ì¤‘ê°„ ì§€ì  ê³„ì‚°
            mid = len(units_tensor) // 2
            # ì¤‘ê°„ ì§€ì ë¶€í„° 10ê°œ ì¶œë ¥ (ë²”ìœ„ ì´ˆê³¼ ë°©ì§€ ìœ„í•´ min ì‚¬ìš©)
            mid_pattern = units_tensor[mid : mid + 10].tolist()
            
            unique_units = torch.unique(units_tensor)
          
            print(f"DEBUG: Layers Avg | Unique: {len(unique_units)} | Mid-Pattern: {mid_pattern}")
            
        # ì €ì¥
        save_data = {
            'code': units_tensor,
            'spkr': torch.zeros(256).float(),
            'f0': torch.zeros(len(units_tensor)).float(),
            'dur_prediction': False
        }
        
        save_path = os.path.join(OUT_DIR, os.path.basename(f).replace(".wav", ".pt"))
        torch.save(save_data, save_path)
        if (i + 1) % 100 == 0:
            print(f"[{i+1}/{len(all_files)}] Progressing...")
        
    except Exception as e:
        import traceback
        print(f"[{i+1}/10] âŒ Error: {e}")
        traceback.print_exc()