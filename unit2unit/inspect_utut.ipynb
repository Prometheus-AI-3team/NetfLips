{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a08781b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-18 20:38:44 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
      "/Users/jisu/Desktop/dev/cli/av2av/fairseq/fairseq/checkpoint_utils.py:322: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(f, map_location=torch.device(\"cpu\"))\n",
      "2026-01-18 20:38:45 | INFO | fairseq.tasks.multilingual_denoising | dictionary: 1023 types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model config: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 2, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': './', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 1024, 'batch_size': 128, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': 'mmap', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 1024, 'batch_size_valid': 128, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.1, 'sentence_avg': False, 'update_freq': [8], 'lr': [0.0001], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 1000, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': 50000, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 20, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir='tblog', wandb_project=None, azureml_logging=False, seed=2, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir='./', empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='polynomial_decay', simul_type=None, scoring='bleu', task='utut_pretraining', num_workers=6, skip_invalid_size_inputs_valid_test=True, max_tokens=1024, batch_size=128, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl='mmap', data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=1024, batch_size_valid=128, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=8, distributed_num_procs=8, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=8, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='utut_large', max_epoch=0, max_update=30000, stop_time_hours=0, clip_norm=0.1, sentence_avg=False, update_freq=[8], lr=[0.0001], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, debug_param_names=False, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=1000, keep_interval_updates=1, keep_interval_updates_pattern=50000, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='./', tokens_per_sample=1020, sample_break_mode='eos', replace_length=-1, mask=0.3, mask_random=0.1, insert=0.0, permute=0.0, rotate=0.0, poisson_lambda=10.0, shuffle_instance=False, mask_length='span-poisson', permute_sentences=1.0, shorten_method='truncate', shorten_data_split_list='train', multilang_sampling_alpha=0.7, add_lang_token=True, langs='en,es,fr,it,pt,el,ru,cs,da,de,fi,hr,hu,lt,nl,pl,ro,sk,sl', no_whole_word_mask_langs='', label_smoothing=0.2, report_accuracy=True, ignore_prefix_size=0, force_anneal=None, lr_shrink=0.1, warmup_updates=3000, pad=1, eos=2, unk=3, no_seed_provided=False, no_scale_embedding=False, encoder_embed_path=None, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_layers=12, encoder_attention_heads=16, encoder_normalize_before=True, encoder_learned_pos=False, decoder_embed_path=None, decoder_embed_dim=1024, decoder_ffn_embed_dim=4096, decoder_layers=12, decoder_attention_heads=16, decoder_normalize_before=True, decoder_learned_pos=False, attention_dropout=0.1, relu_dropout=0.0, dropout=0.1, max_target_positions=1024, max_source_positions=1024, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, share_decoder_input_output_embed=True, share_all_embeddings=True, decoder_output_dim=1024, decoder_input_dim=1024, layernorm_embedding=False, activation_fn='gelu', pooler_activation_fn='tanh', pooler_dropout=0.0, _name='mbart_large', activation_dropout=0.0, merge_src_tgt_embed=False, no_token_positional_embeddings=False, adaptive_input=False, no_cross_attention=False, cross_self_attention=False, tie_adaptive_weights=False, checkpoint_activations=False, offload_activations=False, encoder_layers_to_keep=None, decoder_layers_to_keep=None, encoder_layerdrop=0, decoder_layerdrop=0, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0), 'task': {'_name': 'utut_pretraining', 'data': './', 'bpe': None, 'tokens_per_sample': 1020, 'sample_break_mode': 'eos', 'replace_length': -1, 'mask': 0.3, 'mask_random': 0.1, 'insert': 0.0, 'permute': 0.0, 'rotate': 0.0, 'poisson_lambda': 10.0, 'shuffle_instance': 0.0, 'mask_length': 'span-poisson', 'permute_sentences': 1, 'seed': 2, 'shorten_method': 'truncate', 'shorten_data_split_list': 'train', 'max_source_positions': 1024, 'max_target_positions': 1024, 'dataset_impl': 'mmap', 'multilang_sampling_alpha': 0.7, 'add_lang_token': True, 'langs': 'en,es,fr,it,pt,el,ru,cs,da,de,fi,hr,hu,lt,nl,pl,ro,sk,sl', 'no_whole_word_mask_langs': '', 'train_subset': 'train', 'valid_subset': 'valid'}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.2, 'report_accuracy': True, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': [0.9, 0.999], 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0001]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 3000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 30000.0, 'lr': [0.0001]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/jisu/Desktop/dev/cli/av2av\")\n",
    "from unit2unit.inference import load_model as load_unit2unit_model\n",
    "\n",
    "utut_path = \"/Users/jisu/Desktop/dev/cli/av2av/modelckpt/utut_sts_ft.pt\"\n",
    "src_lang = \"en\"\n",
    "tgt_lang = \"es\"\n",
    "use_cuda = False\n",
    "\n",
    "unit2unit_task, unit2unit_generator = load_unit2unit_model(utut_path, src_lang, tgt_lang, use_cuda=use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b0ef1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jisu/Desktop/dev/cli/av2av/fairseq/fairseq/checkpoint_utils.py:322: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(f, map_location=torch.device(\"cpu\"))\n",
      "2026-01-18 20:45:11 | INFO | fairseq.tasks.multilingual_denoising | dictionary: 1023 types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model config: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 2, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': './', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 1024, 'batch_size': 128, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': 'mmap', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 1024, 'batch_size_valid': 128, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.1, 'sentence_avg': False, 'update_freq': [8], 'lr': [0.0001], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 1000, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': 50000, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 20, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir='tblog', wandb_project=None, azureml_logging=False, seed=2, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir='./', empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='polynomial_decay', simul_type=None, scoring='bleu', task='utut_pretraining', num_workers=6, skip_invalid_size_inputs_valid_test=True, max_tokens=1024, batch_size=128, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl='mmap', data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=1024, batch_size_valid=128, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=8, distributed_num_procs=8, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=8, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='utut_large', max_epoch=0, max_update=30000, stop_time_hours=0, clip_norm=0.1, sentence_avg=False, update_freq=[8], lr=[0.0001], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, debug_param_names=False, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=1000, keep_interval_updates=1, keep_interval_updates_pattern=50000, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='./', tokens_per_sample=1020, sample_break_mode='eos', replace_length=-1, mask=0.3, mask_random=0.1, insert=0.0, permute=0.0, rotate=0.0, poisson_lambda=10.0, shuffle_instance=False, mask_length='span-poisson', permute_sentences=1.0, shorten_method='truncate', shorten_data_split_list='train', multilang_sampling_alpha=0.7, add_lang_token=True, langs='en,es,fr,it,pt,el,ru,cs,da,de,fi,hr,hu,lt,nl,pl,ro,sk,sl', no_whole_word_mask_langs='', label_smoothing=0.2, report_accuracy=True, ignore_prefix_size=0, force_anneal=None, lr_shrink=0.1, warmup_updates=3000, pad=1, eos=2, unk=3, no_seed_provided=False, no_scale_embedding=False, encoder_embed_path=None, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_layers=12, encoder_attention_heads=16, encoder_normalize_before=True, encoder_learned_pos=False, decoder_embed_path=None, decoder_embed_dim=1024, decoder_ffn_embed_dim=4096, decoder_layers=12, decoder_attention_heads=16, decoder_normalize_before=True, decoder_learned_pos=False, attention_dropout=0.1, relu_dropout=0.0, dropout=0.1, max_target_positions=1024, max_source_positions=1024, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, share_decoder_input_output_embed=True, share_all_embeddings=True, decoder_output_dim=1024, decoder_input_dim=1024, layernorm_embedding=False, activation_fn='gelu', pooler_activation_fn='tanh', pooler_dropout=0.0, _name='mbart_large', activation_dropout=0.0, merge_src_tgt_embed=False, no_token_positional_embeddings=False, adaptive_input=False, no_cross_attention=False, cross_self_attention=False, tie_adaptive_weights=False, checkpoint_activations=False, offload_activations=False, encoder_layers_to_keep=None, decoder_layers_to_keep=None, encoder_layerdrop=0, decoder_layerdrop=0, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0), 'task': {'_name': 'utut_pretraining', 'data': './', 'bpe': None, 'tokens_per_sample': 1020, 'sample_break_mode': 'eos', 'replace_length': -1, 'mask': 0.3, 'mask_random': 0.1, 'insert': 0.0, 'permute': 0.0, 'rotate': 0.0, 'poisson_lambda': 10.0, 'shuffle_instance': 0.0, 'mask_length': 'span-poisson', 'permute_sentences': 1, 'seed': 2, 'shorten_method': 'truncate', 'shorten_data_split_list': 'train', 'max_source_positions': 1024, 'max_target_positions': 1024, 'dataset_impl': 'mmap', 'multilang_sampling_alpha': 0.7, 'add_lang_token': True, 'langs': 'en,es,fr,it,pt,el,ru,cs,da,de,fi,hr,hu,lt,nl,pl,ro,sk,sl', 'no_whole_word_mask_langs': '', 'train_subset': 'train', 'valid_subset': 'valid'}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.2, 'report_accuracy': True, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': [0.9, 0.999], 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0001]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 3000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 30000.0, 'lr': [0.0001]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}\n",
      "Trainable params: 353,767,424\n",
      "Total params:     353,767,424\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from fairseq import checkpoint_utils, utils\n",
    "from fairseq_cli.generate import get_symbols_to_strip_from_output\n",
    "\n",
    "from unit2unit.task import UTUTPretrainingTask\n",
    "from util import process_units, save_unit\n",
    "\n",
    "models, cfg, task = checkpoint_utils.load_model_ensemble_and_task([utut_path])\n",
    "print(f\"loaded model config: {cfg}\")\n",
    "\n",
    "model = models[0]\n",
    "trainable_params = sum(\n",
    "    p.numel() for p in model.parameters() if p.requires_grad\n",
    ")\n",
    "\n",
    "total_params = sum(\n",
    "    p.numel() for p in model.parameters()\n",
    ")\n",
    "\n",
    "print(f\"Trainable params: {trainable_params:,}\")\n",
    "print(f\"Total params:     {total_params:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d703e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<unit2unit.task.UTUTPretrainingTask at 0x41ec4bee0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unit2unit_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2584f519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceGenerator(\n",
       "  (model): EnsembleModel(\n",
       "    (single_model): BARTModel(\n",
       "      (encoder): TransformerEncoderBase(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (embed_tokens): Embedding(1024, 1024, padding_idx=1)\n",
       "        (embed_positions): SinusoidalPositionalEmbedding()\n",
       "        (layers): ModuleList(\n",
       "          (0-11): 12 x TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): TransformerDecoderBase(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (embed_tokens): Embedding(1024, 1024, padding_idx=1)\n",
       "        (embed_positions): SinusoidalPositionalEmbedding()\n",
       "        (layers): ModuleList(\n",
       "          (0-11): 12 x TransformerDecoderLayerBase(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (output_projection): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "      )\n",
       "      (classification_heads): ModuleDict()\n",
       "    )\n",
       "    (models): ModuleList(\n",
       "      (0): BARTModel(\n",
       "        (encoder): TransformerEncoderBase(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (embed_tokens): Embedding(1024, 1024, padding_idx=1)\n",
       "          (embed_positions): SinusoidalPositionalEmbedding()\n",
       "          (layers): ModuleList(\n",
       "            (0-11): 12 x TransformerEncoderLayerBase(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (dropout_module): FairseqDropout()\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (activation_dropout_module): FairseqDropout()\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (decoder): TransformerDecoderBase(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (embed_tokens): Embedding(1024, 1024, padding_idx=1)\n",
       "          (embed_positions): SinusoidalPositionalEmbedding()\n",
       "          (layers): ModuleList(\n",
       "            (0-11): 12 x TransformerDecoderLayerBase(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (dropout_module): FairseqDropout()\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (activation_dropout_module): FairseqDropout()\n",
       "              (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (encoder_attn): MultiheadAttention(\n",
       "                (dropout_module): FairseqDropout()\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (output_projection): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (classification_heads): ModuleDict()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (search): BeamSearch()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unit2unit_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24620de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y9/nm4qdmtn143d63hcl5r54xbr0000gn/T/ipykernel_6665/2460976691.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  utut_ckpt = torch.load(utut_path, map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of weights: 515\n",
      "encoder.version\n",
      "encoder.embed_tokens.weight\n",
      "encoder.embed_positions._float_tensor\n",
      "encoder.layers.0.self_attn.k_proj.weight\n",
      "encoder.layers.0.self_attn.k_proj.bias\n",
      "encoder.layers.0.self_attn.v_proj.weight\n",
      "encoder.layers.0.self_attn.v_proj.bias\n",
      "encoder.layers.0.self_attn.q_proj.weight\n",
      "encoder.layers.0.self_attn.q_proj.bias\n",
      "encoder.layers.0.self_attn.out_proj.weight\n",
      "encoder.layers.0.self_attn.out_proj.bias\n",
      "encoder.layers.0.self_attn_layer_norm.weight\n",
      "encoder.layers.0.self_attn_layer_norm.bias\n",
      "encoder.layers.0.fc1.weight\n",
      "encoder.layers.0.fc1.bias\n",
      "encoder.layers.0.fc2.weight\n",
      "encoder.layers.0.fc2.bias\n",
      "encoder.layers.0.final_layer_norm.weight\n",
      "encoder.layers.0.final_layer_norm.bias\n",
      "encoder.layers.1.self_attn.k_proj.weight\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "utut_ckpt = torch.load(utut_path, map_location='cpu')\n",
    "\n",
    "\n",
    "print(f\"Number of weights: {len(list(utut_ckpt['model'].keys()))}\")\n",
    "\n",
    "# 가중치 키 목록 중 상위 20개만 출력하여 언어 코드가 포함되어 있는지 확인\n",
    "for key in list(utut_ckpt['model'].keys())[:20]:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56dd8397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'args': None,\n",
       " 'cfg': {'_name': None,\n",
       "  'common': {'_name': None,\n",
       "   'no_progress_bar': False,\n",
       "   'log_interval': 100,\n",
       "   'log_format': 'json',\n",
       "   'log_file': None,\n",
       "   'aim_repo': None,\n",
       "   'aim_run_hash': None,\n",
       "   'tensorboard_logdir': 'tblog',\n",
       "   'wandb_project': None,\n",
       "   'azureml_logging': False,\n",
       "   'seed': 2,\n",
       "   'cpu': False,\n",
       "   'tpu': False,\n",
       "   'bf16': False,\n",
       "   'memory_efficient_bf16': False,\n",
       "   'fp16': True,\n",
       "   'memory_efficient_fp16': False,\n",
       "   'fp16_no_flatten_grads': False,\n",
       "   'fp16_init_scale': 128,\n",
       "   'fp16_scale_window': None,\n",
       "   'fp16_scale_tolerance': 0.0,\n",
       "   'on_cpu_convert_precision': False,\n",
       "   'min_loss_scale': 0.0001,\n",
       "   'threshold_loss_scale': None,\n",
       "   'amp': False,\n",
       "   'amp_batch_retries': 2,\n",
       "   'amp_init_scale': 128,\n",
       "   'amp_scale_window': None,\n",
       "   'user_dir': './',\n",
       "   'empty_cache_freq': 0,\n",
       "   'all_gather_list_size': 16384,\n",
       "   'model_parallel_size': 1,\n",
       "   'quantization_config_path': None,\n",
       "   'profile': False,\n",
       "   'reset_logging': False,\n",
       "   'suppress_crashes': False,\n",
       "   'use_plasma_view': False,\n",
       "   'plasma_path': '/tmp/plasma'},\n",
       "  'common_eval': {'_name': None,\n",
       "   'path': None,\n",
       "   'post_process': None,\n",
       "   'quiet': False,\n",
       "   'model_overrides': '{}',\n",
       "   'results_path': None},\n",
       "  'distributed_training': {'_name': None,\n",
       "   'distributed_world_size': 8,\n",
       "   'distributed_num_procs': 8,\n",
       "   'distributed_rank': 0,\n",
       "   'distributed_backend': 'nccl',\n",
       "   'distributed_init_method': None,\n",
       "   'distributed_port': -1,\n",
       "   'device_id': 0,\n",
       "   'distributed_no_spawn': False,\n",
       "   'ddp_backend': 'pytorch_ddp',\n",
       "   'ddp_comm_hook': 'none',\n",
       "   'bucket_cap_mb': 25,\n",
       "   'fix_batches_to_gpus': False,\n",
       "   'find_unused_parameters': False,\n",
       "   'gradient_as_bucket_view': False,\n",
       "   'fast_stat_sync': False,\n",
       "   'heartbeat_timeout': -1,\n",
       "   'broadcast_buffers': False,\n",
       "   'slowmo_momentum': None,\n",
       "   'slowmo_base_algorithm': 'localsgd',\n",
       "   'localsgd_frequency': 3,\n",
       "   'nprocs_per_node': 8,\n",
       "   'pipeline_model_parallel': False,\n",
       "   'pipeline_balance': None,\n",
       "   'pipeline_devices': None,\n",
       "   'pipeline_chunks': 0,\n",
       "   'pipeline_encoder_balance': None,\n",
       "   'pipeline_encoder_devices': None,\n",
       "   'pipeline_decoder_balance': None,\n",
       "   'pipeline_decoder_devices': None,\n",
       "   'pipeline_checkpoint': 'never',\n",
       "   'zero_sharding': 'none',\n",
       "   'fp16': True,\n",
       "   'memory_efficient_fp16': False,\n",
       "   'tpu': False,\n",
       "   'no_reshard_after_forward': False,\n",
       "   'fp32_reduce_scatter': False,\n",
       "   'cpu_offload': False,\n",
       "   'use_sharded_state': False,\n",
       "   'not_fsdp_flatten_parameters': False},\n",
       "  'dataset': {'_name': None,\n",
       "   'num_workers': 6,\n",
       "   'skip_invalid_size_inputs_valid_test': True,\n",
       "   'max_tokens': 1024,\n",
       "   'batch_size': 128,\n",
       "   'required_batch_size_multiple': 8,\n",
       "   'required_seq_len_multiple': 1,\n",
       "   'dataset_impl': 'mmap',\n",
       "   'data_buffer_size': 10,\n",
       "   'train_subset': 'train',\n",
       "   'valid_subset': 'valid',\n",
       "   'combine_valid_subsets': None,\n",
       "   'ignore_unused_valid_subsets': False,\n",
       "   'validate_interval': 1,\n",
       "   'validate_interval_updates': 0,\n",
       "   'validate_after_updates': 0,\n",
       "   'fixed_validation_seed': None,\n",
       "   'disable_validation': False,\n",
       "   'max_tokens_valid': 1024,\n",
       "   'batch_size_valid': 128,\n",
       "   'max_valid_steps': None,\n",
       "   'curriculum': 0,\n",
       "   'gen_subset': 'test',\n",
       "   'num_shards': 1,\n",
       "   'shard_id': 0,\n",
       "   'grouped_shuffling': False,\n",
       "   'update_epoch_batch_itr': False,\n",
       "   'update_ordered_indices_seed': False},\n",
       "  'optimization': {'_name': None,\n",
       "   'max_epoch': 0,\n",
       "   'max_update': 30000,\n",
       "   'stop_time_hours': 0.0,\n",
       "   'clip_norm': 0.1,\n",
       "   'sentence_avg': False,\n",
       "   'update_freq': [8],\n",
       "   'lr': [0.0001],\n",
       "   'stop_min_lr': -1.0,\n",
       "   'use_bmuf': False,\n",
       "   'skip_remainder_batch': False,\n",
       "   'debug_param_names': False},\n",
       "  'checkpoint': {'_name': None,\n",
       "   'save_dir': 'checkpoints',\n",
       "   'restore_file': 'checkpoint_last.pt',\n",
       "   'continue_once': None,\n",
       "   'finetune_from_model': None,\n",
       "   'reset_dataloader': False,\n",
       "   'reset_lr_scheduler': False,\n",
       "   'reset_meters': False,\n",
       "   'reset_optimizer': False,\n",
       "   'optimizer_overrides': '{}',\n",
       "   'save_interval': 1,\n",
       "   'save_interval_updates': 1000,\n",
       "   'keep_interval_updates': 1,\n",
       "   'keep_interval_updates_pattern': 50000,\n",
       "   'keep_last_epochs': -1,\n",
       "   'keep_best_checkpoints': -1,\n",
       "   'no_save': False,\n",
       "   'no_epoch_checkpoints': True,\n",
       "   'no_last_checkpoints': False,\n",
       "   'no_save_optimizer_state': False,\n",
       "   'best_checkpoint_metric': 'loss',\n",
       "   'maximize_best_checkpoint_metric': False,\n",
       "   'patience': -1,\n",
       "   'checkpoint_suffix': '',\n",
       "   'checkpoint_shard_count': 1,\n",
       "   'load_checkpoint_on_all_dp_ranks': False,\n",
       "   'write_checkpoints_asynchronously': False,\n",
       "   'model_parallel_size': 1},\n",
       "  'bmuf': {'_name': None,\n",
       "   'block_lr': 1.0,\n",
       "   'block_momentum': 0.875,\n",
       "   'global_sync_iter': 50,\n",
       "   'warmup_iterations': 500,\n",
       "   'use_nbm': False,\n",
       "   'average_sync': False,\n",
       "   'distributed_world_size': 8},\n",
       "  'generation': {'_name': None,\n",
       "   'beam': 20,\n",
       "   'beam_mt': 0,\n",
       "   'nbest': 1,\n",
       "   'max_len_a': 0.0,\n",
       "   'max_len_b': 200,\n",
       "   'max_len_a_mt': 0.0,\n",
       "   'max_len_b_mt': 200,\n",
       "   'min_len': 1,\n",
       "   'match_source_len': False,\n",
       "   'unnormalized': False,\n",
       "   'no_early_stop': False,\n",
       "   'no_beamable_mm': False,\n",
       "   'lenpen': 1.0,\n",
       "   'lenpen_mt': 1.0,\n",
       "   'unkpen': 0.0,\n",
       "   'replace_unk': None,\n",
       "   'sacrebleu': False,\n",
       "   'score_reference': False,\n",
       "   'prefix_size': 0,\n",
       "   'no_repeat_ngram_size': 0,\n",
       "   'sampling': False,\n",
       "   'sampling_topk': -1,\n",
       "   'sampling_topp': -1.0,\n",
       "   'constraints': None,\n",
       "   'temperature': 1.0,\n",
       "   'diverse_beam_groups': -1,\n",
       "   'diverse_beam_strength': 0.5,\n",
       "   'diversity_rate': -1.0,\n",
       "   'print_alignment': None,\n",
       "   'print_step': False,\n",
       "   'lm_path': None,\n",
       "   'lm_weight': 0.0,\n",
       "   'iter_decode_eos_penalty': 0.0,\n",
       "   'iter_decode_max_iter': 10,\n",
       "   'iter_decode_force_max_iter': False,\n",
       "   'iter_decode_with_beam': 1,\n",
       "   'iter_decode_with_external_reranker': False,\n",
       "   'retain_iter_history': False,\n",
       "   'retain_dropout': False,\n",
       "   'retain_dropout_modules': None,\n",
       "   'decoding_format': None,\n",
       "   'no_seed_provided': False,\n",
       "   'eos_token': None},\n",
       "  'eval_lm': {'_name': None,\n",
       "   'output_word_probs': False,\n",
       "   'output_word_stats': False,\n",
       "   'context_window': 0,\n",
       "   'softmax_batch': 9223372036854775807},\n",
       "  'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'},\n",
       "  'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir='tblog', wandb_project=None, azureml_logging=False, seed=2, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir='./', empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='polynomial_decay', simul_type=None, scoring='bleu', task='utut_pretraining', num_workers=6, skip_invalid_size_inputs_valid_test=True, max_tokens=1024, batch_size=128, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl='mmap', data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=1024, batch_size_valid=128, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=8, distributed_num_procs=8, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=8, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='utut_large', max_epoch=0, max_update=30000, stop_time_hours=0, clip_norm=0.1, sentence_avg=False, update_freq=[8], lr=[0.0001], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, debug_param_names=False, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=1000, keep_interval_updates=1, keep_interval_updates_pattern=50000, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='./', tokens_per_sample=1020, sample_break_mode='eos', replace_length=-1, mask=0.3, mask_random=0.1, insert=0.0, permute=0.0, rotate=0.0, poisson_lambda=10.0, shuffle_instance=False, mask_length='span-poisson', permute_sentences=1.0, shorten_method='truncate', shorten_data_split_list='train', multilang_sampling_alpha=0.7, add_lang_token=True, langs='en,es,fr,it,pt,el,ru,cs,da,de,fi,hr,hu,lt,nl,pl,ro,sk,sl', no_whole_word_mask_langs='', label_smoothing=0.2, report_accuracy=True, ignore_prefix_size=0, force_anneal=None, lr_shrink=0.1, warmup_updates=3000, pad=1, eos=2, unk=3, no_seed_provided=False, no_scale_embedding=False, encoder_embed_path=None, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_layers=12, encoder_attention_heads=16, encoder_normalize_before=True, encoder_learned_pos=False, decoder_embed_path=None, decoder_embed_dim=1024, decoder_ffn_embed_dim=4096, decoder_layers=12, decoder_attention_heads=16, decoder_normalize_before=True, decoder_learned_pos=False, attention_dropout=0.1, relu_dropout=0.0, dropout=0.1, max_target_positions=1024, max_source_positions=1024, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, share_decoder_input_output_embed=True, share_all_embeddings=True, decoder_output_dim=1024, decoder_input_dim=1024, layernorm_embedding=False, activation_fn='gelu', pooler_activation_fn='tanh', pooler_dropout=0.0, _name='mbart_large', activation_dropout=0.0, merge_src_tgt_embed=False, no_token_positional_embeddings=False, adaptive_input=False, no_cross_attention=False, cross_self_attention=False, tie_adaptive_weights=False, checkpoint_activations=False, offload_activations=False, encoder_layers_to_keep=None, decoder_layers_to_keep=None, encoder_layerdrop=0, decoder_layerdrop=0, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0),\n",
       "  'task': {'_name': 'utut_pretraining',\n",
       "   'data': './',\n",
       "   'bpe': None,\n",
       "   'tokens_per_sample': 1020,\n",
       "   'sample_break_mode': 'eos',\n",
       "   'replace_length': -1,\n",
       "   'mask': 0.3,\n",
       "   'mask_random': 0.1,\n",
       "   'insert': 0.0,\n",
       "   'permute': 0.0,\n",
       "   'rotate': 0.0,\n",
       "   'poisson_lambda': 10.0,\n",
       "   'shuffle_instance': 0.0,\n",
       "   'mask_length': 'span-poisson',\n",
       "   'permute_sentences': 1,\n",
       "   'seed': 2,\n",
       "   'shorten_method': 'truncate',\n",
       "   'shorten_data_split_list': 'train',\n",
       "   'max_source_positions': 1024,\n",
       "   'max_target_positions': 1024,\n",
       "   'dataset_impl': 'mmap',\n",
       "   'multilang_sampling_alpha': 0.7,\n",
       "   'add_lang_token': True,\n",
       "   'langs': 'en,es,fr,it,pt,el,ru,cs,da,de,fi,hr,hu,lt,nl,pl,ro,sk,sl',\n",
       "   'no_whole_word_mask_langs': '',\n",
       "   'train_subset': 'train',\n",
       "   'valid_subset': 'valid'},\n",
       "  'criterion': {'_name': 'label_smoothed_cross_entropy',\n",
       "   'label_smoothing': 0.2,\n",
       "   'report_accuracy': True,\n",
       "   'ignore_prefix_size': 0,\n",
       "   'sentence_avg': False},\n",
       "  'optimizer': {'_name': 'adam',\n",
       "   'adam_betas': [0.9, 0.999],\n",
       "   'adam_eps': 1e-08,\n",
       "   'weight_decay': 0.0,\n",
       "   'use_old_adam': False,\n",
       "   'fp16_adam_stats': False,\n",
       "   'tpu': False,\n",
       "   'lr': [0.0001]},\n",
       "  'lr_scheduler': {'_name': 'polynomial_decay',\n",
       "   'warmup_updates': 3000,\n",
       "   'force_anneal': None,\n",
       "   'end_learning_rate': 0.0,\n",
       "   'power': 1.0,\n",
       "   'total_num_update': 30000.0,\n",
       "   'lr': [0.0001]},\n",
       "  'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3},\n",
       "  'bpe': None,\n",
       "  'tokenizer': None,\n",
       "  'ema': {'_name': None,\n",
       "   'store_ema': False,\n",
       "   'ema_decay': 0.9999,\n",
       "   'ema_start_update': 0,\n",
       "   'ema_seed_model': None,\n",
       "   'ema_update_freq': 1,\n",
       "   'ema_fp32': False},\n",
       "  'simul_type': None},\n",
       " 'model': OrderedDict([('encoder.version', tensor([3.])),\n",
       "              ('encoder.embed_tokens.weight',\n",
       "               tensor([[-2.7542e-03, -6.4964e-03, -4.6921e-03,  ..., -3.9246e-02,\n",
       "                        -6.2714e-03, -3.5461e-02],\n",
       "                       [ 1.9897e-02, -2.8782e-03,  6.2823e-05,  ..., -3.4149e-02,\n",
       "                        -2.8900e-02, -1.1429e-02],\n",
       "                       [ 2.3499e-03,  1.6083e-02, -3.1586e-02,  ...,  5.2490e-02,\n",
       "                        -1.6565e-01,  6.2927e-02],\n",
       "                       ...,\n",
       "                       [-1.9388e-03,  7.3853e-03, -1.0155e-02,  ..., -4.6844e-03,\n",
       "                        -4.4891e-02, -3.9673e-03],\n",
       "                       [-1.6541e-02,  7.1573e-04, -1.6661e-03,  ..., -3.8483e-02,\n",
       "                        -1.0849e-02, -1.2779e-02],\n",
       "                       [ 7.7477e-03, -3.5492e-02, -3.5736e-02,  ..., -4.9561e-02,\n",
       "                        -1.4519e-02,  4.3068e-03]])),\n",
       "              ('encoder.embed_positions._float_tensor', tensor([0.])),\n",
       "              ('encoder.layers.0.self_attn.k_proj.weight',\n",
       "               tensor([[ 0.0122,  0.0552, -0.0743,  ..., -0.0810, -0.1447, -0.1106],\n",
       "                       [ 0.0410,  0.0946, -0.1002,  ...,  0.0195, -0.0745, -0.0151],\n",
       "                       [ 0.1207,  0.0029,  0.2108,  ..., -0.0825,  0.0332,  0.0413],\n",
       "                       ...,\n",
       "                       [-0.1398,  0.0110,  0.0051,  ...,  0.1166, -0.0240, -0.0873],\n",
       "                       [ 0.0737, -0.0518,  0.0004,  ...,  0.0855, -0.0886,  0.1310],\n",
       "                       [-0.1432, -0.0155, -0.0175,  ...,  0.0840,  0.2037, -0.1555]])),\n",
       "              ('encoder.layers.0.self_attn.k_proj.bias',\n",
       "               tensor([-0.0054, -0.0027, -0.0025,  ..., -0.0012,  0.0009,  0.0031])),\n",
       "              ('encoder.layers.0.self_attn.v_proj.weight',\n",
       "               tensor([[-0.0460,  0.0497,  0.0555,  ...,  0.1216, -0.0815, -0.0166],\n",
       "                       [-0.1617,  0.1163, -0.0162,  ..., -0.1133,  0.0283,  0.0509],\n",
       "                       [-0.0662,  0.0434,  0.0471,  ..., -0.1598,  0.0403,  0.1287],\n",
       "                       ...,\n",
       "                       [-0.0074, -0.0853, -0.0019,  ..., -0.0197, -0.0222, -0.0428],\n",
       "                       [-0.0127, -0.0624, -0.1917,  ...,  0.0817, -0.0017, -0.1465],\n",
       "                       [ 0.0169,  0.0182,  0.0012,  ...,  0.0645,  0.1437,  0.1427]])),\n",
       "              ('encoder.layers.0.self_attn.v_proj.bias',\n",
       "               tensor([-0.0039, -0.0016,  0.0081,  ...,  0.0078,  0.0173, -0.0125])),\n",
       "              ('encoder.layers.0.self_attn.q_proj.weight',\n",
       "               tensor([[ 0.1083, -0.1626,  0.0497,  ..., -0.0172,  0.1476,  0.0117],\n",
       "                       [ 0.0082, -0.0188, -0.1160,  ...,  0.0386, -0.1887, -0.0697],\n",
       "                       [ 0.1069,  0.1133, -0.1959,  ...,  0.0591, -0.1364,  0.0984],\n",
       "                       ...,\n",
       "                       [ 0.0382, -0.0577,  0.0077,  ...,  0.0247, -0.0336,  0.0089],\n",
       "                       [-0.0486,  0.1014,  0.1079,  ...,  0.0320, -0.2559, -0.1200],\n",
       "                       [ 0.1591, -0.1583,  0.0812,  ...,  0.0258,  0.1210,  0.0627]])),\n",
       "              ('encoder.layers.0.self_attn.q_proj.bias',\n",
       "               tensor([ 0.2253,  0.2084,  0.0629,  ...,  0.0133, -0.1327,  0.2413])),\n",
       "              ('encoder.layers.0.self_attn.out_proj.weight',\n",
       "               tensor([[ 0.0531, -0.0160, -0.0032,  ...,  0.0265, -0.0424, -0.0772],\n",
       "                       [-0.1393,  0.0043,  0.1794,  ...,  0.0430, -0.1453, -0.1086],\n",
       "                       [-0.0278,  0.1087,  0.0409,  ...,  0.1077, -0.0589, -0.0385],\n",
       "                       ...,\n",
       "                       [-0.0253,  0.1295,  0.0059,  ...,  0.1127, -0.0714, -0.2517],\n",
       "                       [ 0.1456, -0.1035,  0.0363,  ..., -0.0223, -0.1816,  0.1327],\n",
       "                       [ 0.0506,  0.0051,  0.2322,  ...,  0.0687,  0.0762,  0.0111]])),\n",
       "              ('encoder.layers.0.self_attn.out_proj.bias',\n",
       "               tensor([-0.0210, -0.1031, -0.1323,  ...,  0.1130,  0.1260,  0.0712])),\n",
       "              ('encoder.layers.0.self_attn_layer_norm.weight',\n",
       "               tensor([0.1353, 0.0071, 0.0678,  ..., 0.1246, 0.1129, 0.1327])),\n",
       "              ('encoder.layers.0.self_attn_layer_norm.bias',\n",
       "               tensor([-0.0003, -0.0015,  0.0114,  ..., -0.0183, -0.0127, -0.0165])),\n",
       "              ('encoder.layers.0.fc1.weight',\n",
       "               tensor([[-0.1101, -0.1109,  0.0674,  ..., -0.0770, -0.1072, -0.0190],\n",
       "                       [-0.0794,  0.0630, -0.0578,  ..., -0.1646,  0.1072, -0.0704],\n",
       "                       [ 0.0577, -0.0637,  0.0547,  ..., -0.1522, -0.0862, -0.0144],\n",
       "                       ...,\n",
       "                       [ 0.0281,  0.1033,  0.1055,  ..., -0.1121, -0.0816, -0.1316],\n",
       "                       [-0.0009,  0.0479,  0.0681,  ..., -0.0656,  0.0011, -0.0947],\n",
       "                       [ 0.2120,  0.0668,  0.0324,  ..., -0.0751, -0.0854, -0.0773]])),\n",
       "              ('encoder.layers.0.fc1.bias',\n",
       "               tensor([-0.0865, -0.0887, -0.1191,  ..., -0.1609, -0.1613, -0.1570])),\n",
       "              ('encoder.layers.0.fc2.weight',\n",
       "               tensor([[ 6.6338e-03,  6.4941e-02,  1.1238e-02,  ...,  7.2021e-02,\n",
       "                        -3.6163e-02,  8.0261e-02],\n",
       "                       [-7.5439e-02, -8.2642e-02,  2.1420e-03,  ..., -3.1891e-02,\n",
       "                        -2.1469e-02,  6.3293e-02],\n",
       "                       [-2.3413e-04,  6.9031e-02, -4.9225e-02,  ..., -1.2520e-02,\n",
       "                         1.0486e-01,  4.5929e-02],\n",
       "                       ...,\n",
       "                       [-2.1684e-04, -8.0994e-02,  5.2002e-02,  ..., -3.6743e-02,\n",
       "                        -5.2185e-02,  2.0676e-02],\n",
       "                       [ 1.4465e-01,  2.5146e-01,  4.9042e-02,  ..., -3.3112e-02,\n",
       "                        -5.3619e-02,  2.2537e-02],\n",
       "                       [-6.0272e-03,  1.3391e-01,  2.8687e-02,  ...,  2.0309e-02,\n",
       "                        -4.0771e-02,  4.7668e-02]])),\n",
       "              ('encoder.layers.0.fc2.bias',\n",
       "               tensor([-0.1231, -0.0175,  0.0089,  ..., -0.0850,  0.1052, -0.2340])),\n",
       "              ('encoder.layers.0.final_layer_norm.weight',\n",
       "               tensor([1.7158, 0.1422, 0.1741,  ..., 0.1545, 0.0645, 0.0955])),\n",
       "              ('encoder.layers.0.final_layer_norm.bias',\n",
       "               tensor([ 0.0369, -0.0320, -0.1190,  ...,  0.2539,  0.0623,  0.0170])),\n",
       "              ('encoder.layers.1.self_attn.k_proj.weight',\n",
       "               tensor([[-0.1418, -0.2264,  0.1714,  ..., -0.1777, -0.1044, -0.1458],\n",
       "                       [ 0.1085, -0.0396,  0.0972,  ..., -0.1437, -0.0590, -0.0875],\n",
       "                       [ 0.0097, -0.0828,  0.1672,  ...,  0.0579, -0.0797, -0.2028],\n",
       "                       ...,\n",
       "                       [ 0.0561,  0.0414,  0.1598,  ...,  0.0245, -0.1324, -0.2255],\n",
       "                       [ 0.1649,  0.1158, -0.0505,  ...,  0.2021, -0.2263, -0.3267],\n",
       "                       [ 0.0564,  0.0309, -0.0066,  ...,  0.0811, -0.0668, -0.0704]])),\n",
       "              ('encoder.layers.1.self_attn.k_proj.bias',\n",
       "               tensor([-0.0016, -0.0076, -0.0045,  ...,  0.0051, -0.0035, -0.0012])),\n",
       "              ('encoder.layers.1.self_attn.v_proj.weight',\n",
       "               tensor([[-0.0421,  0.0518, -0.0033,  ..., -0.1245,  0.0518, -0.0514],\n",
       "                       [-0.1033, -0.0011, -0.0742,  ...,  0.0286,  0.0978,  0.0669],\n",
       "                       [ 0.1351,  0.0056,  0.0120,  ...,  0.0939, -0.0874,  0.0694],\n",
       "                       ...,\n",
       "                       [ 0.0197,  0.0088,  0.0842,  ..., -0.0766, -0.0230, -0.0557],\n",
       "                       [ 0.0659,  0.0712, -0.0448,  ...,  0.0785,  0.0511,  0.1509],\n",
       "                       [-0.0561,  0.1481,  0.0485,  ...,  0.0270, -0.0549, -0.0297]])),\n",
       "              ('encoder.layers.1.self_attn.v_proj.bias',\n",
       "               tensor([-0.0261,  0.0114, -0.0012,  ...,  0.0100, -0.0230, -0.0065])),\n",
       "              ('encoder.layers.1.self_attn.q_proj.weight',\n",
       "               tensor([[-0.1677, -0.0611,  0.3433,  ..., -0.0174, -0.2559,  0.1234],\n",
       "                       [ 0.0107,  0.2214,  0.0100,  ..., -0.0935, -0.2183,  0.2961],\n",
       "                       [ 0.1105, -0.0420, -0.0578,  ..., -0.0962,  0.0377,  0.1885],\n",
       "                       ...,\n",
       "                       [ 0.0183,  0.0417, -0.0100,  ..., -0.1553, -0.2134, -0.1132],\n",
       "                       [-0.0041,  0.1096, -0.0294,  ..., -0.1198, -0.3025, -0.0350],\n",
       "                       [-0.0938, -0.0500, -0.0709,  ...,  0.0093, -0.0956, -0.0594]])),\n",
       "              ('encoder.layers.1.self_attn.q_proj.bias',\n",
       "               tensor([ 0.3625,  0.3066,  0.1289,  ...,  0.2874, -0.1155, -0.0347])),\n",
       "              ('encoder.layers.1.self_attn.out_proj.weight',\n",
       "               tensor([[ 0.0632, -0.0662, -0.1022,  ..., -0.0685,  0.0152, -0.0134],\n",
       "                       [-0.0493,  0.0423,  0.0880,  ..., -0.0485, -0.1462, -0.1407],\n",
       "                       [-0.0289, -0.2445,  0.1338,  ..., -0.0070, -0.0439,  0.0897],\n",
       "                       ...,\n",
       "                       [ 0.0202,  0.0720, -0.0660,  ..., -0.0433,  0.0433, -0.0443],\n",
       "                       [ 0.0204,  0.0567,  0.0728,  ...,  0.0408, -0.0738, -0.0387],\n",
       "                       [ 0.0199, -0.0863, -0.1078,  ...,  0.1192, -0.1721,  0.1147]])),\n",
       "              ('encoder.layers.1.self_attn.out_proj.bias',\n",
       "               tensor([-0.1598, -0.0839, -0.1504,  ...,  0.0377, -0.0266,  0.1067])),\n",
       "              ('encoder.layers.1.self_attn_layer_norm.weight',\n",
       "               tensor([0.3977, 0.1298, 0.1433,  ..., 0.1445, 0.1270, 0.1644])),\n",
       "              ('encoder.layers.1.self_attn_layer_norm.bias',\n",
       "               tensor([ 0.0338,  0.0143,  0.0226,  ..., -0.0223, -0.0228, -0.0061])),\n",
       "              ('encoder.layers.1.fc1.weight',\n",
       "               tensor([[ 0.0902,  0.0511,  0.0804,  ...,  0.0643, -0.0285, -0.1613],\n",
       "                       [-0.0591,  0.0286, -0.1118,  ..., -0.0726,  0.0248, -0.1552],\n",
       "                       [-0.2244,  0.0848,  0.0450,  ...,  0.0520, -0.0094,  0.0948],\n",
       "                       ...,\n",
       "                       [ 0.0338,  0.1664,  0.0147,  ...,  0.0171, -0.1171, -0.0800],\n",
       "                       [-0.0081, -0.0397,  0.0453,  ..., -0.1190, -0.0242, -0.0644],\n",
       "                       [ 0.1482,  0.0110,  0.0848,  ..., -0.0671, -0.0988, -0.2681]])),\n",
       "              ('encoder.layers.1.fc1.bias',\n",
       "               tensor([-0.0684, -0.0763,  0.0034,  ..., -0.1511, -0.1371, -0.0471])),\n",
       "              ('encoder.layers.1.fc2.weight',\n",
       "               tensor([[ 0.1412, -0.0481,  0.0522,  ..., -0.0075, -0.0101,  0.0348],\n",
       "                       [ 0.1505, -0.0610, -0.0622,  ...,  0.0069,  0.0515, -0.0023],\n",
       "                       [-0.1163, -0.2776,  0.0900,  ...,  0.0234,  0.0233, -0.0509],\n",
       "                       ...,\n",
       "                       [-0.1285, -0.1033, -0.0908,  ..., -0.1017, -0.0950, -0.1011],\n",
       "                       [ 0.2388, -0.1885,  0.1316,  ..., -0.0034, -0.0612,  0.0525],\n",
       "                       [-0.0090, -0.0481, -0.2236,  ..., -0.0220, -0.0840, -0.0178]])),\n",
       "              ('encoder.layers.1.fc2.bias',\n",
       "               tensor([ 0.0766, -0.1062, -0.1459,  ...,  0.0748,  0.0231,  0.0859])),\n",
       "              ('encoder.layers.1.final_layer_norm.weight',\n",
       "               tensor([0.6929, 0.2908, 0.4353,  ..., 0.3486, 0.3054, 0.3801])),\n",
       "              ('encoder.layers.1.final_layer_norm.bias',\n",
       "               tensor([ 0.0629,  0.0126, -0.0351,  ...,  0.0753,  0.0069,  0.0847])),\n",
       "              ('encoder.layers.2.self_attn.k_proj.weight',\n",
       "               tensor([[ 0.0126,  0.1174,  0.1532,  ...,  0.0172, -0.0198,  0.0317],\n",
       "                       [ 0.1731,  0.0031, -0.2417,  ..., -0.2217, -0.0308, -0.0561],\n",
       "                       [-0.1768, -0.0343,  0.1543,  ...,  0.0162,  0.0963,  0.0237],\n",
       "                       ...,\n",
       "                       [ 0.1520,  0.0709,  0.1617,  ..., -0.0369, -0.0265, -0.0191],\n",
       "                       [ 0.0864, -0.0452, -0.1061,  ...,  0.2588, -0.0766,  0.1531],\n",
       "                       [ 0.0846, -0.0468, -0.0490,  ..., -0.0416,  0.0048,  0.0986]])),\n",
       "              ('encoder.layers.2.self_attn.k_proj.bias',\n",
       "               tensor([-0.0001,  0.0121, -0.0080,  ..., -0.0065,  0.0040, -0.0025])),\n",
       "              ('encoder.layers.2.self_attn.v_proj.weight',\n",
       "               tensor([[-0.0337,  0.0209,  0.0546,  ...,  0.1110, -0.1268, -0.0184],\n",
       "                       [-0.0565, -0.0281,  0.0313,  ..., -0.0405,  0.0091,  0.1267],\n",
       "                       [ 0.0760,  0.0491, -0.0311,  ..., -0.0382,  0.0633, -0.0512],\n",
       "                       ...,\n",
       "                       [ 0.0055, -0.0179, -0.0979,  ...,  0.1752,  0.0693, -0.0110],\n",
       "                       [ 0.0727, -0.0485, -0.0633,  ..., -0.1864, -0.0323, -0.1694],\n",
       "                       [-0.0156, -0.1229, -0.1024,  ..., -0.1663, -0.0428, -0.0760]])),\n",
       "              ('encoder.layers.2.self_attn.v_proj.bias',\n",
       "               tensor([ 0.0076,  0.0027,  0.0038,  ..., -0.0371,  0.0886,  0.0004])),\n",
       "              ('encoder.layers.2.self_attn.q_proj.weight',\n",
       "               tensor([[ 0.0984,  0.0285,  0.0793,  ...,  0.0421, -0.1147,  0.1224],\n",
       "                       [-0.1605,  0.1011, -0.1818,  ..., -0.1500,  0.0382, -0.0084],\n",
       "                       [ 0.1017, -0.2632,  0.0299,  ...,  0.0745,  0.0362, -0.0066],\n",
       "                       ...,\n",
       "                       [-0.1168, -0.0019, -0.2737,  ...,  0.0194,  0.0456,  0.0681],\n",
       "                       [-0.0208,  0.0847,  0.4424,  ..., -0.0066, -0.0871, -0.2056],\n",
       "                       [-0.0870, -0.0110,  0.2979,  ...,  0.1152,  0.0182, -0.0194]])),\n",
       "              ('encoder.layers.2.self_attn.q_proj.bias',\n",
       "               tensor([ 0.2217, -0.3208,  0.2852,  ..., -0.0932, -0.1215,  0.1066])),\n",
       "              ('encoder.layers.2.self_attn.out_proj.weight',\n",
       "               tensor([[-0.0660,  0.0983, -0.0273,  ..., -0.0589,  0.0865, -0.0283],\n",
       "                       [ 0.1559, -0.0436, -0.0059,  ..., -0.0205,  0.1066, -0.0531],\n",
       "                       [-0.0750,  0.0058,  0.1185,  ...,  0.0703,  0.1393,  0.0236],\n",
       "                       ...,\n",
       "                       [ 0.0577, -0.0157,  0.0457,  ...,  0.0292,  0.0119,  0.0937],\n",
       "                       [ 0.1074, -0.0205, -0.2710,  ...,  0.0727, -0.0511, -0.0111],\n",
       "                       [ 0.0380, -0.1376, -0.0240,  ..., -0.0244, -0.0654,  0.0316]])),\n",
       "              ('encoder.layers.2.self_attn.out_proj.bias',\n",
       "               tensor([ 0.0559,  0.0069, -0.0290,  ...,  0.0460, -0.0484,  0.0861])),\n",
       "              ('encoder.layers.2.self_attn_layer_norm.weight',\n",
       "               tensor([0.5581, 0.2334, 0.2297,  ..., 0.2993, 0.2346, 0.2218])),\n",
       "              ('encoder.layers.2.self_attn_layer_norm.bias',\n",
       "               tensor([ 0.0216,  0.0176,  0.0486,  ..., -0.0301, -0.0213, -0.0070])),\n",
       "              ('encoder.layers.2.fc1.weight',\n",
       "               tensor([[-0.1537,  0.0607,  0.0643,  ..., -0.0695, -0.0109, -0.0121],\n",
       "                       [-0.0689, -0.0200,  0.1199,  ...,  0.0449, -0.1184,  0.1062],\n",
       "                       [-0.0089, -0.0547,  0.2695,  ..., -0.0889, -0.0831, -0.1769],\n",
       "                       ...,\n",
       "                       [ 0.0568,  0.1504,  0.0251,  ...,  0.0640,  0.0295,  0.0859],\n",
       "                       [-0.1462,  0.0199, -0.0161,  ..., -0.1190,  0.1111,  0.0771],\n",
       "                       [ 0.0063, -0.1100,  0.0979,  ..., -0.1399,  0.0817, -0.0665]])),\n",
       "              ('encoder.layers.2.fc1.bias',\n",
       "               tensor([-0.0701, -0.0982, -0.0869,  ..., -0.1166, -0.1096, -0.1096])),\n",
       "              ('encoder.layers.2.fc2.weight',\n",
       "               tensor([[-1.8066e-01,  3.2397e-01, -5.0125e-03,  ...,  8.6182e-02,\n",
       "                        -1.5088e-01, -5.6763e-02],\n",
       "                       [-2.0911e-01,  3.2562e-02,  1.2769e-01,  ...,  6.4026e-02,\n",
       "                         2.9800e-02,  8.3740e-02],\n",
       "                       [ 5.9426e-05,  2.1561e-02, -5.7495e-02,  ...,  5.6343e-03,\n",
       "                        -1.1224e-01,  6.6757e-03],\n",
       "                       ...,\n",
       "                       [-7.2815e-02,  1.1450e-01, -4.3579e-02,  ...,  8.6487e-02,\n",
       "                        -1.4734e-01, -1.3159e-01],\n",
       "                       [-4.3304e-02, -3.4504e-03, -9.5520e-02,  ..., -1.3684e-01,\n",
       "                        -2.6074e-01, -3.9337e-02],\n",
       "                       [-1.6357e-01,  8.8135e-02,  1.9092e-01,  ...,  1.1682e-01,\n",
       "                        -1.8814e-02,  2.0947e-01]])),\n",
       "              ('encoder.layers.2.fc2.bias',\n",
       "               tensor([ 0.0205, -0.1582, -0.1057,  ...,  0.0958,  0.1235,  0.1411])),\n",
       "              ('encoder.layers.2.final_layer_norm.weight',\n",
       "               tensor([0.5649, 0.3799, 0.5083,  ..., 0.4387, 0.3862, 0.5083])),\n",
       "              ('encoder.layers.2.final_layer_norm.bias',\n",
       "               tensor([ 0.0876, -0.0231, -0.0821,  ...,  0.0483, -0.0173,  0.1122])),\n",
       "              ('encoder.layers.3.self_attn.k_proj.weight',\n",
       "               tensor([[ 0.0795, -0.0999,  0.1244,  ..., -0.0424, -0.0275, -0.1724],\n",
       "                       [ 0.0958, -0.0544, -0.1697,  ...,  0.0392, -0.1105, -0.1074],\n",
       "                       [-0.0212, -0.1842,  0.1305,  ..., -0.0005, -0.0438,  0.1049],\n",
       "                       ...,\n",
       "                       [ 0.0959, -0.1716,  0.0452,  ...,  0.0321, -0.0198, -0.1135],\n",
       "                       [-0.1414, -0.1555,  0.0474,  ..., -0.0243,  0.0120,  0.0784],\n",
       "                       [-0.0040,  0.0533,  0.2034,  ...,  0.0032,  0.1395, -0.0863]])),\n",
       "              ('encoder.layers.3.self_attn.k_proj.bias',\n",
       "               tensor([ 0.0093,  0.0037, -0.0004,  ...,  0.0165,  0.0001, -0.0077])),\n",
       "              ('encoder.layers.3.self_attn.v_proj.weight',\n",
       "               tensor([[ 0.0285,  0.1443,  0.0385,  ..., -0.0223, -0.1250, -0.1194],\n",
       "                       [-0.0164,  0.1113,  0.0903,  ...,  0.0385,  0.0539, -0.0612],\n",
       "                       [-0.0272,  0.0150,  0.0724,  ...,  0.0554,  0.0069, -0.0404],\n",
       "                       ...,\n",
       "                       [ 0.0446, -0.1090, -0.2161,  ..., -0.0097, -0.1425,  0.0275],\n",
       "                       [-0.0934,  0.0784, -0.1186,  ..., -0.0626,  0.0240, -0.0309],\n",
       "                       [-0.1732,  0.0170,  0.1893,  ...,  0.0712,  0.0795,  0.0923]])),\n",
       "              ('encoder.layers.3.self_attn.v_proj.bias',\n",
       "               tensor([ 0.0224, -0.0240,  0.0119,  ..., -0.0019, -0.0073,  0.0126])),\n",
       "              ('encoder.layers.3.self_attn.q_proj.weight',\n",
       "               tensor([[-0.0399,  0.0623, -0.0701,  ...,  0.0054,  0.0076,  0.1487],\n",
       "                       [-0.1721,  0.0031,  0.0482,  ..., -0.1689,  0.0931, -0.3049],\n",
       "                       [ 0.0023,  0.2024,  0.0529,  ...,  0.0864,  0.0174, -0.2063],\n",
       "                       ...,\n",
       "                       [ 0.0679, -0.0768, -0.0785,  ..., -0.2324,  0.1116,  0.0918],\n",
       "                       [-0.0662,  0.1241, -0.1333,  ..., -0.0535,  0.0595, -0.0355],\n",
       "                       [ 0.0747,  0.1147, -0.3198,  ...,  0.0172,  0.2296, -0.1234]])),\n",
       "              ('encoder.layers.3.self_attn.q_proj.bias',\n",
       "               tensor([ 0.0478,  0.0841, -0.2292,  ...,  0.2400,  0.1562,  0.2549])),\n",
       "              ('encoder.layers.3.self_attn.out_proj.weight',\n",
       "               tensor([[-0.0750, -0.1260,  0.0140,  ..., -0.1105, -0.0142,  0.0074],\n",
       "                       [-0.0483, -0.1052,  0.0207,  ..., -0.0302, -0.0653,  0.0327],\n",
       "                       [ 0.0250, -0.0950, -0.0287,  ..., -0.1661, -0.1595,  0.2305],\n",
       "                       ...,\n",
       "                       [ 0.0396,  0.0651, -0.0078,  ...,  0.0049, -0.0578, -0.0169],\n",
       "                       [ 0.0712, -0.0454, -0.0338,  ..., -0.0273, -0.1682, -0.0303],\n",
       "                       [ 0.1055, -0.0253,  0.0634,  ...,  0.1131, -0.0470, -0.0372]])),\n",
       "              ('encoder.layers.3.self_attn.out_proj.bias',\n",
       "               tensor([ 0.0526, -0.0721,  0.0228,  ...,  0.0246,  0.0829,  0.0724])),\n",
       "              ('encoder.layers.3.self_attn_layer_norm.weight',\n",
       "               tensor([0.3433, 0.2693, 0.2522,  ..., 0.2639, 0.2469, 0.2581])),\n",
       "              ('encoder.layers.3.self_attn_layer_norm.bias',\n",
       "               tensor([ 0.0148,  0.0130,  0.0300,  ..., -0.0163, -0.0282,  0.0119])),\n",
       "              ('encoder.layers.3.fc1.weight',\n",
       "               tensor([[ 1.7853e-03,  6.5186e-02,  1.2952e-01,  ..., -2.9373e-02,\n",
       "                        -4.0747e-01, -2.6025e-01],\n",
       "                       [ 1.1530e-01,  9.6817e-03,  1.9714e-01,  ..., -1.4856e-01,\n",
       "                        -3.3903e-04, -1.2512e-01],\n",
       "                       [ 2.3376e-01, -6.8542e-02,  4.8950e-02,  ...,  1.2520e-02,\n",
       "                        -4.1595e-02,  2.4094e-02],\n",
       "                       ...,\n",
       "                       [ 1.0785e-01, -5.4352e-02,  1.6968e-01,  ...,  1.9275e-01,\n",
       "                         4.6661e-02, -1.5979e-01],\n",
       "                       [ 3.7842e-02, -3.2139e-03,  1.1523e-01,  ...,  5.5481e-02,\n",
       "                        -4.7668e-02, -1.1304e-01],\n",
       "                       [-3.3020e-02, -6.8176e-02, -1.0889e-01,  ...,  5.1178e-02,\n",
       "                        -1.1243e-01,  8.6243e-02]])),\n",
       "              ('encoder.layers.3.fc1.bias',\n",
       "               tensor([-0.0953, -0.0917, -0.0643,  ..., -0.1235, -0.0757, -0.0939])),\n",
       "              ('encoder.layers.3.fc2.weight',\n",
       "               tensor([[-0.0762,  0.0625, -0.0497,  ..., -0.0102,  0.0531, -0.0333],\n",
       "                       [ 0.0072, -0.1015,  0.0831,  ...,  0.0727,  0.1456, -0.0500],\n",
       "                       [-0.0127,  0.0178,  0.0507,  ..., -0.0873,  0.0765, -0.0821],\n",
       "                       ...,\n",
       "                       [-0.1842, -0.2678,  0.0261,  ..., -0.0968, -0.0154,  0.0493],\n",
       "                       [-0.0429, -0.0295,  0.0526,  ..., -0.0597,  0.2074, -0.0964],\n",
       "                       [ 0.0280,  0.0640,  0.0190,  ...,  0.0866,  0.0309,  0.0379]])),\n",
       "              ('encoder.layers.3.fc2.bias',\n",
       "               tensor([ 0.0075, -0.0403, -0.1503,  ...,  0.0527,  0.0152, -0.0186])),\n",
       "              ('encoder.layers.3.final_layer_norm.weight',\n",
       "               tensor([0.4854, 0.4875, 0.5547,  ..., 0.4504, 0.4202, 0.4688])),\n",
       "              ('encoder.layers.3.final_layer_norm.bias',\n",
       "               tensor([ 0.0307,  0.0123, -0.0650,  ...,  0.0351, -0.0392,  0.1078])),\n",
       "              ('encoder.layers.4.self_attn.k_proj.weight',\n",
       "               tensor([[ 0.0936, -0.1608,  0.0568,  ...,  0.0494,  0.0267,  0.0374],\n",
       "                       [-0.1289,  0.1896,  0.0308,  ..., -0.0524, -0.0555,  0.0726],\n",
       "                       [-0.0093,  0.0263,  0.0658,  ..., -0.0616, -0.0782,  0.0108],\n",
       "                       ...,\n",
       "                       [-0.0302, -0.0155, -0.0372,  ..., -0.0737,  0.1054, -0.1375],\n",
       "                       [ 0.0167,  0.0227, -0.0606,  ..., -0.0936,  0.1364, -0.1202],\n",
       "                       [-0.0349,  0.0529,  0.0800,  ..., -0.0739,  0.1614,  0.0662]])),\n",
       "              ('encoder.layers.4.self_attn.k_proj.bias',\n",
       "               tensor([ 0.0089, -0.0004, -0.0074,  ..., -0.0057, -0.0031, -0.0018])),\n",
       "              ('encoder.layers.4.self_attn.v_proj.weight',\n",
       "               tensor([[-5.0385e-02,  1.4111e-01,  4.4373e-02,  ...,  3.8605e-02,\n",
       "                         1.0004e-01,  8.3984e-02],\n",
       "                       [-2.0782e-02,  2.5070e-02,  2.4033e-02,  ..., -6.0944e-02,\n",
       "                        -3.2196e-02, -7.1167e-02],\n",
       "                       [ 5.2917e-02,  1.2610e-01,  6.6895e-02,  ..., -2.1545e-02,\n",
       "                        -1.5002e-01,  1.0571e-01],\n",
       "                       ...,\n",
       "                       [-8.9783e-02,  6.6467e-02,  1.3184e-01,  ...,  1.1945e-01,\n",
       "                         1.1249e-01,  4.3945e-02],\n",
       "                       [-3.8940e-02,  3.4943e-02,  1.6678e-02,  ...,  3.2562e-02,\n",
       "                         1.2769e-01, -9.8816e-02],\n",
       "                       [ 3.4393e-02, -3.4241e-02,  1.8524e-02,  ..., -3.1311e-02,\n",
       "                         6.2744e-02,  6.2883e-05]])),\n",
       "              ('encoder.layers.4.self_attn.v_proj.bias',\n",
       "               tensor([-0.0068,  0.0097, -0.0312,  ..., -0.0052,  0.0184,  0.0019])),\n",
       "              ('encoder.layers.4.self_attn.q_proj.weight',\n",
       "               tensor([[ 0.0390,  0.0630,  0.1213,  ...,  0.0013,  0.0298,  0.2423],\n",
       "                       [-0.0544, -0.2610, -0.1609,  ...,  0.0019,  0.2798, -0.1665],\n",
       "                       [-0.0789,  0.0539, -0.1715,  ...,  0.0504,  0.1918,  0.0432],\n",
       "                       ...,\n",
       "                       [-0.0996, -0.0645,  0.1113,  ..., -0.1215, -0.0457, -0.0352],\n",
       "                       [ 0.1112,  0.0021,  0.1531,  ..., -0.0051, -0.0934,  0.0072],\n",
       "                       [-0.0228, -0.0206,  0.1041,  ..., -0.0058, -0.0958, -0.0398]])),\n",
       "              ('encoder.layers.4.self_attn.q_proj.bias',\n",
       "               tensor([-0.4939,  0.2395,  0.1046,  ...,  0.0897,  0.0577, -0.0097])),\n",
       "              ('encoder.layers.4.self_attn.out_proj.weight',\n",
       "               tensor([[ 0.0334,  0.1244, -0.0408,  ...,  0.0546,  0.1005,  0.0431],\n",
       "                       [-0.0479,  0.0071, -0.0873,  ..., -0.0262,  0.0303, -0.0941],\n",
       "                       [ 0.0167, -0.0912, -0.0131,  ..., -0.0424, -0.0347, -0.1028],\n",
       "                       ...,\n",
       "                       [ 0.0291, -0.0372, -0.0454,  ..., -0.0456,  0.0582,  0.0961],\n",
       "                       [ 0.1003,  0.1208,  0.0700,  ..., -0.0081, -0.0651,  0.0934],\n",
       "                       [-0.1863,  0.2316,  0.0045,  ..., -0.0734,  0.0432, -0.0335]])),\n",
       "              ('encoder.layers.4.self_attn.out_proj.bias',\n",
       "               tensor([-0.0119, -0.0157, -0.0117,  ..., -0.0301, -0.0387, -0.0804])),\n",
       "              ('encoder.layers.4.self_attn_layer_norm.weight',\n",
       "               tensor([0.3811, 0.3103, 0.3042,  ..., 0.3142, 0.2900, 0.2700])),\n",
       "              ('encoder.layers.4.self_attn_layer_norm.bias',\n",
       "               tensor([ 0.0096, -0.0023,  0.0155,  ..., -0.0113, -0.0255,  0.0068])),\n",
       "              ('encoder.layers.4.fc1.weight',\n",
       "               tensor([[-4.6692e-02,  1.7981e-01,  1.1920e-01,  ...,  6.5498e-03,\n",
       "                        -3.7256e-01, -1.2140e-01],\n",
       "                       [-1.7212e-01, -7.5623e-02,  6.8176e-02,  ...,  8.4996e-05,\n",
       "                        -1.2402e-01, -9.5177e-04],\n",
       "                       [-3.5370e-02,  6.7871e-02, -6.9824e-02,  ...,  3.0396e-02,\n",
       "                         1.9983e-01,  4.4281e-02],\n",
       "                       ...,\n",
       "                       [ 4.3115e-01, -1.3232e-01,  1.0669e-01,  ..., -2.1997e-01,\n",
       "                        -3.8513e-02,  1.9580e-01],\n",
       "                       [-9.0714e-03,  6.6345e-02,  1.6687e-01,  ...,  1.0742e-01,\n",
       "                        -1.4038e-01, -1.6907e-01],\n",
       "                       [-1.4001e-01, -1.7151e-01,  1.8234e-02,  ..., -4.7852e-02,\n",
       "                         2.6514e-01,  1.0229e-01]])),\n",
       "              ('encoder.layers.4.fc1.bias',\n",
       "               tensor([-0.1152, -0.1265, -0.0641,  ..., -0.1154, -0.0831, -0.0830])),\n",
       "              ('encoder.layers.4.fc2.weight',\n",
       "               tensor([[ 0.0124,  0.0771,  0.0077,  ...,  0.2407,  0.1086,  0.1170],\n",
       "                       [-0.0225, -0.0022, -0.0050,  ...,  0.0504, -0.0237,  0.2394],\n",
       "                       [ 0.0103,  0.2505, -0.0381,  ...,  0.0494,  0.0114, -0.0809],\n",
       "                       ...,\n",
       "                       [-0.2524, -0.2180, -0.0011,  ...,  0.0032, -0.1261,  0.0480],\n",
       "                       [ 0.0144, -0.1250, -0.1978,  ..., -0.1208,  0.1254,  0.1202],\n",
       "                       [-0.1048, -0.1403, -0.1110,  ..., -0.0294, -0.0587, -0.1536]])),\n",
       "              ('encoder.layers.4.fc2.bias',\n",
       "               tensor([ 0.1387,  0.0393, -0.1597,  ..., -0.0139,  0.0360, -0.0650])),\n",
       "              ('encoder.layers.4.final_layer_norm.weight',\n",
       "               tensor([0.4468, 0.5054, 0.5430,  ..., 0.4771, 0.4250, 0.4707])),\n",
       "              ('encoder.layers.4.final_layer_norm.bias',\n",
       "               tensor([ 0.0205,  0.0223, -0.1069,  ...,  0.0078, -0.0396,  0.0672])),\n",
       "              ('encoder.layers.5.self_attn.k_proj.weight',\n",
       "               tensor([[-0.0504,  0.0775,  0.0411,  ...,  0.0025, -0.1661,  0.0688],\n",
       "                       [ 0.0300,  0.0851,  0.0090,  ..., -0.0204,  0.0972, -0.0449],\n",
       "                       [ 0.0703,  0.0034, -0.0094,  ..., -0.1395, -0.0493,  0.1855],\n",
       "                       ...,\n",
       "                       [-0.1827,  0.1149, -0.0370,  ..., -0.0966, -0.0489,  0.0650],\n",
       "                       [-0.0523, -0.0223, -0.0775,  ...,  0.1301, -0.1029,  0.0429],\n",
       "                       [ 0.0989, -0.0488, -0.1476,  ...,  0.1124,  0.0954, -0.0581]])),\n",
       "              ('encoder.layers.5.self_attn.k_proj.bias',\n",
       "               tensor([-0.0220,  0.0148,  0.0148,  ..., -0.0036, -0.0016,  0.0015])),\n",
       "              ('encoder.layers.5.self_attn.v_proj.weight',\n",
       "               tensor([[ 0.0958, -0.0725, -0.0587,  ...,  0.0561, -0.1140, -0.0191],\n",
       "                       [ 0.1201, -0.1130, -0.0076,  ..., -0.0319,  0.0171,  0.0374],\n",
       "                       [-0.0019,  0.0434,  0.1396,  ..., -0.0161, -0.0411, -0.0451],\n",
       "                       ...,\n",
       "                       [-0.0727, -0.0005, -0.1453,  ..., -0.0308, -0.0560, -0.0685],\n",
       "                       [ 0.0150,  0.0571,  0.0718,  ...,  0.0247,  0.0197, -0.1008],\n",
       "                       [ 0.1793,  0.1387,  0.0674,  ...,  0.0210,  0.0041,  0.0815]])),\n",
       "              ('encoder.layers.5.self_attn.v_proj.bias',\n",
       "               tensor([-0.0049,  0.0184, -0.0016,  ...,  0.0050, -0.0414, -0.0214])),\n",
       "              ('encoder.layers.5.self_attn.q_proj.weight',\n",
       "               tensor([[-0.0417,  0.1346,  0.0782,  ..., -0.0573, -0.1486,  0.0793],\n",
       "                       [-0.0798, -0.1633, -0.0999,  ..., -0.2742, -0.0374, -0.2512],\n",
       "                       [ 0.0407,  0.0016,  0.1070,  ...,  0.0571, -0.0037,  0.1892],\n",
       "                       ...,\n",
       "                       [ 0.0275, -0.1205,  0.0907,  ...,  0.0562,  0.0587, -0.0324],\n",
       "                       [ 0.2103,  0.0094, -0.0120,  ...,  0.1486, -0.1204, -0.0463],\n",
       "                       [ 0.1373,  0.0781, -0.0529,  ...,  0.1049,  0.0259, -0.0466]])),\n",
       "              ('encoder.layers.5.self_attn.q_proj.bias',\n",
       "               tensor([ 0.3809, -0.0887, -0.2010,  ...,  0.0746, -0.2401, -0.1204])),\n",
       "              ('encoder.layers.5.self_attn.out_proj.weight',\n",
       "               tensor([[-0.0997, -0.0063,  0.0889,  ..., -0.0451, -0.3416,  0.0103],\n",
       "                       [ 0.1459,  0.0107,  0.0327,  ...,  0.0632, -0.1509, -0.0271],\n",
       "                       [ 0.0878, -0.1979, -0.0253,  ..., -0.0341, -0.0064, -0.0159],\n",
       "                       ...,\n",
       "                       [-0.0875,  0.1323, -0.1009,  ...,  0.0669,  0.0529, -0.0745],\n",
       "                       [-0.0760,  0.0539, -0.1143,  ...,  0.0300, -0.0476, -0.1327],\n",
       "                       [-0.1321, -0.0284,  0.0982,  ..., -0.0276,  0.0844,  0.0855]])),\n",
       "              ('encoder.layers.5.self_attn.out_proj.bias',\n",
       "               tensor([ 0.0788, -0.0597,  0.0204,  ...,  0.0255, -0.0310, -0.0362])),\n",
       "              ('encoder.layers.5.self_attn_layer_norm.weight',\n",
       "               tensor([0.3657, 0.3203, 0.3242,  ..., 0.3845, 0.3081, 0.2996])),\n",
       "              ('encoder.layers.5.self_attn_layer_norm.bias',\n",
       "               tensor([ 0.0064, -0.0004,  0.0201,  ..., -0.0146, -0.0369,  0.0019])),\n",
       "              ('encoder.layers.5.fc1.weight',\n",
       "               tensor([[-0.0986, -0.1738,  0.2181,  ...,  0.2639,  0.0079, -0.2578],\n",
       "                       [-0.1256, -0.1367,  0.1054,  ...,  0.0949,  0.0355, -0.1321],\n",
       "                       [-0.1462, -0.0550, -0.0234,  ..., -0.1284,  0.0847,  0.1702],\n",
       "                       ...,\n",
       "                       [-0.0737,  0.2026,  0.1938,  ...,  0.1104,  0.0362,  0.2014],\n",
       "                       [ 0.1036,  0.0988, -0.0466,  ..., -0.0374,  0.1431, -0.1571],\n",
       "                       [ 0.0987,  0.1993,  0.0481,  ..., -0.1738,  0.0183,  0.1270]])),\n",
       "              ('encoder.layers.5.fc1.bias',\n",
       "               tensor([-0.0909, -0.1159, -0.0554,  ..., -0.0984, -0.1154, -0.1273])),\n",
       "              ('encoder.layers.5.fc2.weight',\n",
       "               tensor([[-0.1300,  0.0191,  0.1233,  ..., -0.3130,  0.2062, -0.1088],\n",
       "                       [-0.0628,  0.0787,  0.1549,  ...,  0.0051, -0.1704, -0.1794],\n",
       "                       [-0.1398,  0.0413,  0.1095,  ..., -0.0503,  0.1427,  0.0270],\n",
       "                       ...,\n",
       "                       [-0.0887, -0.0381,  0.0541,  ...,  0.1055,  0.0006, -0.0309],\n",
       "                       [ 0.1608,  0.1016,  0.0880,  ...,  0.0248,  0.0794,  0.0680],\n",
       "                       [ 0.1022,  0.1499,  0.1292,  ...,  0.1500, -0.0169,  0.0112]])),\n",
       "              ('encoder.layers.5.fc2.bias',\n",
       "               tensor([ 0.1808,  0.0145, -0.0579,  ...,  0.0530,  0.0258, -0.0641])),\n",
       "              ('encoder.layers.5.final_layer_norm.weight',\n",
       "               tensor([0.4780, 0.5190, 0.6270,  ..., 0.4763, 0.5005, 0.5410])),\n",
       "              ('encoder.layers.5.final_layer_norm.bias',\n",
       "               tensor([ 0.0208,  0.0215, -0.1504,  ..., -0.0178, -0.0218,  0.0138])),\n",
       "              ('encoder.layers.6.self_attn.k_proj.weight',\n",
       "               tensor([[-0.0044,  0.0484, -0.0370,  ..., -0.1130,  0.0380,  0.0526],\n",
       "                       [ 0.0185,  0.1704,  0.1477,  ..., -0.1227, -0.0041, -0.1412],\n",
       "                       [ 0.0251, -0.0160, -0.0333,  ...,  0.2299,  0.0843,  0.0321],\n",
       "                       ...,\n",
       "                       [-0.0018,  0.1549, -0.0900,  ..., -0.0880, -0.0847, -0.0073],\n",
       "                       [-0.1162,  0.0883, -0.0400,  ..., -0.0173,  0.0782, -0.1495],\n",
       "                       [ 0.1030, -0.1042,  0.1027,  ...,  0.0930, -0.1912,  0.0210]])),\n",
       "              ('encoder.layers.6.self_attn.k_proj.bias',\n",
       "               tensor([ 0.0081,  0.0088, -0.0018,  ...,  0.0231,  0.0068,  0.0104])),\n",
       "              ('encoder.layers.6.self_attn.v_proj.weight',\n",
       "               tensor([[ 8.7280e-02,  3.7292e-02, -2.8854e-02,  ...,  5.5206e-02,\n",
       "                        -1.5748e-04, -1.3428e-01],\n",
       "                       [ 2.9327e-02, -5.2704e-02, -1.8417e-02,  ..., -1.5063e-01,\n",
       "                         5.4260e-02,  2.8915e-02],\n",
       "                       [ 4.8889e-02, -1.4830e-04, -3.2501e-03,  ...,  1.8921e-02,\n",
       "                         1.0736e-01,  4.6417e-02],\n",
       "                       ...,\n",
       "                       [ 7.3059e-02,  1.8518e-01, -1.3440e-01,  ...,  1.0138e-01,\n",
       "                        -3.3813e-02,  1.0095e-01],\n",
       "                       [ 1.4197e-01,  1.8396e-01, -5.5046e-03,  ..., -1.6919e-01,\n",
       "                         1.0168e-01,  3.9581e-02],\n",
       "                       [ 9.8450e-02, -1.8970e-01, -4.9469e-02,  ..., -7.0839e-03,\n",
       "                        -2.8174e-01, -1.7432e-01]])),\n",
       "              ('encoder.layers.6.self_attn.v_proj.bias',\n",
       "               tensor([-0.0007, -0.0072, -0.0264,  ...,  0.0739, -0.0224, -0.0386])),\n",
       "              ('encoder.layers.6.self_attn.q_proj.weight',\n",
       "               tensor([[ 0.0406, -0.1777,  0.0612,  ...,  0.0558, -0.1705,  0.1359],\n",
       "                       [-0.1458, -0.0061, -0.0927,  ...,  0.0333, -0.0041, -0.0078],\n",
       "                       [-0.0372,  0.0310,  0.1625,  ..., -0.1481, -0.1270,  0.0113],\n",
       "                       ...,\n",
       "                       [ 0.1399, -0.0959, -0.1566,  ..., -0.0423, -0.0227, -0.0031],\n",
       "                       [-0.0325,  0.0873,  0.0035,  ..., -0.0933,  0.0478, -0.0530],\n",
       "                       [ 0.2581,  0.1578, -0.1177,  ...,  0.0414,  0.1680, -0.1279]])),\n",
       "              ('encoder.layers.6.self_attn.q_proj.bias',\n",
       "               tensor([-0.4358, -0.4683, -0.2223,  ..., -0.4307,  0.3855, -0.0149])),\n",
       "              ('encoder.layers.6.self_attn.out_proj.weight',\n",
       "               tensor([[ 0.0677,  0.1750,  0.0024,  ..., -0.5635,  0.3169, -0.3325],\n",
       "                       [-0.0857,  0.0661, -0.0367,  ...,  0.2654, -0.0245,  0.2512],\n",
       "                       [ 0.0406,  0.1780,  0.0555,  ..., -0.1752, -0.1844,  0.1202],\n",
       "                       ...,\n",
       "                       [-0.1143,  0.0542, -0.0023,  ..., -0.1381, -0.1771, -0.1466],\n",
       "                       [ 0.0432,  0.0399, -0.1459,  ...,  0.0217, -0.0794,  0.1201],\n",
       "                       [ 0.0569, -0.0802, -0.0690,  ...,  0.2947, -0.1736,  0.0688]])),\n",
       "              ('encoder.layers.6.self_attn.out_proj.bias',\n",
       "               tensor([ 0.1360,  0.0461, -0.0696,  ...,  0.0552, -0.0276, -0.0683])),\n",
       "              ('encoder.layers.6.self_attn_layer_norm.weight',\n",
       "               tensor([0.2974, 0.3599, 0.3303,  ..., 0.3777, 0.2917, 0.3071])),\n",
       "              ('encoder.layers.6.self_attn_layer_norm.bias',\n",
       "               tensor([ 0.0041, -0.0164,  0.0193,  ..., -0.0289, -0.0361, -0.0033])),\n",
       "              ('encoder.layers.6.fc1.weight',\n",
       "               tensor([[ 0.2128, -0.0550, -0.0656,  ...,  0.0616, -0.2222,  0.0070],\n",
       "                       [-0.2389, -0.2808,  0.0558,  ..., -0.1214, -0.0180, -0.0908],\n",
       "                       [ 0.1005, -0.3503,  0.1768,  ..., -0.1610,  0.1753, -0.0628],\n",
       "                       ...,\n",
       "                       [ 0.0221, -0.0914, -0.0081,  ...,  0.0736, -0.0083, -0.3062],\n",
       "                       [-0.0570, -0.1232,  0.0359,  ..., -0.1625, -0.0117, -0.0388],\n",
       "                       [ 0.1763,  0.1331, -0.0860,  ..., -0.1115,  0.2042,  0.0154]])),\n",
       "              ('encoder.layers.6.fc1.bias',\n",
       "               tensor([-0.0935, -0.0479, -0.0861,  ..., -0.0833, -0.0969, -0.1021])),\n",
       "              ('encoder.layers.6.fc2.weight',\n",
       "               tensor([[ 0.1317,  0.0517,  0.3337,  ...,  0.1881, -0.1523, -0.0737],\n",
       "                       [-0.0181, -0.0143,  0.0062,  ...,  0.1873,  0.0498, -0.0520],\n",
       "                       [ 0.1348,  0.0427, -0.0890,  ...,  0.1114,  0.1433,  0.0286],\n",
       "                       ...,\n",
       "                       [-0.2583, -0.0289, -0.1764,  ..., -0.0331,  0.1820, -0.0347],\n",
       "                       [ 0.1510,  0.1761,  0.0269,  ..., -0.1318, -0.0016,  0.0406],\n",
       "                       [ 0.0897, -0.1434, -0.0652,  ...,  0.0947, -0.0529, -0.1119]])),\n",
       "              ('encoder.layers.6.fc2.bias',\n",
       "               tensor([ 0.0955,  0.0221, -0.0035,  ...,  0.1018, -0.0482, -0.0174])),\n",
       "              ('encoder.layers.6.final_layer_norm.weight',\n",
       "               tensor([0.4841, 0.6274, 0.6968,  ..., 0.5713, 0.5391, 0.6060])),\n",
       "              ('encoder.layers.6.final_layer_norm.bias',\n",
       "               tensor([ 1.3292e-05,  7.0007e-02, -1.4307e-01,  ..., -3.0090e-02,\n",
       "                       -6.5186e-02, -9.0637e-03])),\n",
       "              ('encoder.layers.7.self_attn.k_proj.weight',\n",
       "               tensor([[ 0.0756, -0.0616, -0.0933,  ...,  0.0065,  0.1082, -0.1653],\n",
       "                       [-0.0878, -0.1016,  0.0416,  ...,  0.0848,  0.0912,  0.0612],\n",
       "                       [ 0.0145,  0.0061,  0.0597,  ...,  0.0212,  0.0414,  0.1943],\n",
       "                       ...,\n",
       "                       [-0.0727,  0.0056,  0.0250,  ...,  0.1705, -0.1382, -0.0276],\n",
       "                       [-0.2125, -0.0547, -0.0371,  ...,  0.0455, -0.1221, -0.0414],\n",
       "                       [-0.0168,  0.1124,  0.0375,  ...,  0.0857, -0.0377, -0.0383]])),\n",
       "              ('encoder.layers.7.self_attn.k_proj.bias',\n",
       "               tensor([ 0.0018,  0.0043,  0.0084,  ..., -0.0006, -0.0051,  0.0016])),\n",
       "              ('encoder.layers.7.self_attn.v_proj.weight',\n",
       "               tensor([[-0.0890,  0.0559,  0.1201,  ...,  0.1903, -0.0352, -0.0898],\n",
       "                       [ 0.1802, -0.0417,  0.0698,  ..., -0.0021, -0.0052,  0.0108],\n",
       "                       [ 0.2061, -0.0875,  0.0305,  ..., -0.0903, -0.1687,  0.0424],\n",
       "                       ...,\n",
       "                       [-0.1376,  0.1869,  0.1517,  ...,  0.2061,  0.0021,  0.1862],\n",
       "                       [ 0.2487, -0.2017, -0.0096,  ..., -0.2219, -0.1044, -0.1165],\n",
       "                       [ 0.0655,  0.0160, -0.1727,  ...,  0.0961,  0.1622, -0.2217]])),\n",
       "              ('encoder.layers.7.self_attn.v_proj.bias',\n",
       "               tensor([ 0.0110, -0.0208,  0.0209,  ..., -0.0029, -0.0324, -0.0133])),\n",
       "              ('encoder.layers.7.self_attn.q_proj.weight',\n",
       "               tensor([[ 0.1313,  0.1121, -0.0705,  ...,  0.1005, -0.0172, -0.1700],\n",
       "                       [-0.0885,  0.0708, -0.0082,  ...,  0.0011, -0.0351,  0.0361],\n",
       "                       [ 0.0779,  0.1171,  0.1035,  ...,  0.0238, -0.0742, -0.1375],\n",
       "                       ...,\n",
       "                       [-0.0122,  0.1183, -0.1754,  ..., -0.0867,  0.1687,  0.1279],\n",
       "                       [-0.1091,  0.1077,  0.0037,  ..., -0.1877, -0.1082, -0.0553],\n",
       "                       [-0.0748,  0.0837, -0.0612,  ..., -0.0318, -0.2379, -0.3879]])),\n",
       "              ('encoder.layers.7.self_attn.q_proj.bias',\n",
       "               tensor([-0.0963,  0.0442,  0.0548,  ..., -0.1423,  0.0151, -0.2369])),\n",
       "              ('encoder.layers.7.self_attn.out_proj.weight',\n",
       "               tensor([[ 0.0142,  0.0903,  0.0330,  ...,  0.0421, -0.3340, -0.2710],\n",
       "                       [ 0.0826, -0.0352, -0.1367,  ...,  0.0611,  0.2096,  0.0077],\n",
       "                       [-0.0382,  0.0834, -0.2423,  ..., -0.0972,  0.0436,  0.0032],\n",
       "                       ...,\n",
       "                       [ 0.0309,  0.0700,  0.1254,  ..., -0.2009,  0.0448,  0.0814],\n",
       "                       [-0.0787,  0.2247,  0.0285,  ..., -0.0147, -0.0097, -0.1691],\n",
       "                       [-0.0670, -0.0043, -0.0841,  ..., -0.2380, -0.0082, -0.1354]])),\n",
       "              ('encoder.layers.7.self_attn.out_proj.bias',\n",
       "               tensor([ 0.2698,  0.0856, -0.0589,  ...,  0.0457, -0.0274, -0.0800])),\n",
       "              ('encoder.layers.7.self_attn_layer_norm.weight',\n",
       "               tensor([0.2852, 0.3501, 0.3601,  ..., 0.4189, 0.3513, 0.3132])),\n",
       "              ('encoder.layers.7.self_attn_layer_norm.bias',\n",
       "               tensor([-0.0121, -0.0068,  0.0332,  ..., -0.0244, -0.0466, -0.0080])),\n",
       "              ('encoder.layers.7.fc1.weight',\n",
       "               tensor([[ 0.0896, -0.0214, -0.1105,  ..., -0.1078,  0.0410, -0.0818],\n",
       "                       [ 0.4224,  0.0427, -0.0671,  ..., -0.0172,  0.0798,  0.1433],\n",
       "                       [-0.1571, -0.0027,  0.0674,  ..., -0.1636,  0.0102,  0.0108],\n",
       "                       ...,\n",
       "                       [ 0.1582,  0.1821,  0.0181,  ...,  0.2944,  0.0015,  0.0235],\n",
       "                       [ 0.0891,  0.0946,  0.1091,  ..., -0.0656,  0.0021, -0.0468],\n",
       "                       [ 0.0203,  0.0039,  0.1193,  ..., -0.0896,  0.1663,  0.2421]])),\n",
       "              ('encoder.layers.7.fc1.bias',\n",
       "               tensor([-0.0415, -0.1405, -0.0606,  ..., -0.0756, -0.0828, -0.1135])),\n",
       "              ('encoder.layers.7.fc2.weight',\n",
       "               tensor([[ 0.5317,  0.3118,  0.1132,  ..., -0.0967, -0.1783, -0.1311],\n",
       "                       [ 0.0959,  0.3491,  0.0454,  ..., -0.1233, -0.1572,  0.2245],\n",
       "                       [-0.0267, -0.3684,  0.1295,  ..., -0.0559,  0.1276,  0.0078],\n",
       "                       ...,\n",
       "                       [ 0.0781,  0.0049, -0.1467,  ..., -0.1711, -0.0262, -0.1136],\n",
       "                       [ 0.0970, -0.1625,  0.1267,  ..., -0.0993,  0.1455,  0.1245],\n",
       "                       [-0.0984,  0.1617,  0.1063,  ..., -0.2664, -0.2578,  0.1953]])),\n",
       "              ('encoder.layers.7.fc2.bias',\n",
       "               tensor([ 0.1376,  0.0036,  0.0332,  ...,  0.0568,  0.0080, -0.0413])),\n",
       "              ('encoder.layers.7.final_layer_norm.weight',\n",
       "               tensor([0.4199, 0.7930, 0.8394,  ..., 0.7471, 0.6973, 0.7480])),\n",
       "              ('encoder.layers.7.final_layer_norm.bias',\n",
       "               tensor([-0.0371,  0.0863, -0.0720,  ..., -0.0345, -0.0307, -0.0592])),\n",
       "              ('encoder.layers.8.self_attn.k_proj.weight',\n",
       "               tensor([[ 0.0384,  0.0850, -0.0054,  ..., -0.0522, -0.1624,  0.0735],\n",
       "                       [-0.0414, -0.0227,  0.0362,  ..., -0.1343, -0.0356,  0.1814],\n",
       "                       [ 0.0160,  0.0134,  0.0032,  ...,  0.0604, -0.0857, -0.0297],\n",
       "                       ...,\n",
       "                       [ 0.1036, -0.0623, -0.1009,  ...,  0.0751, -0.1752, -0.0504],\n",
       "                       [ 0.2871,  0.0693,  0.1028,  ..., -0.0974, -0.1541, -0.0621],\n",
       "                       [ 0.0552, -0.0019, -0.0438,  ...,  0.0464, -0.0380,  0.1300]])),\n",
       "              ('encoder.layers.8.self_attn.k_proj.bias',\n",
       "               tensor([-0.0019, -0.0112, -0.0023,  ...,  0.0804,  0.0426, -0.0150])),\n",
       "              ('encoder.layers.8.self_attn.v_proj.weight',\n",
       "               tensor([[-0.1100, -0.0982,  0.0287,  ..., -0.2350, -0.0195, -0.0439],\n",
       "                       [ 0.0263, -0.1606, -0.0005,  ..., -0.0688, -0.0836, -0.0033],\n",
       "                       [ 0.1372,  0.0467, -0.0981,  ...,  0.0345,  0.0768,  0.0904],\n",
       "                       ...,\n",
       "                       [-0.0116,  0.1572, -0.1009,  ..., -0.0424, -0.0077,  0.0955],\n",
       "                       [-0.0783,  0.3660, -0.2401,  ...,  0.1759,  0.2908,  0.0158],\n",
       "                       [ 0.1388,  0.1281, -0.3049,  ...,  0.0184, -0.2260, -0.2656]])),\n",
       "              ('encoder.layers.8.self_attn.v_proj.bias',\n",
       "               tensor([ 0.0308,  0.0573, -0.0061,  ...,  0.0723, -0.1146,  0.0582])),\n",
       "              ('encoder.layers.8.self_attn.q_proj.weight',\n",
       "               tensor([[ 0.0017, -0.0613,  0.0307,  ..., -0.0911,  0.0940, -0.0024],\n",
       "                       [ 0.0189,  0.1027,  0.1184,  ..., -0.0314, -0.0720,  0.0464],\n",
       "                       [ 0.0289,  0.0026,  0.0876,  ...,  0.0692, -0.1656,  0.1484],\n",
       "                       ...,\n",
       "                       [ 0.0537,  0.0401,  0.1643,  ...,  0.1801,  0.0317,  0.0045],\n",
       "                       [-0.0352,  0.1913, -0.0493,  ...,  0.1197,  0.0709, -0.1039],\n",
       "                       [ 0.0793,  0.1848, -0.1421,  ..., -0.0385,  0.1022,  0.1092]])),\n",
       "              ('encoder.layers.8.self_attn.q_proj.bias',\n",
       "               tensor([ 0.0545, -0.2852, -0.1078,  ...,  0.1179,  0.1048,  0.2463])),\n",
       "              ('encoder.layers.8.self_attn.out_proj.weight',\n",
       "               tensor([[-2.8534e-02,  1.2781e-01,  2.2131e-01,  ..., -1.7380e-02,\n",
       "                        -2.0386e-01,  3.7378e-01],\n",
       "                       [ 7.7087e-02, -2.0015e-04, -1.1169e-01,  ..., -4.9866e-02,\n",
       "                        -2.5909e-02,  7.7209e-02],\n",
       "                       [-1.3550e-01,  4.8447e-03, -4.7974e-02,  ..., -1.0675e-01,\n",
       "                        -1.6406e-01,  3.0594e-02],\n",
       "                       ...,\n",
       "                       [ 2.0312e-01,  7.4341e-02, -8.4991e-03,  ..., -1.0718e-01,\n",
       "                         4.3884e-02,  6.7871e-02],\n",
       "                       [ 1.3159e-01,  1.1377e-01, -7.9712e-02,  ..., -1.2415e-01,\n",
       "                         4.8943e-03,  1.2244e-01],\n",
       "                       [ 1.2413e-02, -1.4819e-01,  6.6467e-02,  ...,  1.9214e-01,\n",
       "                         1.8115e-01,  2.2681e-01]])),\n",
       "              ('encoder.layers.8.self_attn.out_proj.bias',\n",
       "               tensor([ 0.3162,  0.0702, -0.1359,  ...,  0.0340,  0.0803, -0.1037])),\n",
       "              ('encoder.layers.8.self_attn_layer_norm.weight',\n",
       "               tensor([0.1979, 0.3696, 0.3660,  ..., 0.3928, 0.3176, 0.3308])),\n",
       "              ('encoder.layers.8.self_attn_layer_norm.bias',\n",
       "               tensor([-0.0359, -0.0133,  0.0519,  ..., -0.0389, -0.0531, -0.0008])),\n",
       "              ('encoder.layers.8.fc1.weight',\n",
       "               tensor([[ 0.1990, -0.0742,  0.1059,  ..., -0.1920,  0.2283, -0.0544],\n",
       "                       [ 0.2181, -0.1981, -0.0493,  ..., -0.1958,  0.1722, -0.0169],\n",
       "                       [-0.0494, -0.0403,  0.0401,  ..., -0.1114,  0.1782,  0.0547],\n",
       "                       ...,\n",
       "                       [-0.0220, -0.1527, -0.0291,  ...,  0.0357,  0.1700,  0.0778],\n",
       "                       [-0.0168, -0.1818, -0.0434,  ...,  0.0927,  0.0133,  0.2312],\n",
       "                       [-0.0431, -0.1594,  0.2355,  ...,  0.0992, -0.1299,  0.1201]])),\n",
       "              ('encoder.layers.8.fc1.bias',\n",
       "               tensor([-0.1013, -0.0800, -0.0831,  ..., -0.1622, -0.0051, -0.1006])),\n",
       "              ('encoder.layers.8.fc2.weight',\n",
       "               tensor([[-0.0264, -0.0208,  0.0923,  ...,  0.1315,  0.2744, -0.1508],\n",
       "                       [-0.3066,  0.0952,  0.3071,  ..., -0.3411,  0.1267,  0.0336],\n",
       "                       [-0.0344, -0.0128,  0.1736,  ..., -0.3574, -0.1270,  0.2001],\n",
       "                       ...,\n",
       "                       [-0.1367, -0.1265, -0.0807,  ...,  0.3635, -0.0191, -0.1812],\n",
       "                       [ 0.0612,  0.2842, -0.0178,  ..., -0.0812,  0.0751,  0.0795],\n",
       "                       [ 0.0801, -0.0558,  0.0610,  ..., -0.1382, -0.0544,  0.1776]])),\n",
       "              ('encoder.layers.8.fc2.bias',\n",
       "               tensor([-0.0046,  0.0905, -0.0868,  ...,  0.0674,  0.0467, -0.0749])),\n",
       "              ('encoder.layers.8.final_layer_norm.weight',\n",
       "               tensor([0.3230, 1.0312, 1.0479,  ..., 0.9653, 0.8398, 0.9795])),\n",
       "              ('encoder.layers.8.final_layer_norm.bias',\n",
       "               tensor([-0.1334,  0.0440,  0.0126,  ...,  0.0071, -0.0673, -0.1170])),\n",
       "              ('encoder.layers.9.self_attn.k_proj.weight',\n",
       "               tensor([[-0.1604,  0.0457, -0.0750,  ...,  0.1072,  0.0063, -0.0007],\n",
       "                       [ 0.3918, -0.0290, -0.1455,  ...,  0.0905, -0.2255, -0.0794],\n",
       "                       [ 0.0803,  0.0168,  0.0253,  ..., -0.1688,  0.0814,  0.1481],\n",
       "                       ...,\n",
       "                       [-0.1223, -0.0087, -0.1062,  ..., -0.0138, -0.1969, -0.0468],\n",
       "                       [ 0.0516,  0.0327, -0.0465,  ...,  0.1160, -0.1843, -0.0592],\n",
       "                       [ 0.3311, -0.0138, -0.0695,  ..., -0.1300, -0.0046, -0.1100]])),\n",
       "              ('encoder.layers.9.self_attn.k_proj.bias',\n",
       "               tensor([-0.0260,  0.0461,  0.0143,  ..., -0.0491, -0.0856, -0.0047])),\n",
       "              ('encoder.layers.9.self_attn.v_proj.weight',\n",
       "               tensor([[-0.0443,  0.1998, -0.1990,  ..., -0.0800,  0.1948,  0.0365],\n",
       "                       [ 0.0726,  0.0388,  0.0558,  ..., -0.1970,  0.3367, -0.1603],\n",
       "                       [-0.0668,  0.1326,  0.0686,  ...,  0.0694, -0.1300, -0.0784],\n",
       "                       ...,\n",
       "                       [ 0.3611, -0.0844, -0.0571,  ..., -0.3013,  0.2300,  0.3145],\n",
       "                       [ 0.1090, -0.4497, -0.1735,  ..., -0.1139, -0.1102, -0.2314],\n",
       "                       [ 0.1123,  0.1749, -0.2961,  ..., -0.0570,  0.1921, -0.0441]])),\n",
       "              ('encoder.layers.9.self_attn.v_proj.bias',\n",
       "               tensor([ 0.0117, -0.0192, -0.0439,  ...,  0.0687,  0.0981,  0.0124])),\n",
       "              ('encoder.layers.9.self_attn.q_proj.weight',\n",
       "               tensor([[-9.9548e-02, -2.4426e-01,  2.7527e-02,  ..., -4.2992e-03,\n",
       "                         2.3938e-01,  1.7737e-01],\n",
       "                       [ 4.1064e-01, -6.6223e-02, -6.0913e-02,  ..., -7.3425e-02,\n",
       "                         1.0352e-01, -4.6936e-02],\n",
       "                       [ 1.4551e-01, -2.2461e-02,  6.2500e-02,  ...,  9.7900e-02,\n",
       "                         1.1151e-01,  2.4673e-02],\n",
       "                       ...,\n",
       "                       [-2.3169e-01, -1.4929e-01, -1.2720e-01,  ..., -6.5735e-02,\n",
       "                         6.0822e-02,  4.8737e-02],\n",
       "                       [ 8.9172e-02, -3.5048e-04,  7.4341e-02,  ..., -5.1270e-02,\n",
       "                        -5.6244e-02,  1.8384e-01],\n",
       "                       [ 1.5698e-01, -7.6660e-02,  9.4421e-02,  ..., -1.7502e-02,\n",
       "                         5.7648e-02,  1.0323e-02]])),\n",
       "              ('encoder.layers.9.self_attn.q_proj.bias',\n",
       "               tensor([-0.1367, -0.0304, -0.2297,  ..., -0.3042, -0.1100,  0.0564])),\n",
       "              ('encoder.layers.9.self_attn.out_proj.weight',\n",
       "               tensor([[ 0.2588,  0.3518, -0.0445,  ...,  0.1309,  0.0780,  0.2159],\n",
       "                       [-0.0667,  0.0043, -0.2294,  ...,  0.0679, -0.1516,  0.0654],\n",
       "                       [-0.2167,  0.1141,  0.1672,  ..., -0.0845, -0.1945, -0.0952],\n",
       "                       ...,\n",
       "                       [-0.2571, -0.0328, -0.0325,  ...,  0.0794, -0.1101,  0.0767],\n",
       "                       [ 0.1100,  0.1552, -0.1289,  ..., -0.3081,  0.1669, -0.0951],\n",
       "                       [ 0.0986,  0.1262,  0.0373,  ...,  0.0648, -0.1825,  0.2100]])),\n",
       "              ('encoder.layers.9.self_attn.out_proj.bias',\n",
       "               tensor([ 0.2690,  0.0411, -0.0743,  ...,  0.0863,  0.0752, -0.0915])),\n",
       "              ('encoder.layers.9.self_attn_layer_norm.weight',\n",
       "               tensor([0.1755, 0.4163, 0.3870,  ..., 0.3906, 0.3494, 0.3384])),\n",
       "              ('encoder.layers.9.self_attn_layer_norm.bias',\n",
       "               tensor([-0.0840, -0.0198,  0.0451,  ..., -0.0436, -0.0385,  0.0150])),\n",
       "              ('encoder.layers.9.fc1.weight',\n",
       "               tensor([[-0.0435,  0.1008,  0.1602,  ...,  0.0629, -0.1683,  0.0706],\n",
       "                       [-0.2170,  0.0567, -0.0597,  ..., -0.3179,  0.0846, -0.0125],\n",
       "                       [ 0.1847,  0.0614, -0.0401,  ...,  0.0153, -0.2018, -0.0952],\n",
       "                       ...,\n",
       "                       [-0.0428, -0.0114,  0.3389,  ..., -0.0704, -0.0504, -0.1334],\n",
       "                       [ 0.1017,  0.3081, -0.0963,  ...,  0.0329,  0.1403, -0.0317],\n",
       "                       [-0.1459,  0.0880,  0.0910,  ..., -0.1481,  0.0338, -0.1075]])),\n",
       "              ('encoder.layers.9.fc1.bias',\n",
       "               tensor([-0.1132, -0.1248, -0.0701,  ..., -0.0189, -0.1378, -0.1188])),\n",
       "              ('encoder.layers.9.fc2.weight',\n",
       "               tensor([[-0.1481,  0.5015,  0.0317,  ...,  0.0389, -0.1210,  0.0309],\n",
       "                       [-0.3157, -0.0451,  0.2189,  ...,  0.0193, -0.1776, -0.0809],\n",
       "                       [-0.1826,  0.1037, -0.0287,  ..., -0.0654,  0.1013,  0.0358],\n",
       "                       ...,\n",
       "                       [ 0.0638,  0.1070, -0.0453,  ...,  0.0408,  0.1870,  0.1125],\n",
       "                       [-0.1129,  0.0414,  0.0533,  ..., -0.0429,  0.0734,  0.2927],\n",
       "                       [-0.1460, -0.1689, -0.1774,  ...,  0.1155, -0.1219,  0.2866]])),\n",
       "              ('encoder.layers.9.fc2.bias',\n",
       "               tensor([ 0.2141,  0.1255, -0.1216,  ...,  0.1130,  0.0320, -0.1016])),\n",
       "              ('encoder.layers.9.final_layer_norm.weight',\n",
       "               tensor([0.1259, 1.3535, 1.4277,  ..., 1.2441, 1.1533, 1.3555])),\n",
       "              ('encoder.layers.9.final_layer_norm.bias',\n",
       "               tensor([-0.0754,  0.0643,  0.0844,  ...,  0.0576,  0.0456, -0.2544])),\n",
       "              ('encoder.layers.10.self_attn.k_proj.weight',\n",
       "               tensor([[-1.4172e-01, -1.5784e-01, -9.8389e-02,  ...,  1.3379e-01,\n",
       "                        -1.4722e-01,  6.9397e-02],\n",
       "                       [ 4.2084e-02,  5.5115e-02,  2.5406e-02,  ...,  7.1106e-02,\n",
       "                         3.2135e-02, -5.1819e-02],\n",
       "                       [ 3.6621e-02,  1.1597e-01,  8.3780e-04,  ..., -4.5410e-02,\n",
       "                         1.6327e-02, -1.0352e-01],\n",
       "                       ...,\n",
       "                       [ 6.6711e-02,  8.0261e-03, -1.1208e-02,  ..., -1.4441e-01,\n",
       "                        -7.4646e-02, -3.8055e-02],\n",
       "                       [ 1.3770e-01,  2.4963e-01, -7.8613e-02,  ..., -2.3804e-02,\n",
       "                         2.2827e-02, -3.0371e-01],\n",
       "                       [ 1.3477e-01, -1.0553e-01, -6.5002e-02,  ...,  3.3319e-05,\n",
       "                         5.6427e-02, -2.9373e-02]])),\n",
       "              ('encoder.layers.10.self_attn.k_proj.bias',\n",
       "               tensor([-0.0109, -0.0048, -0.0255,  ..., -0.0009,  0.0116, -0.0067])),\n",
       "              ('encoder.layers.10.self_attn.v_proj.weight',\n",
       "               tensor([[ 0.1040,  0.0090,  0.0130,  ..., -0.2805, -0.1418,  0.0380],\n",
       "                       [ 0.0083,  0.0284, -0.0656,  ...,  0.1439,  0.0913, -0.1611],\n",
       "                       [-0.0335,  0.0260, -0.2329,  ..., -0.2639,  0.0118,  0.2200],\n",
       "                       ...,\n",
       "                       [ 0.1516, -0.1985,  0.0247,  ...,  0.0930, -0.2219,  0.1017],\n",
       "                       [-0.0607,  0.2084, -0.0231,  ...,  0.2251,  0.0095,  0.1252],\n",
       "                       [ 0.0262, -0.0062, -0.0955,  ..., -0.0368, -0.0576, -0.1071]])),\n",
       "              ('encoder.layers.10.self_attn.v_proj.bias',\n",
       "               tensor([-0.0235,  0.0483,  0.0542,  ..., -0.0459,  0.0247, -0.0501])),\n",
       "              ('encoder.layers.10.self_attn.q_proj.weight',\n",
       "               tensor([[ 0.1175,  0.0464, -0.0373,  ..., -0.2908,  0.0754,  0.0018],\n",
       "                       [-0.0637,  0.0230, -0.0278,  ...,  0.0864,  0.2069, -0.0586],\n",
       "                       [-0.0830,  0.0058,  0.2588,  ...,  0.0618,  0.0710, -0.0014],\n",
       "                       ...,\n",
       "                       [ 0.1181,  0.0070, -0.0286,  ..., -0.0423,  0.0007,  0.0323],\n",
       "                       [-0.0640,  0.1766,  0.2135,  ..., -0.0682, -0.0354,  0.0438],\n",
       "                       [ 0.1492, -0.1180, -0.0335,  ...,  0.0583,  0.0723, -0.0088]])),\n",
       "              ('encoder.layers.10.self_attn.q_proj.bias',\n",
       "               tensor([-0.4880, -0.1641,  0.1195,  ...,  0.0897,  0.0518, -0.0795])),\n",
       "              ('encoder.layers.10.self_attn.out_proj.weight',\n",
       "               tensor([[-0.2489, -0.0095,  0.2710,  ..., -0.2397, -0.2379,  0.3521],\n",
       "                       [ 0.0842, -0.1576,  0.0012,  ...,  0.3577,  0.1948, -0.0554],\n",
       "                       [ 0.1010,  0.0119,  0.1697,  ..., -0.2661,  0.0860, -0.1373],\n",
       "                       ...,\n",
       "                       [-0.4546, -0.1199,  0.1572,  ..., -0.0252,  0.1469, -0.0239],\n",
       "                       [-0.3254,  0.1206, -0.5791,  ..., -0.0313, -0.1270,  0.0042],\n",
       "                       [ 0.1747, -0.1901,  0.1273,  ...,  0.4514, -0.1304,  0.2573]])),\n",
       "              ('encoder.layers.10.self_attn.out_proj.bias',\n",
       "               tensor([ 0.2023,  0.0978, -0.0988,  ...,  0.1382,  0.0637, -0.2196])),\n",
       "              ('encoder.layers.10.self_attn_layer_norm.weight',\n",
       "               tensor([0.0829, 0.4302, 0.4670,  ..., 0.4221, 0.3474, 0.3672])),\n",
       "              ('encoder.layers.10.self_attn_layer_norm.bias',\n",
       "               tensor([-0.0403, -0.0269,  0.0580,  ..., -0.0566, -0.0467,  0.0094])),\n",
       "              ('encoder.layers.10.fc1.weight',\n",
       "               tensor([[ 0.0987,  0.0122, -0.2264,  ...,  0.1661, -0.3040, -0.0769],\n",
       "                       [ 0.1526, -0.1573,  0.0937,  ..., -0.1873, -0.2013,  0.0238],\n",
       "                       [-0.0130, -0.2917, -0.2603,  ...,  0.0733, -0.3025,  0.1910],\n",
       "                       ...,\n",
       "                       [-0.1124,  0.0635,  0.0482,  ..., -0.0825,  0.0933, -0.0396],\n",
       "                       [-0.1626, -0.0476, -0.0710,  ..., -0.1041,  0.4983,  0.0264],\n",
       "                       [-0.1191, -0.2163,  0.3438,  ...,  0.0831,  0.0481, -0.0801]])),\n",
       "              ('encoder.layers.10.fc1.bias',\n",
       "               tensor([-0.1443, -0.1041, -0.1550,  ..., -0.0577, -0.1731, -0.0271])),\n",
       "              ('encoder.layers.10.fc2.weight',\n",
       "               tensor([[ 0.2393,  0.0613,  0.4128,  ..., -0.0970,  0.3621,  0.0591],\n",
       "                       [ 0.0313, -0.0329, -0.1450,  ...,  0.0570, -0.1791,  0.0894],\n",
       "                       [-0.1276,  0.0091, -0.0384,  ..., -0.1290,  0.0921, -0.3860],\n",
       "                       ...,\n",
       "                       [ 0.0695, -0.0620, -0.0228,  ..., -0.1317,  0.0836, -0.0608],\n",
       "                       [-0.1156,  0.2083, -0.0410,  ...,  0.0911, -0.0511,  0.0643],\n",
       "                       [ 0.0237, -0.0151, -0.0675,  ..., -0.2346, -0.1798,  0.0671]])),\n",
       "              ('encoder.layers.10.fc2.bias',\n",
       "               tensor([ 0.0502,  0.1647, -0.2064,  ...,  0.0737,  0.0656, -0.0867])),\n",
       "              ('encoder.layers.10.final_layer_norm.weight',\n",
       "               tensor([0.2296, 1.5332, 1.5957,  ..., 1.4824, 1.3340, 1.5859])),\n",
       "              ('encoder.layers.10.final_layer_norm.bias',\n",
       "               tensor([-0.0842, -0.0724,  0.0850,  ...,  0.0622,  0.0514, -0.2786])),\n",
       "              ('encoder.layers.11.self_attn.k_proj.weight',\n",
       "               tensor([[ 0.1029, -0.0238, -0.0326,  ...,  0.1163,  0.0111, -0.0377],\n",
       "                       [ 0.0121, -0.0293, -0.0172,  ..., -0.0769,  0.0518,  0.0585],\n",
       "                       [-0.1650, -0.1393,  0.0342,  ..., -0.0572, -0.0649, -0.1051],\n",
       "                       ...,\n",
       "                       [ 0.0818,  0.0862, -0.0108,  ..., -0.0856, -0.1124,  0.0177],\n",
       "                       [ 0.0320,  0.0956,  0.1171,  ...,  0.0450, -0.1283,  0.2595],\n",
       "                       [ 0.0176,  0.0179,  0.0919,  ..., -0.0259, -0.0640,  0.0285]])),\n",
       "              ('encoder.layers.11.self_attn.k_proj.bias',\n",
       "               tensor([-0.0155, -0.0269,  0.0614,  ..., -0.0281, -0.0114,  0.0147])),\n",
       "              ('encoder.layers.11.self_attn.v_proj.weight',\n",
       "               tensor([[-0.0512,  0.1725, -0.1492,  ..., -0.0138,  0.0501,  0.2864],\n",
       "                       [ 0.1896,  0.0883,  0.1030,  ..., -0.1335, -0.0630, -0.0847],\n",
       "                       [ 0.1071,  0.0371, -0.2722,  ...,  0.1471,  0.1670,  0.4492],\n",
       "                       ...,\n",
       "                       [-0.0715,  0.2175, -0.2375,  ...,  0.0795,  0.2197, -0.2661],\n",
       "                       [-0.0500,  0.0886,  0.0552,  ..., -0.0260,  0.1721, -0.0033],\n",
       "                       [-0.1212, -0.0061, -0.2172,  ...,  0.0234,  0.2245,  0.0155]])),\n",
       "              ('encoder.layers.11.self_attn.v_proj.bias',\n",
       "               tensor([-0.0491, -0.0732, -0.0696,  ..., -0.1003,  0.0222, -0.0050])),\n",
       "              ('encoder.layers.11.self_attn.q_proj.weight',\n",
       "               tensor([[ 0.0178,  0.0574, -0.1978,  ...,  0.0532,  0.0656,  0.0273],\n",
       "                       [-0.0038, -0.0697,  0.0770,  ...,  0.0381,  0.0828, -0.0022],\n",
       "                       [-0.0521, -0.0981,  0.0456,  ...,  0.0364,  0.1208, -0.1103],\n",
       "                       ...,\n",
       "                       [ 0.1724, -0.0590, -0.0973,  ..., -0.1766, -0.0674,  0.0887],\n",
       "                       [-0.2029,  0.0519,  0.0642,  ...,  0.1400,  0.0107,  0.0209],\n",
       "                       [ 0.2218,  0.1729, -0.0488,  ...,  0.0428,  0.0687, -0.0792]])),\n",
       "              ('encoder.layers.11.self_attn.q_proj.bias',\n",
       "               tensor([ 0.0867,  0.0104,  0.2255,  ..., -0.2664,  0.2155,  0.0536])),\n",
       "              ('encoder.layers.11.self_attn.out_proj.weight',\n",
       "               tensor([[-0.2344,  0.2458, -0.2898,  ..., -0.3855,  0.3572,  0.2231],\n",
       "                       [-0.1248, -0.0674, -0.1794,  ..., -0.0243, -0.2484,  0.2162],\n",
       "                       [ 0.1437, -0.0873,  0.1167,  ...,  0.1713, -0.0075,  0.0679],\n",
       "                       ...,\n",
       "                       [ 0.1290,  0.1139, -0.1226,  ...,  0.0137, -0.0135,  0.1232],\n",
       "                       [-0.0629,  0.2129, -0.1051,  ..., -0.0916, -0.2354, -0.3237],\n",
       "                       [-0.2296, -0.1093, -0.4255,  ...,  0.0357,  0.0591,  0.0118]])),\n",
       "              ('encoder.layers.11.self_attn.out_proj.bias',\n",
       "               tensor([ 0.1062,  0.0336, -0.0463,  ...,  0.0589,  0.0517, -0.0897])),\n",
       "              ('encoder.layers.11.self_attn_layer_norm.weight',\n",
       "               tensor([0.0988, 0.4365, 0.4016,  ..., 0.4280, 0.3508, 0.4338])),\n",
       "              ('encoder.layers.11.self_attn_layer_norm.bias',\n",
       "               tensor([-0.1159, -0.0198,  0.0330,  ..., -0.0422, -0.0415,  0.0002])),\n",
       "              ('encoder.layers.11.fc1.weight',\n",
       "               tensor([[-0.2310, -0.1462,  0.2173,  ...,  0.1209, -0.1306,  0.1431],\n",
       "                       [ 0.0299,  0.1729, -0.1316,  ..., -0.0734, -0.1874,  0.2708],\n",
       "                       [-0.0826, -0.1355,  0.1459,  ..., -0.0665,  0.0159, -0.1000],\n",
       "                       ...,\n",
       "                       [ 0.1118,  0.0613, -0.2026,  ...,  0.0143,  0.0321, -0.1769],\n",
       "                       [ 0.0367,  0.1570,  0.2583,  ..., -0.1393, -0.0048,  0.4087],\n",
       "                       [-0.0399, -0.0951, -0.1504,  ..., -0.2061, -0.0227,  0.0311]])),\n",
       "              ('encoder.layers.11.fc1.bias',\n",
       "               tensor([-0.1265, -0.1445, -0.0648,  ..., -0.0646, -0.1647, -0.1137])),\n",
       "              ('encoder.layers.11.fc2.weight',\n",
       "               tensor([[-5.6824e-02,  1.4709e-01,  1.3904e-01,  ...,  3.3142e-02,\n",
       "                         1.5515e-01,  1.7090e-01],\n",
       "                       [ 2.4231e-02,  4.0955e-02,  1.3672e-01,  ..., -4.2773e-01,\n",
       "                         1.0376e-01,  5.9692e-02],\n",
       "                       [ 3.1877e-04,  1.4824e-02,  1.0522e-01,  ..., -2.0828e-02,\n",
       "                        -3.4497e-01,  7.2144e-02],\n",
       "                       ...,\n",
       "                       [-4.4281e-02, -1.2744e-01,  9.8938e-02,  ...,  8.9600e-02,\n",
       "                         1.8262e-01, -8.8196e-02],\n",
       "                       [ 2.1899e-01, -2.3403e-03,  1.1145e-01,  ...,  1.1499e-01,\n",
       "                         1.5918e-01,  7.2083e-02],\n",
       "                       [-1.4954e-01,  3.5132e-01, -1.0208e-02,  ...,  3.4619e-01,\n",
       "                         4.6936e-02,  3.3478e-02]])),\n",
       "              ('encoder.layers.11.fc2.bias',\n",
       "               tensor([-0.3894, -0.0792, -0.0214,  ...,  0.1641,  0.0442,  0.1182])),\n",
       "              ('encoder.layers.11.final_layer_norm.weight',\n",
       "               tensor([0.2717, 1.3027, 1.2861,  ..., 1.3271, 1.0723, 1.2998])),\n",
       "              ('encoder.layers.11.final_layer_norm.bias',\n",
       "               tensor([-0.0137, -0.0555,  0.0578,  ...,  0.0854, -0.0468, -0.1837])),\n",
       "              ('encoder.layer_norm.weight',\n",
       "               tensor([0.0406, 0.2947, 0.3005,  ..., 0.3037, 0.2568, 0.2729])),\n",
       "              ('encoder.layer_norm.bias',\n",
       "               tensor([-3.5614e-02, -1.3412e-02,  1.8997e-02,  ..., -9.7351e-03,\n",
       "                       -1.7517e-02,  3.2961e-05])),\n",
       "              ('decoder.version', tensor([3.])),\n",
       "              ('decoder.embed_tokens.weight',\n",
       "               tensor([[-2.7542e-03, -6.4964e-03, -4.6921e-03,  ..., -3.9246e-02,\n",
       "                        -6.2714e-03, -3.5461e-02],\n",
       "                       [ 1.9897e-02, -2.8782e-03,  6.2823e-05,  ..., -3.4149e-02,\n",
       "                        -2.8900e-02, -1.1429e-02],\n",
       "                       [ 2.3499e-03,  1.6083e-02, -3.1586e-02,  ...,  5.2490e-02,\n",
       "                        -1.6565e-01,  6.2927e-02],\n",
       "                       ...,\n",
       "                       [-1.9388e-03,  7.3853e-03, -1.0155e-02,  ..., -4.6844e-03,\n",
       "                        -4.4891e-02, -3.9673e-03],\n",
       "                       [-1.6541e-02,  7.1573e-04, -1.6661e-03,  ..., -3.8483e-02,\n",
       "                        -1.0849e-02, -1.2779e-02],\n",
       "                       [ 7.7477e-03, -3.5492e-02, -3.5736e-02,  ..., -4.9561e-02,\n",
       "                        -1.4519e-02,  4.3068e-03]])),\n",
       "              ('decoder.embed_positions._float_tensor', tensor([0.])),\n",
       "              ('decoder.layers.0.self_attn.k_proj.weight',\n",
       "               tensor([[-0.1884, -0.0813, -0.0274,  ..., -0.0836, -0.0897,  0.1476],\n",
       "                       [ 0.2644,  0.1331,  0.0779,  ..., -0.1771,  0.0789, -0.1497],\n",
       "                       [-0.0646,  0.1522,  0.2605,  ...,  0.2610, -0.0815,  0.1774],\n",
       "                       ...,\n",
       "                       [-0.5122,  0.1174, -0.0977,  ...,  0.1818, -0.0939,  0.0891],\n",
       "                       [-0.0472,  0.1392,  0.2186,  ..., -0.0366, -0.0805,  0.1194],\n",
       "                       [-0.1733,  0.1260, -0.2169,  ..., -0.0390,  0.0593,  0.0171]])),\n",
       "              ('decoder.layers.0.self_attn.k_proj.bias',\n",
       "               tensor([ 0.0098,  0.0121,  0.0431,  ..., -0.0423,  0.0228,  0.0875])),\n",
       "              ('decoder.layers.0.self_attn.v_proj.weight',\n",
       "               tensor([[-0.0184, -0.0239, -0.0356,  ...,  0.1786,  0.1572,  0.1097],\n",
       "                       [-0.0074,  0.0485, -0.3279,  ..., -0.2072, -0.1492, -0.0670],\n",
       "                       [ 0.0008, -0.1720, -0.0291,  ..., -0.0825, -0.0852,  0.1407],\n",
       "                       ...,\n",
       "                       [ 0.0051, -0.1235,  0.0261,  ...,  0.1566, -0.2448, -0.0466],\n",
       "                       [-0.0132, -0.2761,  0.0030,  ..., -0.0329,  0.0665,  0.1078],\n",
       "                       [ 0.0129,  0.0307, -0.1573,  ..., -0.0047, -0.0806,  0.0245]])),\n",
       "              ('decoder.layers.0.self_attn.v_proj.bias',\n",
       "               tensor([ 0.0506, -0.0442, -0.1373,  ..., -0.0082, -0.0300, -0.0471])),\n",
       "              ('decoder.layers.0.self_attn.q_proj.weight',\n",
       "               tensor([[-0.0713, -0.2234,  0.0379,  ..., -0.1329,  0.0540,  0.2661],\n",
       "                       [ 0.2419,  0.0764,  0.0729,  ..., -0.1018,  0.2830, -0.1466],\n",
       "                       [-0.0275, -0.0494,  0.1420,  ...,  0.1892, -0.0758,  0.2893],\n",
       "                       ...,\n",
       "                       [ 0.1685, -0.0818, -0.1545,  ..., -0.1260, -0.0643,  0.0405],\n",
       "                       [-0.1340,  0.0316, -0.0699,  ..., -0.0376,  0.0088,  0.0716],\n",
       "                       [-0.2798, -0.0385, -0.0248,  ..., -0.1088, -0.0682,  0.3401]])),\n",
       "              ('decoder.layers.0.self_attn.q_proj.bias',\n",
       "               tensor([-0.1830, -0.1039,  0.0362,  ...,  0.0502,  0.0806, -0.2593])),\n",
       "              ('decoder.layers.0.self_attn.out_proj.weight',\n",
       "               tensor([[ 0.0449,  0.1488,  0.0100,  ...,  0.0943, -0.0180,  0.1547],\n",
       "                       [-0.0895, -0.0169,  0.2440,  ..., -0.1216, -0.1627, -0.1038],\n",
       "                       [-0.0278,  0.0901, -0.0074,  ...,  0.0121,  0.0412, -0.1011],\n",
       "                       ...,\n",
       "                       [-0.0916,  0.1403,  0.0931,  ...,  0.0102,  0.0386,  0.0385],\n",
       "                       [-0.0635,  0.0454,  0.1416,  ..., -0.0126,  0.2034,  0.1277],\n",
       "                       [-0.0943, -0.0196,  0.1044,  ...,  0.1321, -0.0446,  0.0416]])),\n",
       "              ('decoder.layers.0.self_attn.out_proj.bias',\n",
       "               tensor([-0.0958, -0.0506,  0.1450,  ...,  0.0942,  0.0858,  0.1074])),\n",
       "              ('decoder.layers.0.self_attn_layer_norm.weight',\n",
       "               tensor([2.0449, 0.0992, 0.0999,  ..., 0.1263, 0.1141, 0.1156])),\n",
       "              ('decoder.layers.0.self_attn_layer_norm.bias',\n",
       "               tensor([ 0.0573,  0.0020,  0.0062,  ..., -0.0048, -0.0094, -0.0057])),\n",
       "              ('decoder.layers.0.encoder_attn.k_proj.weight',\n",
       "               tensor([[ 0.3591, -0.1187, -0.0152,  ...,  0.1333, -0.1057, -0.0894],\n",
       "                       [-0.0407, -0.1559, -0.1412,  ..., -0.0247,  0.2527, -0.2065],\n",
       "                       [ 0.2247, -0.1790, -0.1091,  ..., -0.0127, -0.0398,  0.0192],\n",
       "                       ...,\n",
       "                       [-0.0445,  0.0745, -0.0707,  ..., -0.0535, -0.0652, -0.0501],\n",
       "                       [-0.0489,  0.0774, -0.1097,  ...,  0.0028,  0.0128, -0.1542],\n",
       "                       [ 0.1310, -0.0506,  0.0764,  ..., -0.0250,  0.0575,  0.2080]])),\n",
       "              ('decoder.layers.0.encoder_attn.k_proj.bias',\n",
       "               tensor([-0.0120, -0.0282,  0.0038,  ...,  0.0036, -0.0048, -0.0021])),\n",
       "              ('decoder.layers.0.encoder_attn.v_proj.weight',\n",
       "               tensor([[-0.0253,  0.1725, -0.0082,  ..., -0.0236, -0.0626, -0.0743],\n",
       "                       [-0.0726,  0.0589,  0.0244,  ...,  0.0801,  0.0582, -0.0431],\n",
       "                       [ 0.0139,  0.0302, -0.0134,  ..., -0.0012,  0.0197, -0.0646],\n",
       "                       ...,\n",
       "                       [ 0.0176,  0.0274, -0.1133,  ...,  0.1432,  0.1311, -0.0447],\n",
       "                       [-0.0211,  0.0893,  0.0885,  ...,  0.1575, -0.2891,  0.0741],\n",
       "                       [ 0.0577,  0.0848, -0.0304,  ...,  0.0470,  0.0553,  0.0632]])),\n",
       "              ('decoder.layers.0.encoder_attn.v_proj.bias',\n",
       "               tensor([-0.0134,  0.0278,  0.0279,  ...,  0.0004, -0.0210, -0.0790])),\n",
       "              ('decoder.layers.0.encoder_attn.q_proj.weight',\n",
       "               tensor([[-0.1013, -0.2191,  0.1204,  ..., -0.0378, -0.1965, -0.2505],\n",
       "                       [-0.0204, -0.0682, -0.0603,  ...,  0.1624, -0.0766, -0.0093],\n",
       "                       [ 0.1053, -0.0288,  0.1917,  ...,  0.1127,  0.1221,  0.0072],\n",
       "                       ...,\n",
       "                       [ 0.0191,  0.0457,  0.0692,  ...,  0.0268, -0.1641,  0.0185],\n",
       "                       [-0.1292,  0.0946,  0.1091,  ..., -0.0806,  0.1877,  0.0334],\n",
       "                       [ 0.2510, -0.1149, -0.1575,  ...,  0.1851,  0.0951,  0.0012]])),\n",
       "              ('decoder.layers.0.encoder_attn.q_proj.bias',\n",
       "               tensor([-0.0329,  0.0302, -0.0312,  ...,  0.0140, -0.0137, -0.0281])),\n",
       "              ('decoder.layers.0.encoder_attn.out_proj.weight',\n",
       "               tensor([[ 0.0105, -0.1368, -0.2739,  ..., -0.1750, -0.0252,  0.0195],\n",
       "                       [-0.0113, -0.0215, -0.1187,  ...,  0.1175,  0.0402,  0.0013],\n",
       "                       [-0.0431,  0.0051,  0.0952,  ..., -0.0748, -0.0913,  0.1019],\n",
       "                       ...,\n",
       "                       [ 0.1131, -0.1256, -0.0677,  ...,  0.0437,  0.0665,  0.0217],\n",
       "                       [-0.0800,  0.0214, -0.0188,  ...,  0.1519,  0.0126,  0.0364],\n",
       "                       [ 0.0706, -0.0012,  0.0685,  ..., -0.1107,  0.0401, -0.0576]])),\n",
       "              ('decoder.layers.0.encoder_attn.out_proj.bias',\n",
       "               tensor([-0.0170, -0.0841, -0.2871,  ...,  0.2563,  0.0961,  0.1442])),\n",
       "              ('decoder.layers.0.encoder_attn_layer_norm.weight',\n",
       "               tensor([0.8682, 0.4331, 0.5127,  ..., 0.5356, 0.5239, 0.5322])),\n",
       "              ('decoder.layers.0.encoder_attn_layer_norm.bias',\n",
       "               tensor([-0.0252, -0.0518, -0.0534,  ..., -0.0337, -0.0839, -0.0292])),\n",
       "              ('decoder.layers.0.fc1.weight',\n",
       "               tensor([[ 0.0725,  0.0558,  0.2576,  ..., -0.1703,  0.1196, -0.1252],\n",
       "                       [ 0.2610, -0.2539,  0.0559,  ...,  0.1305, -0.1587,  0.0044],\n",
       "                       [ 0.1475, -0.0756,  0.0277,  ..., -0.2869,  0.0864, -0.0562],\n",
       "                       ...,\n",
       "                       [-0.1985, -0.2568,  0.0998,  ...,  0.0147, -0.0792, -0.0674],\n",
       "                       [ 0.0584, -0.1448,  0.0361,  ..., -0.0978, -0.2007,  0.0391],\n",
       "                       [ 0.1089,  0.1271, -0.0210,  ..., -0.0279, -0.0012, -0.0349]])),\n",
       "              ('decoder.layers.0.fc1.bias',\n",
       "               tensor([ 0.0224, -0.2040, -0.0239,  ...,  0.0007, -0.2415, -0.1191])),\n",
       "              ('decoder.layers.0.fc2.weight',\n",
       "               tensor([[-1.0492e-01, -4.4342e-02, -1.0773e-01,  ...,  1.2286e-01,\n",
       "                        -1.3135e-01, -8.0383e-02],\n",
       "                       [-1.6919e-01,  1.5222e-01,  8.3069e-02,  ...,  2.6025e-01,\n",
       "                        -7.1602e-03, -1.6113e-01],\n",
       "                       [-2.7051e-01, -3.7720e-02, -1.5087e-03,  ..., -5.9357e-02,\n",
       "                        -1.2952e-01, -2.6230e-02],\n",
       "                       ...,\n",
       "                       [ 2.6172e-01,  1.9067e-01,  1.3452e-01,  ..., -2.3520e-04,\n",
       "                        -1.2354e-01, -6.4941e-02],\n",
       "                       [-1.4490e-01, -2.2354e-02, -1.5393e-01,  ...,  9.4666e-02,\n",
       "                         7.0190e-02,  4.0039e-02],\n",
       "                       [ 9.2896e-02, -7.2327e-02, -3.0457e-02,  ...,  7.0923e-02,\n",
       "                         1.0504e-01,  4.5410e-02]])),\n",
       "              ('decoder.layers.0.fc2.bias',\n",
       "               tensor([ 0.0479,  0.0408, -0.0618,  ...,  0.2615,  0.2001,  0.1846])),\n",
       "              ('decoder.layers.0.final_layer_norm.weight',\n",
       "               tensor([0.4192, 0.2783, 0.3154,  ..., 0.3955, 0.3564, 0.3606])),\n",
       "              ('decoder.layers.0.final_layer_norm.bias',\n",
       "               tensor([0.0030, 0.0131, 0.0149,  ..., 0.0214, 0.0306, 0.0275])),\n",
       "              ('decoder.layers.1.self_attn.k_proj.weight',\n",
       "               tensor([[-0.0344,  0.0956, -0.0731,  ..., -0.0225,  0.0134, -0.2001],\n",
       "                       [-0.1119,  0.0029, -0.0941,  ..., -0.1417, -0.0867,  0.1821],\n",
       "                       [-0.1866,  0.1085,  0.1493,  ...,  0.0219,  0.0421, -0.1479],\n",
       "                       ...,\n",
       "                       [ 0.0478, -0.0363, -0.1848,  ..., -0.0353,  0.0236, -0.0343],\n",
       "                       [-0.0558,  0.0912,  0.2430,  ..., -0.1322,  0.0931, -0.1068],\n",
       "                       [-0.0895, -0.1520, -0.0066,  ...,  0.0450, -0.0797,  0.2109]])),\n",
       "              ('decoder.layers.1.self_attn.k_proj.bias',\n",
       "               tensor([-0.0618,  0.0173, -0.0019,  ..., -0.0382,  0.0115, -0.0826])),\n",
       "              ('decoder.layers.1.self_attn.v_proj.weight',\n",
       "               tensor([[-0.0916,  0.1432,  0.0825,  ..., -0.1604, -0.0828, -0.0158],\n",
       "                       [-0.2216,  0.0501,  0.0868,  ..., -0.0504, -0.1088,  0.1317],\n",
       "                       [ 0.0634, -0.0354,  0.3496,  ..., -0.0514,  0.0514,  0.0919],\n",
       "                       ...,\n",
       "                       [-0.1831,  0.1466, -0.0532,  ...,  0.0593, -0.0035, -0.0668],\n",
       "                       [ 0.0445, -0.0893, -0.3069,  ..., -0.1823,  0.0055, -0.0756],\n",
       "                       [ 0.0578, -0.0419, -0.0259,  ...,  0.1790, -0.0484, -0.1283]])),\n",
       "              ('decoder.layers.1.self_attn.v_proj.bias',\n",
       "               tensor([-0.0038, -0.0162,  0.0268,  ...,  0.0424,  0.0135,  0.0265])),\n",
       "              ('decoder.layers.1.self_attn.q_proj.weight',\n",
       "               tensor([[ 0.3418, -0.0194, -0.1351,  ..., -0.0401, -0.1064, -0.0913],\n",
       "                       [ 0.2264,  0.1433,  0.2031,  ...,  0.0048,  0.0393,  0.1432],\n",
       "                       [ 0.0964, -0.0159,  0.0784,  ...,  0.1305, -0.0211, -0.0208],\n",
       "                       ...,\n",
       "                       [ 0.0229, -0.0386,  0.0986,  ...,  0.1031,  0.1752,  0.0898],\n",
       "                       [-0.0536, -0.2568, -0.1038,  ..., -0.0630,  0.0897,  0.1776],\n",
       "                       [ 0.0649, -0.2634, -0.2006,  ...,  0.0370,  0.2223, -0.0280]])),\n",
       "              ('decoder.layers.1.self_attn.q_proj.bias',\n",
       "               tensor([-0.1521,  0.0818, -0.1588,  ..., -0.2396,  0.2683, -0.0331])),\n",
       "              ('decoder.layers.1.self_attn.out_proj.weight',\n",
       "               tensor([[-0.0745,  0.0151,  0.0754,  ...,  0.0386, -0.0698, -0.2322],\n",
       "                       [-0.0479,  0.0938, -0.1135,  ..., -0.1068,  0.0493, -0.0406],\n",
       "                       [-0.1733, -0.1593, -0.1400,  ...,  0.1742,  0.0956, -0.1316],\n",
       "                       ...,\n",
       "                       [ 0.0762,  0.0043,  0.0445,  ..., -0.1135, -0.0853, -0.2292],\n",
       "                       [-0.0634, -0.0273, -0.0222,  ..., -0.0021, -0.1119, -0.0544],\n",
       "                       [ 0.0013, -0.0552,  0.0177,  ...,  0.1399,  0.2025,  0.1227]])),\n",
       "              ('decoder.layers.1.self_attn.out_proj.bias',\n",
       "               tensor([ 0.0382, -0.0423,  0.0437,  ..., -0.0261, -0.0106, -0.0812])),\n",
       "              ('decoder.layers.1.self_attn_layer_norm.weight',\n",
       "               tensor([0.4187, 0.2727, 0.3184,  ..., 0.3438, 0.2751, 0.3098])),\n",
       "              ('decoder.layers.1.self_attn_layer_norm.bias',\n",
       "               tensor([ 0.0089,  0.0142,  0.0135,  ..., -0.0153, -0.0217, -0.0052])),\n",
       "              ('decoder.layers.1.encoder_attn.k_proj.weight',\n",
       "               tensor([[-0.1409,  0.0075, -0.1860,  ...,  0.0038,  0.0111,  0.2249],\n",
       "                       [-0.2189, -0.0126, -0.0584,  ..., -0.0740, -0.1210, -0.0078],\n",
       "                       [-0.1281, -0.0488,  0.0404,  ...,  0.0457,  0.0647, -0.0155],\n",
       "                       ...,\n",
       "                       [-0.0679, -0.1140, -0.1560,  ...,  0.2130, -0.1172,  0.2087],\n",
       "                       [ 0.0121, -0.1073, -0.1471,  ..., -0.2039, -0.0307, -0.1202],\n",
       "                       [-0.0071, -0.0715,  0.0876,  ...,  0.0460,  0.1316, -0.2096]])),\n",
       "              ('decoder.layers.1.encoder_attn.k_proj.bias',\n",
       "               tensor([-0.0161, -0.0036, -0.0426,  ...,  0.0245,  0.0069,  0.0091])),\n",
       "              ('decoder.layers.1.encoder_attn.v_proj.weight',\n",
       "               tensor([[ 0.1317, -0.0510,  0.1906,  ...,  0.0163,  0.0058, -0.0465],\n",
       "                       [-0.0266,  0.0514, -0.0861,  ...,  0.0020, -0.0386,  0.0801],\n",
       "                       [ 0.0253,  0.0558, -0.0170,  ..., -0.1281,  0.0314, -0.0175],\n",
       "                       ...,\n",
       "                       [-0.1060,  0.0506,  0.0055,  ..., -0.2949, -0.0927,  0.0254],\n",
       "                       [-0.0048, -0.1101,  0.0279,  ...,  0.2010,  0.0030, -0.0057],\n",
       "                       [ 0.0865, -0.0663,  0.0238,  ..., -0.1453,  0.0330,  0.0768]])),\n",
       "              ('decoder.layers.1.encoder_attn.v_proj.bias',\n",
       "               tensor([-0.0003, -0.0010,  0.0226,  ...,  0.0128, -0.0068, -0.0069])),\n",
       "              ('decoder.layers.1.encoder_attn.q_proj.weight',\n",
       "               tensor([[ 0.0343,  0.0088, -0.0920,  ..., -0.0199, -0.0856, -0.0234],\n",
       "                       [ 0.0119,  0.1423,  0.1976,  ...,  0.0188,  0.0871, -0.1705],\n",
       "                       [-0.1344,  0.1610, -0.1481,  ..., -0.0773,  0.1104,  0.2140],\n",
       "                       ...,\n",
       "                       [ 0.0691,  0.0583,  0.2418,  ..., -0.0558,  0.0852, -0.0151],\n",
       "                       [ 0.0493, -0.0851,  0.0082,  ...,  0.0219,  0.0450, -0.0519],\n",
       "                       [-0.1675,  0.0197,  0.1819,  ..., -0.0517,  0.0217, -0.0283]])),\n",
       "              ('decoder.layers.1.encoder_attn.q_proj.bias',\n",
       "               tensor([ 0.0075,  0.0851, -0.0140,  ...,  0.0855, -0.0956, -0.1461])),\n",
       "              ('decoder.layers.1.encoder_attn.out_proj.weight',\n",
       "               tensor([[ 0.0688,  0.0363, -0.0530,  ...,  0.0505,  0.0950,  0.0210],\n",
       "                       [-0.0836,  0.2076,  0.1012,  ..., -0.1477,  0.0321,  0.1302],\n",
       "                       [-0.0426, -0.0279, -0.0540,  ...,  0.0106,  0.0042, -0.0244],\n",
       "                       ...,\n",
       "                       [ 0.1222,  0.1091, -0.0029,  ..., -0.0246, -0.0400, -0.0195],\n",
       "                       [-0.0155, -0.0972, -0.1089,  ..., -0.0132, -0.0696,  0.1147],\n",
       "                       [-0.0135, -0.2268,  0.1742,  ..., -0.0461,  0.0198,  0.0157]])),\n",
       "              ('decoder.layers.1.encoder_attn.out_proj.bias',\n",
       "               tensor([ 3.6194e-02, -2.2308e-02, -2.9800e-02,  ...,  4.1723e-05,\n",
       "                       -1.5434e-02,  6.7711e-03])),\n",
       "              ('decoder.layers.1.encoder_attn_layer_norm.weight',\n",
       "               tensor([0.8633, 0.5322, 0.7065,  ..., 0.7041, 0.6890, 0.6411])),\n",
       "              ('decoder.layers.1.encoder_attn_layer_norm.bias',\n",
       "               tensor([0.0335, 0.0724, 0.0618,  ..., 0.0450, 0.0535, 0.0927])),\n",
       "              ('decoder.layers.1.fc1.weight',\n",
       "               tensor([[-5.2719e-03, -5.6496e-03,  1.4563e-01,  ..., -1.2573e-01,\n",
       "                         2.1277e-01, -1.6309e-01],\n",
       "                       [-4.4250e-02, -2.8275e-02,  1.6016e-01,  ...,  6.8054e-02,\n",
       "                         2.1500e-02,  2.1148e-04],\n",
       "                       [ 3.3936e-02,  5.2917e-02,  1.9043e-01,  ...,  2.0416e-02,\n",
       "                        -3.0960e-02, -9.1797e-02],\n",
       "                       ...,\n",
       "                       [-2.9565e-01,  1.6748e-01,  2.5955e-02,  ..., -1.6174e-01,\n",
       "                        -3.9429e-02, -5.6824e-02],\n",
       "                       [ 1.2158e-01, -4.4632e-03, -2.0477e-02,  ...,  1.0750e-02,\n",
       "                         1.4697e-01, -2.1423e-01],\n",
       "                       [ 9.4604e-02, -2.9150e-01,  2.9633e-02,  ..., -2.2388e-01,\n",
       "                        -1.6937e-02, -9.4910e-02]])),\n",
       "              ('decoder.layers.1.fc1.bias',\n",
       "               tensor([-0.2196, -0.1479, -0.2067,  ..., -0.2178, -0.1731, -0.1448])),\n",
       "              ('decoder.layers.1.fc2.weight',\n",
       "               tensor([[ 0.1644, -0.1849,  0.0491,  ...,  0.0005, -0.1715, -0.1381],\n",
       "                       [-0.0957, -0.1930, -0.0894,  ...,  0.1136,  0.1456,  0.2255],\n",
       "                       [-0.1598,  0.1199, -0.1685,  ...,  0.0474, -0.1086, -0.0362],\n",
       "                       ...,\n",
       "                       [ 0.0004, -0.1823,  0.0618,  ..., -0.0558,  0.0222, -0.1494],\n",
       "                       [-0.1250,  0.1624,  0.0184,  ..., -0.0315, -0.1914, -0.0026],\n",
       "                       [ 0.0656, -0.0609, -0.0091,  ...,  0.0168, -0.2400, -0.0889]])),\n",
       "              ('decoder.layers.1.fc2.bias',\n",
       "               tensor([-0.1107, -0.1015, -0.1581,  ...,  0.0576,  0.2288,  0.0895])),\n",
       "              ('decoder.layers.1.final_layer_norm.weight',\n",
       "               tensor([0.4209, 0.3386, 0.4092,  ..., 0.4683, 0.4016, 0.4412])),\n",
       "              ('decoder.layers.1.final_layer_norm.bias',\n",
       "               tensor([-0.0063,  0.0224, -0.0066,  ...,  0.0489,  0.0350,  0.0639])),\n",
       "              ('decoder.layers.2.self_attn.k_proj.weight',\n",
       "               tensor([[-0.0159,  0.1838, -0.4326,  ...,  0.2964,  0.0081,  0.1343],\n",
       "                       [-0.4390, -0.1763, -0.0094,  ..., -0.1532, -0.0240, -0.1207],\n",
       "                       [-0.2595, -0.1179, -0.3154,  ..., -0.0229, -0.2114, -0.0948],\n",
       "                       ...,\n",
       "                       [ 0.0148,  0.0924,  0.1198,  ..., -0.1339,  0.1853,  0.2637],\n",
       "                       [-0.1521,  0.1646, -0.2302,  ...,  0.2445,  0.0197,  0.2008],\n",
       "                       [ 0.0668, -0.0602,  0.3022,  ...,  0.4265,  0.3167, -0.5278]])),\n",
       "              ('decoder.layers.2.self_attn.k_proj.bias',\n",
       "               tensor([ 0.1733, -0.1356,  0.2249,  ..., -0.0603,  0.0206,  0.0038])),\n",
       "              ('decoder.layers.2.self_attn.v_proj.weight',\n",
       "               tensor([[ 0.0312,  0.0602,  0.0986,  ...,  0.0659,  0.1200, -0.0316],\n",
       "                       [ 0.0094,  0.0684, -0.0310,  ...,  0.0075, -0.0270, -0.0189],\n",
       "                       [-0.0078, -0.0135,  0.0073,  ..., -0.0463,  0.0082,  0.0629],\n",
       "                       ...,\n",
       "                       [ 0.1054,  0.1163,  0.0041,  ...,  0.0199,  0.0876,  0.1484],\n",
       "                       [ 0.1283,  0.1039,  0.1251,  ..., -0.0508, -0.1794,  0.0980],\n",
       "                       [ 0.0495,  0.1218,  0.0148,  ...,  0.0880, -0.2573,  0.0389]])),\n",
       "              ('decoder.layers.2.self_attn.v_proj.bias',\n",
       "               tensor([0.0878, 0.0120, 0.0039,  ..., 0.0421, 0.0162, 0.1068])),\n",
       "              ('decoder.layers.2.self_attn.q_proj.weight',\n",
       "               tensor([[-0.2544,  0.1504,  0.3064,  ..., -0.0439,  0.1847, -0.0066],\n",
       "                       [-0.0272, -0.7256,  0.2421,  ..., -0.1429,  0.2588, -0.2734],\n",
       "                       [ 0.0093,  0.0361, -0.1520,  ...,  0.2671,  0.1393,  0.3411],\n",
       "                       ...,\n",
       "                       [ 0.3201, -0.3696,  0.0195,  ...,  0.3828,  0.0373,  0.0064],\n",
       "                       [-0.0494, -0.2236,  0.1868,  ..., -0.1584,  0.0690,  0.2339],\n",
       "                       [ 0.2358,  0.0047,  0.0168,  ...,  0.0337,  0.0964,  0.1992]])),\n",
       "              ('decoder.layers.2.self_attn.q_proj.bias',\n",
       "               tensor([-0.0169, -0.1772,  0.2346,  ...,  0.3098, -0.1220,  0.0794])),\n",
       "              ('decoder.layers.2.self_attn.out_proj.weight',\n",
       "               tensor([[ 0.0261, -0.0598, -0.0898,  ...,  0.0013,  0.1506, -0.1048],\n",
       "                       [-0.0399, -0.0010, -0.0673,  ...,  0.0682,  0.1998,  0.0220],\n",
       "                       [ 0.0902, -0.0609, -0.0725,  ..., -0.0058, -0.1606,  0.1312],\n",
       "                       ...,\n",
       "                       [ 0.0159,  0.0092, -0.0614,  ..., -0.0690, -0.0209,  0.0270],\n",
       "                       [ 0.1750, -0.0499,  0.0066,  ...,  0.0415, -0.1980, -0.0300],\n",
       "                       [-0.1517, -0.0771,  0.1176,  ...,  0.1036, -0.0198, -0.0870]])),\n",
       "              ('decoder.layers.2.self_attn.out_proj.bias',\n",
       "               tensor([ 0.0600, -0.1378,  0.0151,  ..., -0.1093, -0.1428, -0.1086])),\n",
       "              ('decoder.layers.2.self_attn_layer_norm.weight',\n",
       "               tensor([0.4780, 0.3760, 0.4209,  ..., 0.4417, 0.3704, 0.3721])),\n",
       "              ('decoder.layers.2.self_attn_layer_norm.bias',\n",
       "               tensor([ 0.0046,  0.0099,  0.0072,  ..., -0.0071, -0.0171, -0.0016])),\n",
       "              ('decoder.layers.2.encoder_attn.k_proj.weight',\n",
       "               tensor([[-0.0881, -0.1361,  0.0187,  ...,  0.0886, -0.0050,  0.1899],\n",
       "                       [-0.0987,  0.1455, -0.0944,  ...,  0.2634, -0.1842, -0.1542],\n",
       "                       [-0.0801,  0.1594, -0.0441,  ...,  0.0238, -0.0571, -0.0981],\n",
       "                       ...,\n",
       "                       [-0.0181,  0.1317,  0.0429,  ...,  0.0740,  0.0811, -0.0475],\n",
       "                       [ 0.0237, -0.1031, -0.0057,  ...,  0.1562, -0.1331,  0.0589],\n",
       "                       [-0.0451, -0.1772,  0.2170,  ..., -0.0414, -0.0292,  0.0485]])),\n",
       "              ('decoder.layers.2.encoder_attn.k_proj.bias',\n",
       "               tensor([ 0.0146,  0.0078, -0.0250,  ..., -0.0032,  0.0152, -0.0119])),\n",
       "              ('decoder.layers.2.encoder_attn.v_proj.weight',\n",
       "               tensor([[-1.2549e-01, -8.4595e-02,  6.5002e-02,  ..., -1.5076e-01,\n",
       "                         1.2360e-01, -2.0554e-02],\n",
       "                       [ 7.5493e-03, -1.1652e-01,  4.7394e-02,  ..., -1.0170e-02,\n",
       "                        -5.9448e-02, -2.7710e-01],\n",
       "                       [-8.7023e-05,  7.9834e-02,  1.1713e-01,  ...,  1.3123e-01,\n",
       "                         2.4071e-03, -6.8481e-02],\n",
       "                       ...,\n",
       "                       [-9.4177e-02,  5.5542e-02, -1.3283e-02,  ..., -1.2372e-01,\n",
       "                         1.4075e-01,  4.2053e-02],\n",
       "                       [-8.4167e-02, -7.3669e-02, -2.5806e-01,  ..., -2.6416e-01,\n",
       "                        -9.9670e-02, -1.3342e-01],\n",
       "                       [ 5.8563e-02,  1.0443e-01,  1.9995e-01,  ...,  2.0096e-02,\n",
       "                        -4.5319e-02,  2.3697e-02]])),\n",
       "              ('decoder.layers.2.encoder_attn.v_proj.bias',\n",
       "               tensor([ 0.0031, -0.0080, -0.0050,  ..., -0.0162,  0.0027,  0.0079])),\n",
       "              ('decoder.layers.2.encoder_attn.q_proj.weight',\n",
       "               tensor([[-0.0464,  0.0331, -0.0292,  ..., -0.0387,  0.1588,  0.1731],\n",
       "                       [ 0.3196,  0.2803,  0.0371,  ...,  0.0288, -0.1042, -0.1356],\n",
       "                       [ 0.0697,  0.0155,  0.2233,  ...,  0.0538, -0.1749, -0.1190],\n",
       "                       ...,\n",
       "                       [-0.1311,  0.1825, -0.0205,  ...,  0.0706,  0.0504,  0.0542],\n",
       "                       [-0.0364,  0.1632,  0.1708,  ...,  0.0104,  0.0560, -0.0361],\n",
       "                       [ 0.0220,  0.0845,  0.0341,  ...,  0.0012, -0.1114,  0.0555]])),\n",
       "              ('decoder.layers.2.encoder_attn.q_proj.bias',\n",
       "               tensor([-0.1066, -0.0515,  0.0222,  ..., -0.0287, -0.0238, -0.0106])),\n",
       "              ('decoder.layers.2.encoder_attn.out_proj.weight',\n",
       "               tensor([[-0.2065,  0.0116,  0.0957,  ...,  0.1865, -0.0184, -0.0784],\n",
       "                       [ 0.1676, -0.0187, -0.1448,  ...,  0.1923,  0.2104,  0.0259],\n",
       "                       [-0.0374, -0.0274, -0.0569,  ...,  0.1194,  0.0448, -0.0428],\n",
       "                       ...,\n",
       "                       [ 0.0283, -0.0513, -0.1661,  ..., -0.0760,  0.0698,  0.1628],\n",
       "                       [ 0.0265, -0.1252,  0.3296,  ...,  0.0378,  0.0069, -0.0941],\n",
       "                       [-0.1412, -0.0222, -0.1318,  ...,  0.0319, -0.1065,  0.1559]])),\n",
       "              ('decoder.layers.2.encoder_attn.out_proj.bias',\n",
       "               tensor([ 0.0557, -0.0250,  0.0221,  ..., -0.0110, -0.0533, -0.0151])),\n",
       "              ('decoder.layers.2.encoder_attn_layer_norm.weight',\n",
       "               tensor([0.7261, 0.5127, 0.6802,  ..., 0.6338, 0.5356, 0.5649])),\n",
       "              ('decoder.layers.2.encoder_attn_layer_norm.bias',\n",
       "               tensor([ 0.0022,  0.0383,  0.0027,  ...,  0.0189, -0.0037,  0.0634])),\n",
       "              ('decoder.layers.2.fc1.weight',\n",
       "               tensor([[-0.0641,  0.0518,  0.0280,  ..., -0.2659, -0.1060, -0.1964],\n",
       "                       [-0.2279,  0.1344,  0.0631,  ...,  0.0399, -0.1881,  0.0571],\n",
       "                       [ 0.0699, -0.2126, -0.0235,  ..., -0.0170,  0.1497,  0.0706],\n",
       "                       ...,\n",
       "                       [ 0.0975,  0.0269,  0.0602,  ..., -0.2485, -0.1589, -0.0423],\n",
       "                       [ 0.1567,  0.0682, -0.0494,  ...,  0.0006, -0.2164, -0.0765],\n",
       "                       [-0.1371, -0.0082, -0.0258,  ...,  0.0335, -0.0805, -0.2927]])),\n",
       "              ('decoder.layers.2.fc1.bias',\n",
       "               tensor([-0.2185, -0.0670, -0.1412,  ..., -0.0743, -0.1743, -0.0625])),\n",
       "              ('decoder.layers.2.fc2.weight',\n",
       "               tensor([[-0.2400,  0.3118, -0.0676,  ..., -0.0186, -0.1541,  0.1224],\n",
       "                       [ 0.0790, -0.0257, -0.0660,  ..., -0.0461,  0.1365, -0.2646],\n",
       "                       [-0.1554,  0.1589, -0.0416,  ..., -0.0045, -0.0125, -0.0695],\n",
       "                       ...,\n",
       "                       [-0.0622,  0.0273,  0.0117,  ...,  0.2515, -0.0443, -0.1753],\n",
       "                       [-0.0481,  0.0538, -0.1501,  ...,  0.2386, -0.1495, -0.0864],\n",
       "                       [-0.0389, -0.0819, -0.0895,  ...,  0.0289,  0.1322, -0.0594]])),\n",
       "              ('decoder.layers.2.fc2.bias',\n",
       "               tensor([-0.1750, -0.0305, -0.2460,  ...,  0.0582,  0.1780,  0.1383])),\n",
       "              ('decoder.layers.2.final_layer_norm.weight',\n",
       "               tensor([0.4224, 0.3486, 0.4175,  ..., 0.4900, 0.3958, 0.4248])),\n",
       "              ('decoder.layers.2.final_layer_norm.bias',\n",
       "               tensor([-0.0155,  0.0239, -0.0277,  ...,  0.0426,  0.0445,  0.0707])),\n",
       "              ('decoder.layers.3.self_attn.k_proj.weight',\n",
       "               tensor([[ 0.1186, -0.1819,  0.0005,  ..., -0.0393, -0.0986, -0.1992],\n",
       "                       [ 0.0265,  0.0411,  0.0637,  ...,  0.0978, -0.1415, -0.0039],\n",
       "                       [-0.1406, -0.2007,  0.1820,  ...,  0.1059, -0.0217,  0.1776],\n",
       "                       ...,\n",
       "                       [ 0.0038, -0.1087, -0.0688,  ..., -0.0122, -0.1212, -0.1578],\n",
       "                       [ 0.0126,  0.0300,  0.0451,  ...,  0.1367, -0.0411, -0.0538],\n",
       "                       [-0.3040, -0.1545, -0.1888,  ...,  0.0029,  0.2512,  0.0460]])),\n",
       "              ('decoder.layers.3.self_attn.k_proj.bias',\n",
       "               tensor([-0.0224, -0.0606,  0.1016,  ..., -0.0066, -0.0124,  0.0096])),\n",
       "              ('decoder.layers.3.self_attn.v_proj.weight',\n",
       "               tensor([[ 0.0099, -0.0479,  0.1056,  ..., -0.0579, -0.0781, -0.1338],\n",
       "                       [-0.1082,  0.0183,  0.1868,  ...,  0.1041,  0.0021,  0.0024],\n",
       "                       [ 0.0183, -0.0245, -0.0081,  ...,  0.0334,  0.0556, -0.2408],\n",
       "                       ...,\n",
       "                       [ 0.1176,  0.0057, -0.0860,  ...,  0.2861, -0.0082, -0.1309],\n",
       "                       [-0.0238, -0.0771, -0.0069,  ...,  0.0694,  0.0413,  0.0004],\n",
       "                       [ 0.0229,  0.0305, -0.1089,  ...,  0.0795, -0.1356,  0.0583]])),\n",
       "              ('decoder.layers.3.self_attn.v_proj.bias',\n",
       "               tensor([-0.0037, -0.0222,  0.0373,  ..., -0.0073, -0.0056,  0.0039])),\n",
       "              ('decoder.layers.3.self_attn.q_proj.weight',\n",
       "               tensor([[-0.1545, -0.0276, -0.1897,  ...,  0.0301,  0.1632,  0.0190],\n",
       "                       [-0.1163,  0.0862, -0.2477,  ..., -0.0206, -0.1257,  0.1611],\n",
       "                       [ 0.0833, -0.1680, -0.0897,  ..., -0.1310, -0.0984,  0.1418],\n",
       "                       ...,\n",
       "                       [-0.0578,  0.1191,  0.0733,  ..., -0.1259, -0.1426, -0.0759],\n",
       "                       [ 0.1362, -0.0185,  0.2241,  ...,  0.1464,  0.0684,  0.1024],\n",
       "                       [ 0.0552,  0.0524, -0.0227,  ..., -0.0728,  0.0665,  0.0050]])),\n",
       "              ('decoder.layers.3.self_attn.q_proj.bias',\n",
       "               tensor([ 0.2181,  0.2769,  0.0833,  ..., -0.1081,  0.0694,  0.0496])),\n",
       "              ('decoder.layers.3.self_attn.out_proj.weight',\n",
       "               tensor([[ 0.0138, -0.1581, -0.0183,  ..., -0.0425,  0.1871, -0.0150],\n",
       "                       [-0.0331,  0.0941,  0.1711,  ..., -0.0976,  0.0604, -0.1395],\n",
       "                       [-0.0160,  0.0065,  0.1227,  ...,  0.0665, -0.1313,  0.1953],\n",
       "                       ...,\n",
       "                       [-0.1138,  0.1715,  0.1116,  ..., -0.1552, -0.0239,  0.0020],\n",
       "                       [ 0.1257, -0.1560, -0.0004,  ...,  0.0095,  0.0290,  0.0953],\n",
       "                       [-0.0431,  0.0558, -0.0558,  ...,  0.1903,  0.0424, -0.0395]])),\n",
       "              ('decoder.layers.3.self_attn.out_proj.bias',\n",
       "               tensor([ 0.1470, -0.1260,  0.0245,  ..., -0.0471, -0.0902, -0.1830])),\n",
       "              ('decoder.layers.3.self_attn_layer_norm.weight',\n",
       "               tensor([0.4668, 0.3728, 0.3752,  ..., 0.4734, 0.3809, 0.3950])),\n",
       "              ('decoder.layers.3.self_attn_layer_norm.bias',\n",
       "               tensor([-0.0015,  0.0077,  0.0093,  ..., -0.0047, -0.0157,  0.0007])),\n",
       "              ('decoder.layers.3.encoder_attn.k_proj.weight',\n",
       "               tensor([[ 0.0341, -0.1329,  0.1998,  ..., -0.0138,  0.0487, -0.1857],\n",
       "                       [-0.0398, -0.0484,  0.1469,  ..., -0.1232, -0.0468, -0.1730],\n",
       "                       [ 0.0772, -0.2007, -0.0949,  ..., -0.1190, -0.2401,  0.0969],\n",
       "                       ...,\n",
       "                       [ 0.0993,  0.0275,  0.0132,  ...,  0.0774, -0.1165,  0.1247],\n",
       "                       [-0.1968,  0.0797, -0.1934,  ..., -0.0025, -0.0891,  0.1004],\n",
       "                       [-0.0484,  0.0602,  0.0869,  ..., -0.2242,  0.1350, -0.2240]])),\n",
       "              ('decoder.layers.3.encoder_attn.k_proj.bias',\n",
       "               tensor([-0.0209, -0.0053,  0.0998,  ...,  0.0247, -0.0016, -0.0181])),\n",
       "              ('decoder.layers.3.encoder_attn.v_proj.weight',\n",
       "               tensor([[-0.0205,  0.0020, -0.0765,  ..., -0.0352, -0.0761, -0.0767],\n",
       "                       [-0.0201, -0.1254,  0.2150,  ..., -0.1159,  0.0571,  0.0707],\n",
       "                       [-0.0448,  0.0836,  0.0515,  ..., -0.0994,  0.1136,  0.2478],\n",
       "                       ...,\n",
       "                       [ 0.1272, -0.0976, -0.0496,  ...,  0.1025, -0.0745,  0.0356],\n",
       "                       [ 0.0188,  0.0724, -0.1407,  ..., -0.2185, -0.0709,  0.0030],\n",
       "                       [ 0.0290,  0.0853, -0.1383,  ..., -0.1440, -0.0307, -0.0485]])),\n",
       "              ('decoder.layers.3.encoder_attn.v_proj.bias',\n",
       "               tensor([-0.0166,  0.0172, -0.0045,  ...,  0.0100,  0.0066, -0.0018])),\n",
       "              ('decoder.layers.3.encoder_attn.q_proj.weight',\n",
       "               tensor([[ 0.2148,  0.0470,  0.1213,  ..., -0.1375,  0.1661,  0.2686],\n",
       "                       [-0.1918, -0.0312,  0.0916,  ...,  0.4116,  0.0880,  0.1040],\n",
       "                       [-0.1515,  0.0123,  0.1282,  ...,  0.0971, -0.0017,  0.3879],\n",
       "                       ...,\n",
       "                       [ 0.3464, -0.3018,  0.0068,  ..., -0.0775,  0.0268,  0.0150],\n",
       "                       [-0.1392,  0.0230,  0.0566,  ..., -0.0051,  0.1025,  0.3340],\n",
       "                       [-0.1102, -0.0820, -0.2246,  ...,  0.0242, -0.1366,  0.0469]])),\n",
       "              ('decoder.layers.3.encoder_attn.q_proj.bias',\n",
       "               tensor([-0.0417, -0.1051,  0.3047,  ..., -0.0583, -0.0046, -0.0130])),\n",
       "              ('decoder.layers.3.encoder_attn.out_proj.weight',\n",
       "               tensor([[ 0.0254,  0.0636, -0.0626,  ..., -0.0352, -0.1306, -0.0980],\n",
       "                       [ 0.0160,  0.0461,  0.1976,  ...,  0.0759,  0.0111, -0.0111],\n",
       "                       [ 0.2042,  0.1996,  0.0101,  ...,  0.0349,  0.1193,  0.0449],\n",
       "                       ...,\n",
       "                       [-0.0761,  0.1464,  0.1472,  ..., -0.0353,  0.1017,  0.0776],\n",
       "                       [ 0.1417,  0.1801,  0.0508,  ..., -0.0334,  0.0361, -0.1743],\n",
       "                       [-0.0290,  0.0507,  0.0611,  ..., -0.1421, -0.2311,  0.0587]])),\n",
       "              ('decoder.layers.3.encoder_attn.out_proj.bias',\n",
       "               tensor([ 0.1161,  0.0253,  0.0681,  ...,  0.0114,  0.0088, -0.0340])),\n",
       "              ('decoder.layers.3.encoder_attn_layer_norm.weight',\n",
       "               tensor([0.6895, 0.5742, 0.6963,  ..., 0.7153, 0.5303, 0.6191])),\n",
       "              ('decoder.layers.3.encoder_attn_layer_norm.bias',\n",
       "               tensor([-0.0105,  0.0400, -0.0033,  ..., -0.0039,  0.0117,  0.0328])),\n",
       "              ('decoder.layers.3.fc1.weight',\n",
       "               tensor([[ 0.1689, -0.0150,  0.0961,  ...,  0.1385, -0.0497,  0.0941],\n",
       "                       [-0.0222,  0.0278, -0.2297,  ..., -0.0071, -0.0732,  0.1820],\n",
       "                       [-0.1344,  0.1235, -0.0590,  ...,  0.2036, -0.0225, -0.1257],\n",
       "                       ...,\n",
       "                       [ 0.0736,  0.1431,  0.2079,  ...,  0.1965, -0.0467,  0.2039],\n",
       "                       [ 0.1801,  0.1140,  0.1287,  ..., -0.1351, -0.0679, -0.2126],\n",
       "                       [-0.0534,  0.0256,  0.1127,  ..., -0.1588,  0.0126,  0.1338]])),\n",
       "              ('decoder.layers.3.fc1.bias',\n",
       "               tensor([-0.1724, -0.1304, -0.0731,  ..., -0.1285, -0.1262, -0.1566])),\n",
       "              ('decoder.layers.3.fc2.weight',\n",
       "               tensor([[ 1.0071e-01,  1.4844e-01, -8.8318e-02,  ..., -2.5635e-01,\n",
       "                         1.1066e-01, -4.7455e-02],\n",
       "                       [-1.4209e-01,  2.5049e-01, -9.8999e-02,  ..., -1.4893e-01,\n",
       "                        -7.1167e-02,  4.0405e-02],\n",
       "                       [ 1.0521e-02, -3.4088e-02,  9.7656e-02,  ..., -9.5032e-02,\n",
       "                         8.8623e-02, -7.6294e-02],\n",
       "                       ...,\n",
       "                       [ 1.9849e-01, -1.5161e-01, -2.1899e-04,  ...,  4.1473e-02,\n",
       "                        -1.1542e-01,  1.4539e-01],\n",
       "                       [ 5.5817e-02, -1.1957e-01,  1.4014e-01,  ...,  4.0131e-02,\n",
       "                         8.2825e-02,  1.5833e-01],\n",
       "                       [-2.0312e-01,  1.1908e-01,  1.0895e-01,  ..., -1.4172e-01,\n",
       "                        -1.2642e-02,  2.9248e-01]])),\n",
       "              ('decoder.layers.3.fc2.bias',\n",
       "               tensor([-0.0313,  0.0123, -0.4429,  ...,  0.0288,  0.0868,  0.0490])),\n",
       "              ('decoder.layers.3.final_layer_norm.weight',\n",
       "               tensor([0.4597, 0.3669, 0.4453,  ..., 0.4656, 0.4097, 0.4448])),\n",
       "              ('decoder.layers.3.final_layer_norm.bias',\n",
       "               tensor([-0.0205,  0.0317, -0.0612,  ...,  0.0137,  0.0487,  0.0621])),\n",
       "              ('decoder.layers.4.self_attn.k_proj.weight',\n",
       "               tensor([[-0.0447, -0.0461, -0.1050,  ..., -0.0721, -0.0084, -0.0486],\n",
       "                       [-0.0244, -0.0291,  0.0107,  ..., -0.0281, -0.0558,  0.3286],\n",
       "                       [ 0.1469,  0.2023,  0.1318,  ..., -0.0237, -0.1953,  0.0721],\n",
       "                       ...,\n",
       "                       [ 0.0428,  0.2173, -0.1110,  ...,  0.1385, -0.0342,  0.0337],\n",
       "                       [-0.0640,  0.0036, -0.0756,  ..., -0.0792,  0.0415,  0.1191],\n",
       "                       [-0.0311,  0.1279,  0.0359,  ...,  0.0097,  0.1112,  0.1700]])),\n",
       "              ('decoder.layers.4.self_attn.k_proj.bias',\n",
       "               tensor([-0.0567, -0.0038,  0.0268,  ..., -0.0507,  0.0597,  0.0786])),\n",
       "              ('decoder.layers.4.self_attn.v_proj.weight',\n",
       "               tensor([[ 0.0172, -0.3093,  0.1450,  ...,  0.1669, -0.0337,  0.0177],\n",
       "                       [-0.0010, -0.0701, -0.1288,  ..., -0.1671, -0.1271,  0.2571],\n",
       "                       [ 0.1102,  0.0399, -0.1196,  ..., -0.2328, -0.2366, -0.2522],\n",
       "                       ...,\n",
       "                       [ 0.2466,  0.0929,  0.1434,  ..., -0.0299,  0.0721,  0.1826],\n",
       "                       [ 0.0052, -0.1860,  0.0550,  ...,  0.0393, -0.1273,  0.1849],\n",
       "                       [ 0.0684, -0.1157, -0.0872,  ...,  0.0840, -0.0845, -0.1028]])),\n",
       "              ('decoder.layers.4.self_attn.v_proj.bias',\n",
       "               tensor([-0.0129,  0.0129, -0.0084,  ...,  0.0079, -0.0050,  0.0226])),\n",
       "              ('decoder.layers.4.self_attn.q_proj.weight',\n",
       "               tensor([[ 0.1183,  0.0197, -0.1637,  ...,  0.0089,  0.0099,  0.0395],\n",
       "                       [-0.0941, -0.0060,  0.1868,  ..., -0.1659,  0.1396,  0.0812],\n",
       "                       [-0.0357,  0.1691,  0.1676,  ...,  0.0379,  0.1921, -0.0985],\n",
       "                       ...,\n",
       "                       [ 0.0528,  0.3066,  0.0646,  ...,  0.0645, -0.1490,  0.0809],\n",
       "                       [-0.2146,  0.0693,  0.1055,  ..., -0.1388,  0.1700, -0.1464],\n",
       "                       [-0.1875, -0.1066,  0.0621,  ..., -0.1688,  0.0479, -0.0503]])),\n",
       "              ('decoder.layers.4.self_attn.q_proj.bias',\n",
       "               tensor([ 0.7690, -0.2078,  0.0192,  ...,  0.2212, -0.1295, -0.3196])),\n",
       "              ('decoder.layers.4.self_attn.out_proj.weight',\n",
       "               tensor([[-0.0791,  0.1364, -0.2568,  ..., -0.1003,  0.0566,  0.0307],\n",
       "                       [-0.0604,  0.0820, -0.1014,  ...,  0.2245, -0.2452,  0.0982],\n",
       "                       [-0.1475,  0.2219, -0.0278,  ...,  0.1010, -0.0598, -0.1034],\n",
       "                       ...,\n",
       "                       [-0.0776,  0.1735,  0.1692,  ...,  0.1088, -0.1099,  0.1279],\n",
       "                       [-0.1423, -0.1371, -0.0200,  ...,  0.0317,  0.0679,  0.1019],\n",
       "                       [-0.1882, -0.1667,  0.0876,  ..., -0.0170, -0.1846,  0.0776]])),\n",
       "              ('decoder.layers.4.self_attn.out_proj.bias',\n",
       "               tensor([ 0.1041, -0.0743,  0.0570,  ..., -0.0795, -0.1360, -0.2474])),\n",
       "              ('decoder.layers.4.self_attn_layer_norm.weight',\n",
       "               tensor([0.5020, 0.3792, 0.4451,  ..., 0.4656, 0.3794, 0.4309])),\n",
       "              ('decoder.layers.4.self_attn_layer_norm.bias',\n",
       "               tensor([ 5.8413e-05,  8.7738e-03,  6.7368e-03,  ..., -2.4929e-03,\n",
       "                       -1.2314e-02,  6.4087e-03])),\n",
       "              ('decoder.layers.4.encoder_attn.k_proj.weight',\n",
       "               tensor([[ 0.1371,  0.1285,  0.0488,  ...,  0.0191,  0.0695, -0.1248],\n",
       "                       [-0.1219,  0.0065,  0.0221,  ..., -0.0254, -0.0919, -0.1196],\n",
       "                       [-0.0072,  0.0609, -0.0904,  ...,  0.0787, -0.0349, -0.1353],\n",
       "                       ...,\n",
       "                       [-0.1036, -0.0221,  0.0697,  ...,  0.1091, -0.0329,  0.0569],\n",
       "                       [ 0.1218, -0.1072,  0.0257,  ..., -0.0940,  0.1041, -0.0199],\n",
       "                       [ 0.2461,  0.0555, -0.0029,  ...,  0.0155,  0.0864,  0.0664]])),\n",
       "              ('decoder.layers.4.encoder_attn.k_proj.bias',\n",
       "               tensor([-0.0034, -0.0143, -0.0034,  ..., -0.0088,  0.0033,  0.0444])),\n",
       "              ('decoder.layers.4.encoder_attn.v_proj.weight',\n",
       "               tensor([[-9.2590e-02, -1.1981e-01, -7.5378e-02,  ..., -5.5817e-02,\n",
       "                        -6.6589e-02, -1.3293e-01],\n",
       "                       [ 7.3051e-03,  1.1871e-01,  1.5125e-01,  ...,  2.7496e-02,\n",
       "                        -3.5915e-03,  9.1858e-03],\n",
       "                       [-4.6051e-02,  1.0931e-01,  2.6123e-01,  ...,  2.1820e-02,\n",
       "                         2.5049e-01,  7.2632e-02],\n",
       "                       ...,\n",
       "                       [-4.0955e-02,  4.4403e-02, -6.1707e-02,  ...,  2.2717e-03,\n",
       "                        -1.5747e-01, -3.9520e-02],\n",
       "                       [ 8.3984e-02,  8.1909e-02, -1.0516e-01,  ..., -3.8330e-02,\n",
       "                         6.1646e-02,  7.2205e-02],\n",
       "                       [-3.4790e-02,  2.5604e-02, -9.3079e-03,  ...,  1.1373e-04,\n",
       "                        -1.3147e-01,  2.0523e-02]])),\n",
       "              ('decoder.layers.4.encoder_attn.v_proj.bias',\n",
       "               tensor([ 0.0188,  0.0144, -0.0267,  ...,  0.0048, -0.0102, -0.0065])),\n",
       "              ('decoder.layers.4.encoder_attn.q_proj.weight',\n",
       "               tensor([[ 0.0784,  0.0280,  0.0404,  ..., -0.0501,  0.1383, -0.0277],\n",
       "                       [ 0.0169, -0.1126, -0.0330,  ..., -0.2268, -0.1165,  0.0094],\n",
       "                       [ 0.0078,  0.0173, -0.0765,  ..., -0.0679,  0.0530,  0.0245],\n",
       "                       ...,\n",
       "                       [-0.1885,  0.0729, -0.1036,  ...,  0.0538, -0.1123,  0.0256],\n",
       "                       [-0.0777, -0.2656, -0.0251,  ..., -0.0719, -0.0999, -0.0547],\n",
       "                       [-0.0931,  0.0873, -0.0437,  ..., -0.0624, -0.0668,  0.0418]])),\n",
       "              ('decoder.layers.4.encoder_attn.q_proj.bias',\n",
       "               tensor([-0.0972,  0.1357,  0.1500,  ...,  0.2607, -0.0318, -0.6528])),\n",
       "              ('decoder.layers.4.encoder_attn.out_proj.weight',\n",
       "               tensor([[ 0.1545, -0.1426, -0.1417,  ..., -0.0337,  0.2079,  0.0559],\n",
       "                       [ 0.0468,  0.1012, -0.1925,  ..., -0.0214,  0.1224,  0.1154],\n",
       "                       [ 0.0310, -0.2271,  0.2367,  ...,  0.1072, -0.1148, -0.1168],\n",
       "                       ...,\n",
       "                       [ 0.0213, -0.0938,  0.1833,  ...,  0.1003, -0.0642,  0.0039],\n",
       "                       [ 0.0707, -0.1862,  0.0036,  ..., -0.1791, -0.0289,  0.0183],\n",
       "                       [-0.0346, -0.0157, -0.0069,  ...,  0.1433,  0.3345,  0.2644]])),\n",
       "              ('decoder.layers.4.encoder_attn.out_proj.bias',\n",
       "               tensor([ 0.0710,  0.0242,  0.0676,  ...,  0.0155,  0.0093, -0.0333])),\n",
       "              ('decoder.layers.4.encoder_attn_layer_norm.weight',\n",
       "               tensor([0.6572, 0.5513, 0.6680,  ..., 0.6377, 0.5151, 0.6226])),\n",
       "              ('decoder.layers.4.encoder_attn_layer_norm.bias',\n",
       "               tensor([ 0.0126,  0.0209, -0.0302,  ...,  0.0119, -0.0423,  0.0466])),\n",
       "              ('decoder.layers.4.fc1.weight',\n",
       "               tensor([[-0.1113, -0.1565,  0.0345,  ...,  0.0276, -0.0299, -0.0461],\n",
       "                       [ 0.0941,  0.1042,  0.3701,  ..., -0.1063, -0.1010, -0.0748],\n",
       "                       [ 0.1010, -0.1610,  0.0381,  ..., -0.1086,  0.1167, -0.2485],\n",
       "                       ...,\n",
       "                       [-0.0529,  0.2668, -0.0906,  ..., -0.1631, -0.1416, -0.0050],\n",
       "                       [-0.0609,  0.0650,  0.1108,  ..., -0.2566,  0.0422,  0.0095],\n",
       "                       [-0.2639,  0.0785, -0.0264,  ...,  0.0903, -0.3550,  0.0033]])),\n",
       "              ('decoder.layers.4.fc1.bias',\n",
       "               tensor([-0.1156, -0.1990, -0.1731,  ..., -0.1309, -0.0975, -0.1572])),\n",
       "              ('decoder.layers.4.fc2.weight',\n",
       "               tensor([[ 0.1066,  0.0381, -0.0707,  ..., -0.1251,  0.1543, -0.1809],\n",
       "                       [ 0.0099,  0.0986, -0.1855,  ...,  0.0573, -0.0509,  0.0948],\n",
       "                       [ 0.0628,  0.1310,  0.0361,  ..., -0.0063, -0.0458, -0.1954],\n",
       "                       ...,\n",
       "                       [ 0.0217,  0.3188, -0.1071,  ..., -0.0542,  0.0540, -0.0848],\n",
       "                       [ 0.1268, -0.0523, -0.0998,  ...,  0.1289, -0.2612, -0.0006],\n",
       "                       [-0.0583,  0.1770, -0.1605,  ...,  0.0800, -0.1370,  0.1299]])),\n",
       "              ('decoder.layers.4.fc2.bias',\n",
       "               tensor([-0.0873, -0.0331, -0.3984,  ..., -0.0538,  0.1069, -0.0112])),\n",
       "              ('decoder.layers.4.final_layer_norm.weight',\n",
       "               tensor([0.4561, 0.3372, 0.4553,  ..., 0.4731, 0.3657, 0.4363])),\n",
       "              ('decoder.layers.4.final_layer_norm.bias',\n",
       "               tensor([-0.0192,  0.0222, -0.0865,  ..., -0.0008,  0.0227,  0.0589])),\n",
       "              ('decoder.layers.5.self_attn.k_proj.weight',\n",
       "               tensor([[-0.0905, -0.2043,  0.0015,  ..., -0.1630, -0.1521, -0.0026],\n",
       "                       [ 0.1729,  0.0185, -0.1328,  ...,  0.0720,  0.1884, -0.0977],\n",
       "                       [ 0.0719,  0.0313,  0.1975,  ...,  0.0270,  0.0487, -0.0248],\n",
       "                       ...,\n",
       "                       [-0.0136, -0.0315,  0.1046,  ..., -0.1918,  0.2104,  0.0187],\n",
       "                       [-0.0345, -0.1053,  0.0145,  ..., -0.1105, -0.0059, -0.1404],\n",
       "                       [-0.1384,  0.1742, -0.0759,  ..., -0.0912, -0.1934,  0.0956]])),\n",
       "              ('decoder.layers.5.self_attn.k_proj.bias',\n",
       "               tensor([-0.0338, -0.0223, -0.0182,  ..., -0.0341,  0.0689, -0.0063])),\n",
       "              ('decoder.layers.5.self_attn.v_proj.weight',\n",
       "               tensor([[-0.0395,  0.1781,  0.0040,  ...,  0.0334,  0.1628,  0.1681],\n",
       "                       [-0.1777,  0.0332, -0.0699,  ...,  0.1714,  0.0632, -0.1720],\n",
       "                       [-0.2351,  0.2018, -0.0608,  ..., -0.0723,  0.0720,  0.2134],\n",
       "                       ...,\n",
       "                       [ 0.1581,  0.2866,  0.1482,  ...,  0.1479,  0.0961,  0.1576],\n",
       "                       [-0.1205,  0.1453, -0.2117,  ...,  0.0316, -0.1234, -0.0974],\n",
       "                       [-0.0340, -0.0612,  0.1226,  ..., -0.0449, -0.3171,  0.0330]])),\n",
       "              ('decoder.layers.5.self_attn.v_proj.bias',\n",
       "               tensor([ 0.0707,  0.0103,  0.0406,  ...,  0.0341,  0.0354, -0.0230])),\n",
       "              ('decoder.layers.5.self_attn.q_proj.weight',\n",
       "               tensor([[ 0.0235, -0.1205,  0.1821,  ...,  0.2595,  0.0886, -0.1272],\n",
       "                       [ 0.0121, -0.0205,  0.2627,  ..., -0.0036, -0.0868,  0.0089],\n",
       "                       [ 0.0574,  0.1016, -0.0680,  ..., -0.2018,  0.0407, -0.0368],\n",
       "                       ...,\n",
       "                       [-0.1327,  0.0385, -0.1583,  ...,  0.0963,  0.1971, -0.0129],\n",
       "                       [-0.0181,  0.0351, -0.1737,  ..., -0.0215,  0.0303,  0.0351],\n",
       "                       [-0.0138,  0.1523, -0.0188,  ...,  0.0459,  0.1429, -0.0115]])),\n",
       "              ('decoder.layers.5.self_attn.q_proj.bias',\n",
       "               tensor([ 0.0840,  0.0263,  0.0936,  ...,  0.1312,  0.3843, -0.0750])),\n",
       "              ('decoder.layers.5.self_attn.out_proj.weight',\n",
       "               tensor([[-0.0104, -0.0637, -0.3074,  ...,  0.2820,  0.0402, -0.2031],\n",
       "                       [ 0.1611,  0.0128,  0.0243,  ...,  0.1257,  0.0932,  0.1608],\n",
       "                       [ 0.0464,  0.0751,  0.1251,  ..., -0.0675, -0.0561, -0.1209],\n",
       "                       ...,\n",
       "                       [ 0.1647,  0.1691, -0.0128,  ...,  0.0933, -0.0434,  0.0244],\n",
       "                       [ 0.0466,  0.0621, -0.1937,  ..., -0.0026, -0.0524,  0.0062],\n",
       "                       [-0.0259,  0.0807, -0.2798,  ..., -0.0331,  0.1920,  0.0858]])),\n",
       "              ('decoder.layers.5.self_attn.out_proj.bias',\n",
       "               tensor([ 0.0788, -0.1842,  0.1528,  ..., -0.0418, -0.0377, -0.2109])),\n",
       "              ('decoder.layers.5.self_attn_layer_norm.weight',\n",
       "               tensor([0.5244, 0.4033, 0.4951,  ..., 0.5273, 0.4104, 0.4343])),\n",
       "              ('decoder.layers.5.self_attn_layer_norm.bias',\n",
       "               tensor([ 0.0010,  0.0082,  0.0020,  ..., -0.0039, -0.0135,  0.0052])),\n",
       "              ('decoder.layers.5.encoder_attn.k_proj.weight',\n",
       "               tensor([[-0.0272,  0.0039,  0.0387,  ..., -0.0251, -0.0006, -0.0941],\n",
       "                       [ 0.0364, -0.1208,  0.1182,  ..., -0.0469,  0.1039, -0.0293],\n",
       "                       [ 0.1335, -0.1080,  0.0236,  ..., -0.1016,  0.0843, -0.0548],\n",
       "                       ...,\n",
       "                       [-0.5200,  0.0595, -0.0989,  ..., -0.2966, -0.0529,  0.1065],\n",
       "                       [-0.3940,  0.0103, -0.2793,  ...,  0.0931,  0.0016, -0.2261],\n",
       "                       [-0.1232, -0.1506, -0.0068,  ..., -0.0955, -0.1180,  0.1223]])),\n",
       "              ('decoder.layers.5.encoder_attn.k_proj.bias',\n",
       "               tensor([-0.0360,  0.0269,  0.0075,  ..., -0.0668, -0.0789, -0.0126])),\n",
       "              ('decoder.layers.5.encoder_attn.v_proj.weight',\n",
       "               tensor([[-0.0252, -0.0282,  0.1071,  ...,  0.0109,  0.1368, -0.1328],\n",
       "                       [ 0.0381, -0.0238,  0.1138,  ..., -0.1519, -0.1417, -0.0718],\n",
       "                       [-0.0573,  0.0773, -0.0290,  ..., -0.1038, -0.1418,  0.0400],\n",
       "                       ...,\n",
       "                       [-0.1115,  0.1946,  0.0587,  ..., -0.0398,  0.0511,  0.0381],\n",
       "                       [-0.1031,  0.0451, -0.0999,  ...,  0.0137, -0.0844,  0.1649],\n",
       "                       [ 0.1040, -0.0111,  0.0757,  ..., -0.1193,  0.0544,  0.0308]])),\n",
       "              ('decoder.layers.5.encoder_attn.v_proj.bias',\n",
       "               tensor([ 0.0058,  0.0062,  0.0026,  ...,  0.0377,  0.0263, -0.0194])),\n",
       "              ('decoder.layers.5.encoder_attn.q_proj.weight',\n",
       "               tensor([[ 0.1118, -0.0149,  0.1250,  ..., -0.0163, -0.0985,  0.0737],\n",
       "                       [ 0.0398, -0.1896, -0.1495,  ...,  0.1127, -0.1387, -0.1017],\n",
       "                       [-0.0271,  0.0026, -0.0861,  ...,  0.1663, -0.1093, -0.0719],\n",
       "                       ...,\n",
       "                       [-0.0961, -0.0839, -0.1459,  ...,  0.0781, -0.0455,  0.1960],\n",
       "                       [ 0.0705, -0.1197,  0.1538,  ...,  0.0883,  0.2517, -0.0942],\n",
       "                       [ 0.1383,  0.0591, -0.0869,  ...,  0.0179,  0.1783,  0.0929]])),\n",
       "              ('decoder.layers.5.encoder_attn.q_proj.bias',\n",
       "               tensor([ 0.2393, -0.0044, -0.2461,  ..., -0.1243, -0.1111, -0.0626])),\n",
       "              ('decoder.layers.5.encoder_attn.out_proj.weight',\n",
       "               tensor([[-1.0657e-01,  1.1896e-01,  1.6089e-01,  ...,  4.8535e-01,\n",
       "                        -3.4180e-02, -1.7346e-01],\n",
       "                       [ 1.3928e-01, -3.7193e-04, -2.2498e-01,  ..., -9.5337e-02,\n",
       "                        -1.7685e-02,  7.8552e-02],\n",
       "                       [ 1.8677e-01,  9.5093e-02, -1.5383e-03,  ...,  2.0422e-01,\n",
       "                        -1.1438e-01,  2.0798e-02],\n",
       "                       ...,\n",
       "                       [ 1.5564e-01, -1.5247e-01, -1.0217e-01,  ...,  6.2683e-02,\n",
       "                         1.1925e-02, -1.4575e-01],\n",
       "                       [-9.7168e-02,  8.5449e-02, -2.4243e-01,  ...,  3.3325e-02,\n",
       "                        -6.8909e-02,  8.7952e-02],\n",
       "                       [ 6.4880e-02, -1.2585e-01, -1.3206e-02,  ...,  1.2764e-02,\n",
       "                         1.5186e-01,  1.7456e-01]])),\n",
       "              ('decoder.layers.5.encoder_attn.out_proj.bias',\n",
       "               tensor([ 0.0864,  0.0037,  0.0561,  ...,  0.0060, -0.0475,  0.0096])),\n",
       "              ('decoder.layers.5.encoder_attn_layer_norm.weight',\n",
       "               tensor([0.6523, 0.5024, 0.6812,  ..., 0.6118, 0.4778, 0.5972])),\n",
       "              ('decoder.layers.5.encoder_attn_layer_norm.bias',\n",
       "               tensor([ 0.0075,  0.0498, -0.1083,  ..., -0.0112, -0.0201,  0.0266])),\n",
       "              ('decoder.layers.5.fc1.weight',\n",
       "               tensor([[ 0.1705, -0.0637, -0.0341,  ..., -0.0105,  0.0330,  0.0792],\n",
       "                       [-0.0947,  0.3303,  0.2094,  ...,  0.0651, -0.1440,  0.0336],\n",
       "                       [ 0.0970,  0.0739,  0.0844,  ..., -0.0580,  0.0883, -0.0249],\n",
       "                       ...,\n",
       "                       [ 0.0218,  0.0941,  0.1312,  ...,  0.0935,  0.0790, -0.1654],\n",
       "                       [-0.0038, -0.0178,  0.0391,  ..., -0.1628, -0.1506,  0.0016],\n",
       "                       [-0.1005,  0.1482,  0.1327,  ...,  0.1247, -0.0367, -0.0482]])),\n",
       "              ('decoder.layers.5.fc1.bias',\n",
       "               tensor([-0.1310, -0.1405, -0.0489,  ..., -0.0958, -0.0351, -0.1459])),\n",
       "              ('decoder.layers.5.fc2.weight',\n",
       "               tensor([[ 0.0029,  0.2039, -0.1136,  ...,  0.2747, -0.0082,  0.1742],\n",
       "                       [ 0.2764,  0.0798, -0.0505,  ...,  0.2759, -0.1175, -0.1855],\n",
       "                       [ 0.2277,  0.0429, -0.1133,  ...,  0.0287,  0.0829,  0.0909],\n",
       "                       ...,\n",
       "                       [-0.0900,  0.0677, -0.0539,  ..., -0.1925,  0.2080,  0.2737],\n",
       "                       [-0.1646, -0.1523, -0.0399,  ...,  0.3594,  0.0585, -0.0549],\n",
       "                       [-0.1100,  0.0722,  0.0593,  ..., -0.2388, -0.0861, -0.0193]])),\n",
       "              ('decoder.layers.5.fc2.bias',\n",
       "               tensor([-0.2144,  0.0369, -0.3584,  ..., -0.0865,  0.1191,  0.0119])),\n",
       "              ('decoder.layers.5.final_layer_norm.weight',\n",
       "               tensor([0.4614, 0.3511, 0.4465,  ..., 0.4592, 0.3762, 0.4299])),\n",
       "              ('decoder.layers.5.final_layer_norm.bias',\n",
       "               tensor([-0.0281,  0.0124, -0.0964,  ..., -0.0004,  0.0212,  0.0674])),\n",
       "              ('decoder.layers.6.self_attn.k_proj.weight',\n",
       "               tensor([[ 2.8149e-01, -1.3818e-01,  1.5405e-01,  ...,  8.9844e-02,\n",
       "                         4.1565e-02, -3.1219e-02],\n",
       "                       [ 5.9509e-02,  1.2439e-01,  1.5649e-01,  ...,  2.1045e-01,\n",
       "                        -2.6138e-02,  2.1558e-01],\n",
       "                       [ 1.5137e-01, -2.1851e-02,  7.3975e-02,  ...,  3.6591e-02,\n",
       "                         2.3499e-01, -1.1871e-01],\n",
       "                       ...,\n",
       "                       [-6.1340e-02,  2.3365e-03, -1.1945e-01,  ...,  6.2134e-02,\n",
       "                        -6.7200e-02,  4.7668e-02],\n",
       "                       [-8.9966e-02, -1.1530e-01, -1.0492e-01,  ..., -7.8491e-02,\n",
       "                         2.6929e-01,  3.9816e-05],\n",
       "                       [-1.5495e-02, -1.4685e-01,  1.1865e-01,  ..., -2.5000e-01,\n",
       "                        -2.3804e-03, -8.7036e-02]])),\n",
       "              ('decoder.layers.6.self_attn.k_proj.bias',\n",
       "               tensor([-0.0271, -0.0530, -0.0053,  ...,  0.0559, -0.0462, -0.0319])),\n",
       "              ('decoder.layers.6.self_attn.v_proj.weight',\n",
       "               tensor([[ 0.1848, -0.0328, -0.0333,  ...,  0.1172, -0.0654,  0.0539],\n",
       "                       [-0.2590, -0.0149,  0.0231,  ..., -0.1462,  0.1381,  0.2563],\n",
       "                       [ 0.2644,  0.1307,  0.1465,  ...,  0.0805, -0.3188, -0.1858],\n",
       "                       ...,\n",
       "                       [ 0.1814,  0.0529, -0.0246,  ...,  0.0319, -0.0662, -0.0739],\n",
       "                       [-0.3826, -0.0171, -0.0782,  ...,  0.1588, -0.1906,  0.1854],\n",
       "                       [-0.2913,  0.0390, -0.1316,  ..., -0.1467, -0.0541, -0.3064]])),\n",
       "              ('decoder.layers.6.self_attn.v_proj.bias',\n",
       "               tensor([-0.0316, -0.0232,  0.0320,  ..., -0.0003, -0.0143,  0.0102])),\n",
       "              ('decoder.layers.6.self_attn.q_proj.weight',\n",
       "               tensor([[ 0.2233, -0.0036,  0.0559,  ...,  0.2496,  0.0842, -0.0301],\n",
       "                       [ 0.2260, -0.0765,  0.0056,  ..., -0.1075, -0.0168,  0.0400],\n",
       "                       [ 0.0162, -0.0892,  0.0804,  ..., -0.0030, -0.0698, -0.0484],\n",
       "                       ...,\n",
       "                       [-0.0330, -0.0113, -0.1409,  ...,  0.0900, -0.0958, -0.0186],\n",
       "                       [-0.0904, -0.1266, -0.2842,  ..., -0.0616,  0.0853, -0.0734],\n",
       "                       [ 0.2295,  0.0503, -0.0844,  ...,  0.1191,  0.0288,  0.0951]])),\n",
       "              ('decoder.layers.6.self_attn.q_proj.bias',\n",
       "               tensor([-0.0515,  0.1053,  0.0214,  ..., -0.1320,  0.0675,  0.1046])),\n",
       "              ('decoder.layers.6.self_attn.out_proj.weight',\n",
       "               tensor([[-0.1147,  0.2338, -0.1046,  ...,  0.2319,  0.0672, -0.2388],\n",
       "                       [ 0.1044,  0.0134, -0.0280,  ...,  0.0224,  0.1283, -0.2517],\n",
       "                       [-0.2566,  0.0957,  0.2240,  ..., -0.1381, -0.0947, -0.1735],\n",
       "                       ...,\n",
       "                       [ 0.2170,  0.2080,  0.0285,  ..., -0.1484,  0.0594, -0.2524],\n",
       "                       [ 0.1270, -0.0639,  0.0111,  ..., -0.0315, -0.1620,  0.0299],\n",
       "                       [-0.1211,  0.1225,  0.2007,  ..., -0.0151, -0.0817, -0.1265]])),\n",
       "              ('decoder.layers.6.self_attn.out_proj.bias',\n",
       "               tensor([ 0.2424, -0.1144,  0.1170,  ...,  0.0485,  0.0418, -0.1606])),\n",
       "              ('decoder.layers.6.self_attn_layer_norm.weight',\n",
       "               tensor([0.5229, 0.4312, 0.4841,  ..., 0.5254, 0.4497, 0.4980])),\n",
       "              ('decoder.layers.6.self_attn_layer_norm.bias',\n",
       "               tensor([-0.0024,  0.0086, -0.0012,  ...,  0.0001, -0.0093,  0.0079])),\n",
       "              ('decoder.layers.6.encoder_attn.k_proj.weight',\n",
       "               tensor([[ 0.0065,  0.0238, -0.0940,  ...,  0.0051, -0.1252, -0.1323],\n",
       "                       [-0.0740,  0.3105,  0.1098,  ...,  0.0591,  0.0163, -0.1287],\n",
       "                       [-0.0706, -0.2991,  0.1542,  ...,  0.0607,  0.0285,  0.0554],\n",
       "                       ...,\n",
       "                       [-0.0714,  0.1831, -0.1215,  ...,  0.0681, -0.0816,  0.0187],\n",
       "                       [-0.1588,  0.0793, -0.1233,  ...,  0.0388,  0.1331,  0.0163],\n",
       "                       [ 0.1659, -0.0778, -0.0504,  ..., -0.0279, -0.0419, -0.0963]])),\n",
       "              ('decoder.layers.6.encoder_attn.k_proj.bias',\n",
       "               tensor([ 0.0164,  0.0156, -0.0284,  ..., -0.0840,  0.0870, -0.0682])),\n",
       "              ('decoder.layers.6.encoder_attn.v_proj.weight',\n",
       "               tensor([[-0.0749,  0.0461,  0.0313,  ..., -0.0856, -0.0391, -0.0072],\n",
       "                       [ 0.0308,  0.0079, -0.0509,  ..., -0.1931, -0.0545,  0.0373],\n",
       "                       [ 0.0282,  0.1117,  0.0186,  ..., -0.1887,  0.0296,  0.0780],\n",
       "                       ...,\n",
       "                       [ 0.0486, -0.3474,  0.0683,  ...,  0.0891,  0.0983,  0.1052],\n",
       "                       [-0.0300, -0.0735, -0.1410,  ...,  0.0648,  0.0901,  0.3562],\n",
       "                       [-0.1570,  0.1178, -0.0397,  ...,  0.0833, -0.0295,  0.0057]])),\n",
       "              ('decoder.layers.6.encoder_attn.v_proj.bias',\n",
       "               tensor([ 0.0067, -0.0137,  0.0381,  ..., -0.0365,  0.0369, -0.0719])),\n",
       "              ('decoder.layers.6.encoder_attn.q_proj.weight',\n",
       "               tensor([[ 0.0112, -0.1100,  0.0201,  ...,  0.0037, -0.1907,  0.0234],\n",
       "                       [ 0.1392, -0.1262,  0.0670,  ..., -0.0494, -0.0432,  0.1608],\n",
       "                       [-0.1580,  0.1534,  0.1111,  ...,  0.0828, -0.0858,  0.0805],\n",
       "                       ...,\n",
       "                       [-0.1119, -0.0174,  0.0743,  ...,  0.0930, -0.0041, -0.0556],\n",
       "                       [-0.1017, -0.0908, -0.0260,  ...,  0.1124, -0.0148, -0.1261],\n",
       "                       [-0.1282,  0.1279, -0.2107,  ..., -0.0665, -0.0160, -0.0367]])),\n",
       "              ('decoder.layers.6.encoder_attn.q_proj.bias',\n",
       "               tensor([-0.0692,  0.0267,  0.0504,  ..., -0.0051, -0.1669,  0.0866])),\n",
       "              ('decoder.layers.6.encoder_attn.out_proj.weight',\n",
       "               tensor([[ 0.0404, -0.1014,  0.1213,  ..., -0.1267, -0.0035, -0.1058],\n",
       "                       [ 0.1077,  0.0522, -0.1461,  ...,  0.0780,  0.1074, -0.1002],\n",
       "                       [ 0.0367,  0.0405, -0.2401,  ..., -0.0335, -0.1487,  0.0866],\n",
       "                       ...,\n",
       "                       [ 0.0974, -0.0179, -0.0220,  ...,  0.0031, -0.1689, -0.1240],\n",
       "                       [ 0.0128,  0.2234,  0.0302,  ..., -0.1021, -0.0682, -0.1852],\n",
       "                       [ 0.1083,  0.0522,  0.0757,  ...,  0.0560,  0.0125,  0.0388]])),\n",
       "              ('decoder.layers.6.encoder_attn.out_proj.bias',\n",
       "               tensor([ 0.1079, -0.0066,  0.0239,  ...,  0.0006,  0.0316, -0.0336])),\n",
       "              ('decoder.layers.6.encoder_attn_layer_norm.weight',\n",
       "               tensor([0.6436, 0.4639, 0.6128,  ..., 0.6382, 0.5112, 0.5615])),\n",
       "              ('decoder.layers.6.encoder_attn_layer_norm.bias',\n",
       "               tensor([ 0.0330,  0.0620, -0.0577,  ..., -0.0435, -0.0143,  0.0365])),\n",
       "              ('decoder.layers.6.fc1.weight',\n",
       "               tensor([[-1.0777e-04,  1.8945e-01, -2.1973e-02,  ..., -1.4880e-01,\n",
       "                        -5.2185e-02,  3.3569e-02],\n",
       "                       [ 2.0044e-01,  2.2827e-01,  5.8838e-02,  ...,  1.1841e-01,\n",
       "                        -1.4612e-01, -7.9880e-03],\n",
       "                       [ 1.2073e-01, -6.2744e-02,  9.7351e-02,  ..., -1.7932e-01,\n",
       "                        -1.2347e-01, -5.5481e-02],\n",
       "                       ...,\n",
       "                       [ 1.1981e-01,  2.8015e-02,  3.0685e-02,  ..., -9.4238e-02,\n",
       "                         5.1117e-02, -8.0811e-02],\n",
       "                       [ 1.6467e-01, -2.4902e-01,  1.4807e-01,  ..., -6.9031e-02,\n",
       "                        -1.5234e-01, -3.7422e-03],\n",
       "                       [ 2.0154e-01,  7.9529e-02,  1.0315e-01,  ...,  2.6733e-02,\n",
       "                        -5.4932e-02,  4.7340e-03]])),\n",
       "              ('decoder.layers.6.fc1.bias',\n",
       "               tensor([-0.0917, -0.1289, -0.1093,  ..., -0.0746, -0.1740, -0.1472])),\n",
       "              ('decoder.layers.6.fc2.weight',\n",
       "               tensor([[-7.7393e-02,  5.0278e-03, -2.3669e-01,  ..., -3.0487e-02,\n",
       "                         8.7097e-02,  3.2990e-02],\n",
       "                       [ 4.1534e-02, -2.3547e-01,  7.3975e-02,  ...,  7.5722e-03,\n",
       "                        -2.5684e-01, -1.4929e-01],\n",
       "                       [ 4.8218e-02,  5.1758e-02,  1.6589e-01,  ...,  2.8174e-01,\n",
       "                        -1.9861e-01, -3.7323e-02],\n",
       "                       ...,\n",
       "                       [-1.2598e-01,  1.8225e-01,  6.7282e-04,  ..., -1.1395e-01,\n",
       "                        -4.5357e-03,  1.6199e-01],\n",
       "                       [-6.8604e-02,  1.3342e-01,  1.1005e-01,  ..., -3.0609e-02,\n",
       "                        -1.6101e-01, -2.1973e-01],\n",
       "                       [ 2.6077e-02, -2.0921e-05,  7.9712e-02,  ..., -6.9153e-02,\n",
       "                         3.1342e-02,  1.4320e-02]])),\n",
       "              ('decoder.layers.6.fc2.bias',\n",
       "               tensor([-0.3198,  0.0277, -0.1731,  ..., -0.1162, -0.2554,  0.0232])),\n",
       "              ('decoder.layers.6.final_layer_norm.weight',\n",
       "               tensor([0.4922, 0.3796, 0.4490,  ..., 0.5151, 0.4060, 0.4561])),\n",
       "              ('decoder.layers.6.final_layer_norm.bias',\n",
       "               tensor([-0.0504,  0.0013, -0.0929,  ..., -0.0189,  0.0045,  0.0685])),\n",
       "              ('decoder.layers.7.self_attn.k_proj.weight',\n",
       "               tensor([[-0.0385,  0.1639, -0.1671,  ..., -0.1862, -0.0665,  0.2195],\n",
       "                       [ 0.1179, -0.1627, -0.1599,  ..., -0.1473, -0.0834, -0.0254],\n",
       "                       [-0.0060, -0.1333, -0.0382,  ..., -0.0690,  0.1628, -0.1013],\n",
       "                       ...,\n",
       "                       [ 0.1183,  0.0398,  0.1183,  ...,  0.1263,  0.0163,  0.0625],\n",
       "                       [ 0.2205, -0.0653, -0.0317,  ..., -0.0928,  0.0259,  0.3147],\n",
       "                       [ 0.1898, -0.0694,  0.1674,  ..., -0.0693,  0.1389,  0.1198]])),\n",
       "              ('decoder.layers.7.self_attn.k_proj.bias',\n",
       "               tensor([ 0.0279,  0.0121,  0.0115,  ..., -0.0646,  0.0035,  0.0450])),\n",
       "              ('decoder.layers.7.self_attn.v_proj.weight',\n",
       "               tensor([[ 0.1721, -0.0085,  0.0939,  ..., -0.0120, -0.2030,  0.0523],\n",
       "                       [-0.0573,  0.0412,  0.0567,  ..., -0.0467, -0.1107, -0.1677],\n",
       "                       [ 0.5381, -0.0884, -0.1873,  ...,  0.1083, -0.1586,  0.0511],\n",
       "                       ...,\n",
       "                       [ 0.0074, -0.1182, -0.0395,  ..., -0.1610, -0.1295,  0.0152],\n",
       "                       [-0.0444,  0.0070, -0.2390,  ...,  0.1454,  0.0394,  0.0155],\n",
       "                       [-0.0411, -0.1251, -0.1997,  ...,  0.0621,  0.0562,  0.1103]])),\n",
       "              ('decoder.layers.7.self_attn.v_proj.bias',\n",
       "               tensor([-0.0446,  0.0688,  0.0441,  ...,  0.0404,  0.0883, -0.0257])),\n",
       "              ('decoder.layers.7.self_attn.q_proj.weight',\n",
       "               tensor([[ 0.0305,  0.1628, -0.1603,  ..., -0.0591,  0.0294,  0.0282],\n",
       "                       [ 0.0672,  0.0061, -0.0264,  ..., -0.0125, -0.1500,  0.0111],\n",
       "                       [-0.0566, -0.1938,  0.0309,  ..., -0.3103, -0.0507, -0.1125],\n",
       "                       ...,\n",
       "                       [ 0.2722, -0.2144, -0.0305,  ..., -0.0223, -0.0433,  0.0107],\n",
       "                       [-0.1459,  0.1180,  0.0729,  ...,  0.0184,  0.0313,  0.1209],\n",
       "                       [ 0.1460,  0.0054,  0.3049,  ..., -0.0801,  0.0684, -0.0511]])),\n",
       "              ('decoder.layers.7.self_attn.q_proj.bias',\n",
       "               tensor([ 0.0145, -0.0660, -0.0961,  ..., -0.0491,  0.0969, -0.2336])),\n",
       "              ('decoder.layers.7.self_attn.out_proj.weight',\n",
       "               tensor([[ 2.0300e-01, -6.0028e-02,  9.9609e-02,  ...,  1.7554e-01,\n",
       "                         1.7195e-03,  2.7374e-02],\n",
       "                       [ 1.2830e-01, -2.1851e-01, -9.6008e-02,  ...,  2.6099e-01,\n",
       "                        -1.9775e-01, -3.2227e-02],\n",
       "                       [-1.5335e-02, -1.9789e-04,  3.1567e-01,  ..., -6.6345e-02,\n",
       "                        -6.6589e-02, -7.0984e-02],\n",
       "                       ...,\n",
       "                       [-9.4223e-03,  7.7820e-02,  8.2397e-02,  ..., -7.4585e-02,\n",
       "                        -2.4551e-02,  2.1057e-01],\n",
       "                       [-5.9540e-02,  6.7322e-02, -4.2511e-02,  ...,  3.0930e-02,\n",
       "                         1.8433e-01,  1.6187e-01],\n",
       "                       [-1.5210e-01,  9.3445e-02,  5.4703e-03,  ...,  8.2458e-02,\n",
       "                        -4.7569e-03,  6.1218e-02]])),\n",
       "              ('decoder.layers.7.self_attn.out_proj.bias',\n",
       "               tensor([ 0.2078, -0.0880,  0.1757,  ...,  0.0544,  0.1226, -0.1289])),\n",
       "              ('decoder.layers.7.self_attn_layer_norm.weight',\n",
       "               tensor([0.4976, 0.4365, 0.4631,  ..., 0.5171, 0.4065, 0.4460])),\n",
       "              ('decoder.layers.7.self_attn_layer_norm.bias',\n",
       "               tensor([-0.0044,  0.0069, -0.0077,  ...,  0.0042, -0.0129,  0.0109])),\n",
       "              ('decoder.layers.7.encoder_attn.k_proj.weight',\n",
       "               tensor([[ 0.0245, -0.1670, -0.0526,  ...,  0.0576, -0.1746,  0.1126],\n",
       "                       [ 0.1257, -0.1090,  0.0563,  ..., -0.0017,  0.1312,  0.0300],\n",
       "                       [ 0.1250, -0.1744,  0.1114,  ..., -0.0978, -0.0208,  0.0953],\n",
       "                       ...,\n",
       "                       [-0.1276, -0.0507,  0.0598,  ...,  0.0220, -0.1138,  0.1058],\n",
       "                       [-0.0075,  0.1722, -0.1174,  ...,  0.0688,  0.0069,  0.0157],\n",
       "                       [ 0.2815, -0.1125, -0.1832,  ..., -0.1635,  0.0642, -0.0563]])),\n",
       "              ('decoder.layers.7.encoder_attn.k_proj.bias',\n",
       "               tensor([-0.0984,  0.2798,  0.4146,  ..., -0.0051,  0.0215, -0.0272])),\n",
       "              ('decoder.layers.7.encoder_attn.v_proj.weight',\n",
       "               tensor([[ 0.0249, -0.1344, -0.2058,  ..., -0.0308,  0.0215, -0.0068],\n",
       "                       [-0.0600, -0.0008,  0.0887,  ..., -0.1693, -0.0440,  0.0751],\n",
       "                       [-0.0994, -0.1221, -0.0857,  ..., -0.2109,  0.1353, -0.1383],\n",
       "                       ...,\n",
       "                       [ 0.1103, -0.0281, -0.0506,  ...,  0.0528, -0.1263,  0.0970],\n",
       "                       [-0.1191,  0.0161,  0.1460,  ...,  0.3462, -0.0954, -0.2151],\n",
       "                       [ 0.1146,  0.2242, -0.2301,  ..., -0.0300, -0.1302,  0.1761]])),\n",
       "              ('decoder.layers.7.encoder_attn.v_proj.bias',\n",
       "               tensor([ 0.0094,  0.1192,  0.0119,  ...,  0.0191, -0.0127,  0.0119])),\n",
       "              ('decoder.layers.7.encoder_attn.q_proj.weight',\n",
       "               tensor([[-0.0507,  0.0503,  0.1483,  ..., -0.0362,  0.1710,  0.0962],\n",
       "                       [-0.0995,  0.0684, -0.1575,  ...,  0.0081,  0.1165,  0.0261],\n",
       "                       [ 0.2654,  0.1527, -0.1746,  ..., -0.1118, -0.1487,  0.1843],\n",
       "                       ...,\n",
       "                       [-0.3105,  0.0315, -0.1399,  ..., -0.1510, -0.2737,  0.0720],\n",
       "                       [-0.3179,  0.1655,  0.0681,  ..., -0.0453,  0.1930,  0.0764],\n",
       "                       [ 0.1954,  0.0247,  0.0060,  ...,  0.0462,  0.0641,  0.0021]])),\n",
       "              ('decoder.layers.7.encoder_attn.q_proj.bias',\n",
       "               tensor([-0.0716,  0.1023,  0.1481,  ...,  0.0455, -0.0551,  0.1885])),\n",
       "              ('decoder.layers.7.encoder_attn.out_proj.weight',\n",
       "               tensor([[-1.2091e-01, -2.7878e-02,  1.1395e-01,  ..., -1.2805e-01,\n",
       "                        -7.8491e-02,  8.0811e-02],\n",
       "                       [-3.0835e-01, -8.6853e-02,  3.4961e-01,  ...,  3.1348e-01,\n",
       "                         1.7310e-01,  8.9417e-02],\n",
       "                       [ 2.8979e-01, -1.1816e-01,  1.0571e-01,  ..., -7.1289e-02,\n",
       "                        -1.5259e-01,  1.4270e-01],\n",
       "                       ...,\n",
       "                       [ 2.2674e-04, -1.7444e-01,  1.5144e-02,  ..., -1.7200e-01,\n",
       "                         2.4231e-02,  7.5317e-02],\n",
       "                       [-1.2619e-02,  2.7930e-01,  2.5122e-01,  ..., -2.3242e-01,\n",
       "                        -1.2311e-01,  1.3100e-02],\n",
       "                       [ 1.5099e-02, -1.1890e-01, -2.5195e-01,  ...,  1.1328e-01,\n",
       "                        -2.6489e-01,  9.7229e-02]])),\n",
       "              ('decoder.layers.7.encoder_attn.out_proj.bias',\n",
       "               tensor([ 0.0940,  0.0273,  0.1245,  ...,  0.0941,  0.0425, -0.0217])),\n",
       "              ('decoder.layers.7.encoder_attn_layer_norm.weight',\n",
       "               tensor([0.7158, 0.5625, 0.6367,  ..., 0.6367, 0.5361, 0.5435])),\n",
       "              ('decoder.layers.7.encoder_attn_layer_norm.bias',\n",
       "               tensor([-0.0972,  0.0514, -0.1569,  ...,  0.0345, -0.0586,  0.0750])),\n",
       "              ('decoder.layers.7.fc1.weight',\n",
       "               tensor([[-0.3657, -0.0182,  0.0709,  ..., -0.0529, -0.1001, -0.1749],\n",
       "                       [-0.1539, -0.0005, -0.0856,  ...,  0.0039,  0.1868, -0.0227],\n",
       "                       [ 0.0428,  0.0212, -0.0947,  ..., -0.1099,  0.0600,  0.1111],\n",
       "                       ...,\n",
       "                       [-0.1343, -0.0869,  0.0999,  ...,  0.0521, -0.0162,  0.0732],\n",
       "                       [ 0.0784,  0.0899, -0.1389,  ..., -0.1271, -0.1475, -0.0564],\n",
       "                       [-0.0911,  0.1349,  0.0210,  ...,  0.1238, -0.2910, -0.1494]])),\n",
       "              ('decoder.layers.7.fc1.bias',\n",
       "               tensor([-0.0992, -0.1006, -0.1002,  ..., -0.1299, -0.1403, -0.1555])),\n",
       "              ('decoder.layers.7.fc2.weight',\n",
       "               tensor([[ 0.2668,  0.1819,  0.2330,  ...,  0.1126,  0.1567,  0.0586],\n",
       "                       [-0.1735,  0.0829, -0.1273,  ...,  0.1895,  0.0062, -0.1082],\n",
       "                       [ 0.0091,  0.0622,  0.3406,  ..., -0.0493, -0.1332,  0.1228],\n",
       "                       ...,\n",
       "                       [ 0.0857, -0.1129,  0.0966,  ..., -0.1819, -0.1436,  0.1511],\n",
       "                       [ 0.0136,  0.0894, -0.0143,  ...,  0.3652, -0.1486,  0.0511],\n",
       "                       [ 0.0666,  0.3240, -0.1456,  ...,  0.0515, -0.0450,  0.1539]])),\n",
       "              ('decoder.layers.7.fc2.bias',\n",
       "               tensor([-0.3992,  0.1106, -0.1786,  ..., -0.1676,  0.0022, -0.0616])),\n",
       "              ('decoder.layers.7.final_layer_norm.weight',\n",
       "               tensor([0.5103, 0.3926, 0.4670,  ..., 0.4998, 0.4226, 0.4634])),\n",
       "              ('decoder.layers.7.final_layer_norm.bias',\n",
       "               tensor([-0.0680, -0.0028, -0.0883,  ..., -0.0221, -0.0025,  0.0563])),\n",
       "              ('decoder.layers.8.self_attn.k_proj.weight',\n",
       "               tensor([[ 0.0596,  0.0790, -0.0220,  ...,  0.0967,  0.1556,  0.0983],\n",
       "                       [ 0.0184,  0.0146,  0.1757,  ..., -0.0106,  0.0409, -0.1261],\n",
       "                       [-0.0403, -0.0829, -0.3000,  ..., -0.1155,  0.0003,  0.0549],\n",
       "                       ...,\n",
       "                       [ 0.0088,  0.1159,  0.0093,  ..., -0.0657, -0.0469,  0.0194],\n",
       "                       [-0.0215, -0.1372, -0.0121,  ...,  0.1941, -0.1019, -0.0754],\n",
       "                       [ 0.2905,  0.0428,  0.0430,  ...,  0.0646,  0.1940, -0.0101]])),\n",
       "              ('decoder.layers.8.self_attn.k_proj.bias',\n",
       "               tensor([-0.0145, -0.2335, -0.0996,  ..., -0.0334, -0.4180,  0.1766])),\n",
       "              ('decoder.layers.8.self_attn.v_proj.weight',\n",
       "               tensor([[ 1.2793e-01,  1.8689e-01,  3.3932e-03,  ..., -6.8298e-02,\n",
       "                         4.8645e-02,  1.4148e-01],\n",
       "                       [ 2.7002e-01, -1.8814e-02,  1.0431e-01,  ...,  2.6416e-01,\n",
       "                        -5.6946e-02, -9.8145e-02],\n",
       "                       [-2.0276e-01, -1.9177e-01, -6.4514e-02,  ..., -1.5002e-01,\n",
       "                        -4.2877e-02,  8.5602e-03],\n",
       "                       ...,\n",
       "                       [-2.1936e-01,  2.8052e-01,  5.5084e-03,  ...,  1.6455e-01,\n",
       "                        -6.0394e-02,  1.5503e-01],\n",
       "                       [-3.0615e-01,  2.9588e-04, -1.4941e-01,  ..., -3.6011e-01,\n",
       "                        -5.2429e-02,  1.5454e-01],\n",
       "                       [ 1.0852e-01,  2.7664e-02, -5.9601e-02,  ...,  6.3354e-02,\n",
       "                         2.6587e-01, -1.2225e-01]])),\n",
       "              ('decoder.layers.8.self_attn.v_proj.bias',\n",
       "               tensor([-0.0209,  0.0556, -0.0327,  ...,  0.0407,  0.0089,  0.0425])),\n",
       "              ('decoder.layers.8.self_attn.q_proj.weight',\n",
       "               tensor([[-0.0196,  0.0737, -0.2137,  ...,  0.1205, -0.1198,  0.1219],\n",
       "                       [-0.0450,  0.0898,  0.0273,  ...,  0.0947,  0.0906,  0.0875],\n",
       "                       [ 0.0844,  0.1656, -0.0240,  ...,  0.1567, -0.0262, -0.0932],\n",
       "                       ...,\n",
       "                       [ 0.0811,  0.0720,  0.0170,  ..., -0.0942,  0.0996, -0.0639],\n",
       "                       [-0.0643, -0.0095,  0.1000,  ..., -0.1333, -0.0416,  0.1505],\n",
       "                       [ 0.1924,  0.0506,  0.3726,  ...,  0.0232,  0.0009, -0.1917]])),\n",
       "              ('decoder.layers.8.self_attn.q_proj.bias',\n",
       "               tensor([-0.0236,  0.1105,  0.1417,  ...,  0.0942,  0.3479, -0.1447])),\n",
       "              ('decoder.layers.8.self_attn.out_proj.weight',\n",
       "               tensor([[ 0.0988, -0.0338,  0.0445,  ..., -0.1056,  0.0768,  0.2305],\n",
       "                       [-0.0906, -0.2098, -0.1183,  ..., -0.0007, -0.0298, -0.0407],\n",
       "                       [ 0.2649,  0.0076,  0.1409,  ...,  0.0516,  0.1918, -0.0148],\n",
       "                       ...,\n",
       "                       [ 0.1077, -0.0894,  0.0715,  ...,  0.1367, -0.0138,  0.0178],\n",
       "                       [ 0.1199, -0.0442, -0.0371,  ...,  0.1281,  0.0290,  0.1898],\n",
       "                       [ 0.2371, -0.2764,  0.0085,  ..., -0.3008,  0.1945, -0.1028]])),\n",
       "              ('decoder.layers.8.self_attn.out_proj.bias',\n",
       "               tensor([ 0.1231, -0.0079,  0.1250,  ...,  0.0159,  0.1375, -0.1388])),\n",
       "              ('decoder.layers.8.self_attn_layer_norm.weight',\n",
       "               tensor([0.4749, 0.4619, 0.4675,  ..., 0.4998, 0.3921, 0.4871])),\n",
       "              ('decoder.layers.8.self_attn_layer_norm.bias',\n",
       "               tensor([-0.0082,  0.0123, -0.0085,  ...,  0.0059, -0.0169,  0.0143])),\n",
       "              ('decoder.layers.8.encoder_attn.k_proj.weight',\n",
       "               tensor([[-0.1558, -0.0334, -0.0861,  ..., -0.1814,  0.0158,  0.0368],\n",
       "                       [-0.0395,  0.0696,  0.0633,  ...,  0.1080, -0.0630, -0.2039],\n",
       "                       [ 0.0818,  0.1316,  0.1021,  ..., -0.0909,  0.0105,  0.0538],\n",
       "                       ...,\n",
       "                       [ 0.0728, -0.0531, -0.0685,  ...,  0.0926, -0.0541,  0.2024],\n",
       "                       [-0.0513,  0.2935, -0.1864,  ...,  0.2391, -0.0846, -0.0801],\n",
       "                       [ 0.0551,  0.1234,  0.3455,  ...,  0.1786, -0.0253,  0.1677]])),\n",
       "              ('decoder.layers.8.encoder_attn.k_proj.bias',\n",
       "               tensor([-0.0090, -0.0025, -0.0098,  ..., -0.0134,  0.0235,  0.0257])),\n",
       "              ('decoder.layers.8.encoder_attn.v_proj.weight',\n",
       "               tensor([[ 0.0307, -0.2354, -0.0018,  ..., -0.0189, -0.0266, -0.1310],\n",
       "                       [ 0.0866, -0.3074,  0.0539,  ..., -0.0581,  0.1210, -0.0969],\n",
       "                       [ 0.0128,  0.0737, -0.1281,  ..., -0.0078, -0.0612,  0.0178],\n",
       "                       ...,\n",
       "                       [ 0.2042, -0.1150,  0.0463,  ...,  0.0550,  0.1190, -0.0269],\n",
       "                       [-0.1231, -0.1913, -0.1768,  ...,  0.0118, -0.2172,  0.0025],\n",
       "                       [ 0.1942,  0.0092, -0.1685,  ...,  0.0287, -0.0011,  0.0915]])),\n",
       "              ('decoder.layers.8.encoder_attn.v_proj.bias',\n",
       "               tensor([ 0.0253,  0.0264, -0.0629,  ...,  0.0199,  0.0018,  0.0526])),\n",
       "              ('decoder.layers.8.encoder_attn.q_proj.weight',\n",
       "               tensor([[ 4.9103e-02,  1.0852e-01, -1.7444e-01,  ...,  1.6296e-01,\n",
       "                        -1.3562e-01,  8.0139e-02],\n",
       "                       [-4.4098e-02,  2.7740e-02,  2.2229e-01,  ..., -5.1208e-02,\n",
       "                         1.7896e-01, -8.2703e-02],\n",
       "                       [ 5.1331e-02,  6.5430e-02, -4.8248e-02,  ...,  7.2449e-02,\n",
       "                        -5.5923e-03, -7.8552e-02],\n",
       "                       ...,\n",
       "                       [-5.4932e-02, -1.5552e-01,  4.0985e-02,  ..., -1.4490e-01,\n",
       "                        -2.9443e-01,  2.9883e-01],\n",
       "                       [ 1.4417e-01, -1.1818e-02, -2.6464e-05,  ..., -1.8768e-02,\n",
       "                         1.6931e-01, -3.5858e-02],\n",
       "                       [ 1.0284e-01,  1.2012e-01, -3.3386e-02,  ..., -5.7030e-04,\n",
       "                        -7.9651e-02,  8.8928e-02]])),\n",
       "              ('decoder.layers.8.encoder_attn.q_proj.bias',\n",
       "               tensor([-0.0586, -0.0687,  0.0369,  ..., -0.0286,  0.0285, -0.0877])),\n",
       "              ('decoder.layers.8.encoder_attn.out_proj.weight',\n",
       "               tensor([[ 0.0353, -0.1409,  0.0250,  ...,  0.0442, -0.0160, -0.0634],\n",
       "                       [ 0.0237, -0.0248, -0.0827,  ...,  0.1443,  0.1194,  0.0335],\n",
       "                       [-0.0492,  0.0109,  0.0456,  ...,  0.0092,  0.1514,  0.0084],\n",
       "                       ...,\n",
       "                       [ 0.0595,  0.1247, -0.0757,  ..., -0.0295, -0.1782,  0.0834],\n",
       "                       [ 0.1302, -0.0648, -0.1577,  ..., -0.0241, -0.0905,  0.1533],\n",
       "                       [ 0.1068, -0.1182, -0.1271,  ..., -0.2100, -0.0576, -0.1208]])),\n",
       "              ('decoder.layers.8.encoder_attn.out_proj.bias',\n",
       "               tensor([0.1807, 0.0319, 0.0729,  ..., 0.0284, 0.0486, 0.0093])),\n",
       "              ('decoder.layers.8.encoder_attn_layer_norm.weight',\n",
       "               tensor([0.6724, 0.5518, 0.5977,  ..., 0.5981, 0.5176, 0.5435])),\n",
       "              ('decoder.layers.8.encoder_attn_layer_norm.bias',\n",
       "               tensor([-0.0959,  0.0515, -0.1227,  ..., -0.0108, -0.0401,  0.0380])),\n",
       "              ('decoder.layers.8.fc1.weight',\n",
       "               tensor([[-0.0597, -0.0645, -0.1675,  ...,  0.0709, -0.0213,  0.1057],\n",
       "                       [-0.0634,  0.0073,  0.1327,  ...,  0.0128,  0.0997,  0.0640],\n",
       "                       [ 0.0317,  0.0419, -0.0321,  ..., -0.1464,  0.0820, -0.0150],\n",
       "                       ...,\n",
       "                       [ 0.3247,  0.1016,  0.1367,  ...,  0.2046, -0.1724,  0.0215],\n",
       "                       [ 0.0080, -0.0641,  0.0066,  ...,  0.0994, -0.1628,  0.0280],\n",
       "                       [-0.0229, -0.0753, -0.0199,  ..., -0.0164, -0.0358,  0.0152]])),\n",
       "              ('decoder.layers.8.fc1.bias',\n",
       "               tensor([-0.1169, -0.1034, -0.0700,  ..., -0.2275, -0.0877, -0.0922])),\n",
       "              ('decoder.layers.8.fc2.weight',\n",
       "               tensor([[-0.0407,  0.1172, -0.0723,  ..., -0.0575,  0.0575,  0.1365],\n",
       "                       [-0.1704,  0.0645, -0.0934,  ...,  0.1906, -0.0253, -0.0024],\n",
       "                       [-0.0457,  0.0590,  0.0822,  ..., -0.0452,  0.0997, -0.0854],\n",
       "                       ...,\n",
       "                       [-0.0709,  0.0297,  0.2053,  ...,  0.4092, -0.0303,  0.0800],\n",
       "                       [ 0.0603,  0.0637, -0.1570,  ...,  0.0179,  0.0691, -0.2959],\n",
       "                       [-0.1357, -0.3691, -0.0329,  ...,  0.1907, -0.0806, -0.0547]])),\n",
       "              ('decoder.layers.8.fc2.bias',\n",
       "               tensor([-0.4683, -0.0248, -0.0676,  ..., -0.0856, -0.0165, -0.2325])),\n",
       "              ('decoder.layers.8.final_layer_norm.weight',\n",
       "               tensor([0.5479, 0.4263, 0.4612,  ..., 0.5039, 0.4441, 0.4907])),\n",
       "              ('decoder.layers.8.final_layer_norm.bias',\n",
       "               tensor([-0.1124, -0.0166, -0.1109,  ..., -0.0196, -0.0138,  0.0490])),\n",
       "              ('decoder.layers.9.self_attn.k_proj.weight',\n",
       "               tensor([[ 0.2019, -0.0502, -0.0692,  ..., -0.0263, -0.0955, -0.0784],\n",
       "                       [-0.0114,  0.1375, -0.1617,  ..., -0.1151, -0.0335,  0.0153],\n",
       "                       [-0.0053, -0.0672,  0.1002,  ..., -0.0355, -0.3101,  0.0193],\n",
       "                       ...,\n",
       "                       [-0.0673,  0.0879, -0.1531,  ...,  0.0861, -0.0211, -0.0358],\n",
       "                       [-0.1396,  0.1459,  0.1311,  ...,  0.2084,  0.1991, -0.0171],\n",
       "                       [-0.2056, -0.2499,  0.0156,  ...,  0.0456, -0.1453, -0.0092]])),\n",
       "              ('decoder.layers.9.self_attn.k_proj.bias',\n",
       "               tensor([ 0.0294,  0.0174,  0.0298,  ..., -0.0138, -0.0130, -0.0278])),\n",
       "              ('decoder.layers.9.self_attn.v_proj.weight',\n",
       "               tensor([[ 0.0912, -0.1333, -0.0352,  ...,  0.1268,  0.1707, -0.0867],\n",
       "                       [ 0.2195, -0.1504,  0.0563,  ..., -0.0206, -0.2661, -0.0058],\n",
       "                       [-0.0613, -0.2189,  0.0687,  ...,  0.0487, -0.1125,  0.0866],\n",
       "                       ...,\n",
       "                       [-0.0608,  0.1197,  0.0081,  ...,  0.0960, -0.1202, -0.0785],\n",
       "                       [-0.2341, -0.2771, -0.0115,  ..., -0.1053, -0.1509,  0.1333],\n",
       "                       [ 0.0280, -0.1925, -0.1053,  ...,  0.1185, -0.0175,  0.0491]])),\n",
       "              ('decoder.layers.9.self_attn.v_proj.bias',\n",
       "               tensor([-0.0625, -0.0365,  0.0120,  ...,  0.0112, -0.1043,  0.0091])),\n",
       "              ('decoder.layers.9.self_attn.q_proj.weight',\n",
       "               tensor([[-0.0421,  0.0566,  0.1875,  ..., -0.2544, -0.0085,  0.0843],\n",
       "                       [ 0.0315, -0.0631,  0.1429,  ..., -0.0085,  0.1669,  0.0058],\n",
       "                       [ 0.0881,  0.0097,  0.2363,  ..., -0.1329,  0.1652, -0.0622],\n",
       "                       ...,\n",
       "                       [ 0.0151,  0.0062,  0.0205,  ..., -0.0393, -0.2482, -0.1337],\n",
       "                       [ 0.1704, -0.0814,  0.0049,  ..., -0.0504,  0.0447, -0.0153],\n",
       "                       [ 0.1849,  0.0440,  0.1267,  ..., -0.0079,  0.0687, -0.0603]])),\n",
       "              ('decoder.layers.9.self_attn.q_proj.bias',\n",
       "               tensor([-0.1530, -0.0499, -0.0612,  ...,  0.0640,  0.0620, -0.0512])),\n",
       "              ('decoder.layers.9.self_attn.out_proj.weight',\n",
       "               tensor([[-0.0978, -0.0263, -0.0521,  ..., -0.0258,  0.1855,  0.2074],\n",
       "                       [ 0.2615,  0.1194,  0.0775,  ...,  0.1241,  0.0235,  0.1593],\n",
       "                       [-0.0566,  0.0422,  0.0840,  ...,  0.2306,  0.3093,  0.2003],\n",
       "                       ...,\n",
       "                       [ 0.0568,  0.0308,  0.1733,  ..., -0.1334,  0.2683,  0.0450],\n",
       "                       [ 0.1187,  0.0945, -0.2627,  ..., -0.1329, -0.1210,  0.0047],\n",
       "                       [ 0.1545,  0.0917, -0.1149,  ..., -0.0609, -0.4382, -0.0586]])),\n",
       "              ('decoder.layers.9.self_attn.out_proj.bias',\n",
       "               tensor([ 0.1025, -0.0378,  0.2386,  ...,  0.0364,  0.0843,  0.0450])),\n",
       "              ('decoder.layers.9.self_attn_layer_norm.weight',\n",
       "               tensor([0.4958, 0.4575, 0.4468,  ..., 0.4819, 0.4097, 0.4604])),\n",
       "              ('decoder.layers.9.self_attn_layer_norm.bias',\n",
       "               tensor([-0.0169,  0.0082, -0.0089,  ...,  0.0023, -0.0106,  0.0135])),\n",
       "              ('decoder.layers.9.encoder_attn.k_proj.weight',\n",
       "               tensor([[-0.0904,  0.0157, -0.0764,  ..., -0.1353,  0.1404, -0.1478],\n",
       "                       [ 0.1528,  0.0044,  0.0177,  ...,  0.0386,  0.0781,  0.0491],\n",
       "                       [ 0.0183,  0.1003, -0.0269,  ..., -0.0077, -0.1360, -0.0841],\n",
       "                       ...,\n",
       "                       [-0.0354, -0.1046, -0.0557,  ...,  0.1877, -0.1528,  0.1011],\n",
       "                       [-0.0244, -0.0884, -0.1892,  ..., -0.1062,  0.0354,  0.3374],\n",
       "                       [ 0.0142, -0.1340,  0.0445,  ...,  0.1927, -0.0237,  0.1479]])),\n",
       "              ('decoder.layers.9.encoder_attn.k_proj.bias',\n",
       "               tensor([ 1.2705, -0.3374, -0.7881,  ...,  0.0075,  0.0028,  0.0014])),\n",
       "              ('decoder.layers.9.encoder_attn.v_proj.weight',\n",
       "               tensor([[-0.0264,  0.0616, -0.1055,  ...,  0.1746,  0.0077, -0.0135],\n",
       "                       [-0.1007,  0.1031,  0.1404,  ..., -0.0635,  0.1750, -0.0207],\n",
       "                       [-0.0111,  0.1042, -0.0100,  ...,  0.1396, -0.0018,  0.1058],\n",
       "                       ...,\n",
       "                       [-0.0775, -0.0179,  0.0091,  ...,  0.2927,  0.1827,  0.0440],\n",
       "                       [ 0.0126, -0.1951,  0.0137,  ..., -0.1296,  0.1864,  0.0291],\n",
       "                       [-0.0973, -0.1989,  0.0906,  ...,  0.0137,  0.1008,  0.0456]])),\n",
       "              ('decoder.layers.9.encoder_attn.v_proj.bias',\n",
       "               tensor([-0.0024,  0.0003,  0.0317,  ...,  0.0169, -0.0115,  0.0341])),\n",
       "              ('decoder.layers.9.encoder_attn.q_proj.weight',\n",
       "               tensor([[-0.0435,  0.1422,  0.1415,  ..., -0.0648, -0.0530,  0.0984],\n",
       "                       [-0.0557,  0.0536, -0.3403,  ...,  0.0403, -0.1127, -0.2693],\n",
       "                       [ 0.0228,  0.0297, -0.0507,  ...,  0.0673,  0.1288,  0.0742],\n",
       "                       ...,\n",
       "                       [-0.0602, -0.0205, -0.2441,  ...,  0.1832, -0.0425,  0.0352],\n",
       "                       [ 0.1097, -0.0547,  0.1846,  ...,  0.3567,  0.1781,  0.0560],\n",
       "                       [ 0.0558,  0.1007,  0.0903,  ...,  0.1084, -0.1074, -0.0220]])),\n",
       "              ('decoder.layers.9.encoder_attn.q_proj.bias',\n",
       "               tensor([ 0.4089, -0.0739, -0.1833,  ...,  0.1268,  0.0133,  0.0083])),\n",
       "              ('decoder.layers.9.encoder_attn.out_proj.weight',\n",
       "               tensor([[ 0.0334,  0.0842,  0.0823,  ...,  0.0446,  0.0533, -0.0584],\n",
       "                       [ 0.1578,  0.0912,  0.4182,  ..., -0.0056,  0.0682,  0.0294],\n",
       "                       [ 0.1383,  0.0505, -0.1733,  ...,  0.0892, -0.1971,  0.1727],\n",
       "                       ...,\n",
       "                       [-0.2559,  0.0274, -0.0567,  ..., -0.0939, -0.0165,  0.0679],\n",
       "                       [-0.0492,  0.0012,  0.1078,  ...,  0.0130,  0.1323, -0.0083],\n",
       "                       [ 0.0910,  0.0866, -0.0968,  ...,  0.0175,  0.1389, -0.0039]])),\n",
       "              ('decoder.layers.9.encoder_attn.out_proj.bias',\n",
       "               tensor([ 1.3196e-01, -1.1765e-02,  8.0872e-02,  ...,  9.7122e-03,\n",
       "                        4.6570e-02,  2.0623e-05])),\n",
       "              ('decoder.layers.9.encoder_attn_layer_norm.weight',\n",
       "               tensor([0.6997, 0.5356, 0.6104,  ..., 0.5786, 0.4995, 0.5576])),\n",
       "              ('decoder.layers.9.encoder_attn_layer_norm.bias',\n",
       "               tensor([-0.0742,  0.0385, -0.0245,  ...,  0.0036, -0.0266,  0.0104])),\n",
       "              ('decoder.layers.9.fc1.weight',\n",
       "               tensor([[ 0.0775, -0.0635,  0.1212,  ..., -0.1188, -0.1172,  0.0485],\n",
       "                       [ 0.0510, -0.0945,  0.0567,  ...,  0.0193, -0.0056, -0.0919],\n",
       "                       [-0.1342, -0.1192,  0.0777,  ..., -0.0787,  0.0388, -0.3564],\n",
       "                       ...,\n",
       "                       [-0.1504, -0.0291, -0.0145,  ...,  0.0315, -0.1149, -0.1111],\n",
       "                       [ 0.0025,  0.1218, -0.1908,  ...,  0.0224, -0.0055, -0.0526],\n",
       "                       [-0.1102,  0.0031,  0.2520,  ...,  0.0523,  0.0919, -0.0702]])),\n",
       "              ('decoder.layers.9.fc1.bias',\n",
       "               tensor([-0.1157, -0.0811, -0.0851,  ..., -0.0886, -0.0565, -0.1499])),\n",
       "              ('decoder.layers.9.fc2.weight',\n",
       "               tensor([[ 0.0619, -0.0482, -0.2172,  ...,  0.3254, -0.0557,  0.2336],\n",
       "                       [ 0.2380, -0.1359,  0.0989,  ..., -0.0492, -0.1205, -0.1006],\n",
       "                       [-0.0363, -0.0161,  0.0349,  ..., -0.2314,  0.0626,  0.1051],\n",
       "                       ...,\n",
       "                       [-0.0533, -0.0080, -0.0142,  ..., -0.0358, -0.0159,  0.2876],\n",
       "                       [-0.2302,  0.3933,  0.1702,  ...,  0.0267, -0.0537, -0.2483],\n",
       "                       [ 0.0196,  0.0910,  0.0578,  ..., -0.0432, -0.0940,  0.3491]])),\n",
       "              ('decoder.layers.9.fc2.bias',\n",
       "               tensor([-0.0244,  0.1251,  0.0875,  ..., -0.1697,  0.0734, -0.1333])),\n",
       "              ('decoder.layers.9.final_layer_norm.weight',\n",
       "               tensor([0.5527, 0.4863, 0.5034,  ..., 0.5347, 0.5063, 0.5430])),\n",
       "              ('decoder.layers.9.final_layer_norm.bias',\n",
       "               tensor([-0.1294,  0.0051, -0.0898,  ..., -0.0058, -0.0647,  0.0531])),\n",
       "              ('decoder.layers.10.self_attn.k_proj.weight',\n",
       "               tensor([[ 0.0859, -0.1000, -0.0144,  ..., -0.0449,  0.1884,  0.0243],\n",
       "                       [-0.0916, -0.2786, -0.0741,  ...,  0.0346, -0.1230,  0.0763],\n",
       "                       [ 0.0032,  0.0721, -0.1744,  ...,  0.0756,  0.0153, -0.0851],\n",
       "                       ...,\n",
       "                       [ 0.2114, -0.1393, -0.0469,  ..., -0.0792, -0.0084,  0.0330],\n",
       "                       [ 0.0113, -0.0006, -0.0656,  ..., -0.0303, -0.0654,  0.1263],\n",
       "                       [ 0.1239, -0.2534,  0.0867,  ..., -0.0481,  0.1923, -0.2783]])),\n",
       "              ('decoder.layers.10.self_attn.k_proj.bias',\n",
       "               tensor([-0.0180,  0.0786, -0.0265,  ..., -0.0494,  0.0021, -0.0445])),\n",
       "              ('decoder.layers.10.self_attn.v_proj.weight',\n",
       "               tensor([[-0.0262, -0.1201,  0.1710,  ...,  0.0646,  0.0439,  0.1921],\n",
       "                       [ 0.0618, -0.0834,  0.1447,  ...,  0.1317, -0.0865, -0.3943],\n",
       "                       [ 0.0107, -0.0684,  0.2520,  ...,  0.2832,  0.2169,  0.1265],\n",
       "                       ...,\n",
       "                       [ 0.1869, -0.0096,  0.1508,  ...,  0.0892,  0.0158, -0.0671],\n",
       "                       [ 0.1062, -0.1758,  0.1186,  ...,  0.1240,  0.1395, -0.1075],\n",
       "                       [ 0.2944, -0.0731, -0.0064,  ...,  0.3306,  0.0371,  0.1366]])),\n",
       "              ('decoder.layers.10.self_attn.v_proj.bias',\n",
       "               tensor([-0.0123,  0.0148, -0.0262,  ...,  0.0446, -0.0956, -0.0383])),\n",
       "              ('decoder.layers.10.self_attn.q_proj.weight',\n",
       "               tensor([[ 0.2142, -0.2068, -0.0286,  ...,  0.1481,  0.0024,  0.1851],\n",
       "                       [ 0.1498, -0.0326, -0.0666,  ...,  0.1421, -0.1422,  0.0452],\n",
       "                       [-0.1171, -0.0145,  0.1199,  ...,  0.0692,  0.0279, -0.2010],\n",
       "                       ...,\n",
       "                       [-0.1146,  0.0046, -0.1215,  ..., -0.1122,  0.1208, -0.1688],\n",
       "                       [-0.0433, -0.0686, -0.0688,  ..., -0.0928, -0.0511,  0.0470],\n",
       "                       [-0.2448, -0.2341, -0.0290,  ..., -0.1465,  0.1405, -0.0777]])),\n",
       "              ('decoder.layers.10.self_attn.q_proj.bias',\n",
       "               tensor([ 0.0384,  0.0264,  0.0790,  ...,  0.1416, -0.1046,  0.0371])),\n",
       "              ('decoder.layers.10.self_attn.out_proj.weight',\n",
       "               tensor([[ 0.1982, -0.2656, -0.0429,  ...,  0.1008, -0.2025, -0.3142],\n",
       "                       [ 0.0205,  0.2029, -0.2754,  ..., -0.0392, -0.0843, -0.0269],\n",
       "                       [-0.2002,  0.2612, -0.0444,  ...,  0.0271, -0.0632, -0.1886],\n",
       "                       ...,\n",
       "                       [ 0.0127,  0.0526,  0.0615,  ...,  0.3279,  0.0417,  0.2886],\n",
       "                       [-0.0349, -0.2593, -0.0703,  ..., -0.1243, -0.0289,  0.0522],\n",
       "                       [ 0.3015, -0.0396, -0.0289,  ..., -0.0921, -0.0057,  0.1897]])),\n",
       "              ('decoder.layers.10.self_attn.out_proj.bias',\n",
       "               tensor([ 0.0098, -0.2620,  0.4673,  ...,  0.0557,  0.1235, -0.0511])),\n",
       "              ('decoder.layers.10.self_attn_layer_norm.weight',\n",
       "               tensor([0.4631, 0.4285, 0.4419,  ..., 0.4644, 0.4443, 0.4712])),\n",
       "              ('decoder.layers.10.self_attn_layer_norm.bias',\n",
       "               tensor([-0.0205,  0.0064, -0.0090,  ..., -0.0005, -0.0208,  0.0122])),\n",
       "              ('decoder.layers.10.encoder_attn.k_proj.weight',\n",
       "               tensor([[-0.0637,  0.1049,  0.0273,  ...,  0.0494, -0.0035,  0.0058],\n",
       "                       [ 0.2094, -0.0608, -0.0100,  ...,  0.1287, -0.0105, -0.0774],\n",
       "                       [-0.1149,  0.0198,  0.0340,  ...,  0.0734,  0.2301,  0.0883],\n",
       "                       ...,\n",
       "                       [ 0.0482,  0.1573, -0.0509,  ...,  0.1359,  0.0200,  0.2373],\n",
       "                       [-0.0740, -0.0055,  0.1956,  ...,  0.2625, -0.0035, -0.1433],\n",
       "                       [ 0.0617,  0.2087, -0.1707,  ...,  0.2266, -0.1774,  0.0543]])),\n",
       "              ('decoder.layers.10.encoder_attn.k_proj.bias',\n",
       "               tensor([-0.1140, -0.3936, -0.0261,  ..., -0.0006, -0.0081, -0.0167])),\n",
       "              ('decoder.layers.10.encoder_attn.v_proj.weight',\n",
       "               tensor([[-5.2887e-02,  1.6077e-01, -3.2837e-01,  ..., -3.1396e-01,\n",
       "                        -2.1155e-01, -1.0565e-01],\n",
       "                       [-4.0344e-02, -8.0824e-04, -1.2109e-01,  ...,  2.9999e-02,\n",
       "                        -2.5009e-02, -3.8666e-02],\n",
       "                       [-4.1290e-02, -4.2786e-02, -3.3386e-02,  ..., -3.6774e-02,\n",
       "                        -1.8728e-04,  6.3782e-02],\n",
       "                       ...,\n",
       "                       [-3.8940e-02,  9.1858e-02, -2.0325e-01,  ...,  2.3596e-01,\n",
       "                         7.6782e-02,  9.1309e-02],\n",
       "                       [-3.6377e-02, -3.6774e-03,  2.0728e-01,  ...,  1.3696e-01,\n",
       "                         2.6685e-01,  1.8628e-01],\n",
       "                       [ 8.8928e-02, -7.7576e-02,  1.7639e-01,  ..., -1.7712e-01,\n",
       "                         4.6448e-02, -1.1237e-01]])),\n",
       "              ('decoder.layers.10.encoder_attn.v_proj.bias',\n",
       "               tensor([ 0.0414, -0.0105, -0.0078,  ...,  0.0168, -0.0435, -0.0110])),\n",
       "              ('decoder.layers.10.encoder_attn.q_proj.weight',\n",
       "               tensor([[ 0.1262,  0.0209,  0.0201,  ...,  0.1284, -0.0440,  0.0365],\n",
       "                       [-0.0822,  0.0083, -0.0961,  ...,  0.0015, -0.0420,  0.0312],\n",
       "                       [ 0.0439, -0.0178,  0.0581,  ..., -0.1757,  0.3745,  0.1786],\n",
       "                       ...,\n",
       "                       [-0.0419,  0.1227, -0.2625,  ...,  0.0107, -0.0154, -0.0050],\n",
       "                       [-0.2008,  0.0670,  0.2334,  ..., -0.0298,  0.0495, -0.0237],\n",
       "                       [ 0.0198, -0.0195, -0.1484,  ..., -0.1098,  0.0992,  0.1285]])),\n",
       "              ('decoder.layers.10.encoder_attn.q_proj.bias',\n",
       "               tensor([ 0.0599, -0.2673, -0.0069,  ..., -0.0457,  0.0139,  0.0282])),\n",
       "              ('decoder.layers.10.encoder_attn.out_proj.weight',\n",
       "               tensor([[-0.1603, -0.2377, -0.0807,  ..., -0.1378, -0.0264, -0.1116],\n",
       "                       [-0.0018, -0.0385,  0.0164,  ...,  0.1360, -0.0278,  0.1379],\n",
       "                       [ 0.0448,  0.1411,  0.0609,  ..., -0.0689, -0.0099,  0.0144],\n",
       "                       ...,\n",
       "                       [-0.0966, -0.0448,  0.2148,  ..., -0.1774,  0.0459,  0.0462],\n",
       "                       [ 0.0074,  0.0365,  0.0469,  ..., -0.0364,  0.0792, -0.2910],\n",
       "                       [-0.1398,  0.0514,  0.0575,  ..., -0.0217, -0.2007,  0.1915]])),\n",
       "              ('decoder.layers.10.encoder_attn.out_proj.bias',\n",
       "               tensor([ 0.2786, -0.1029,  0.1014,  ...,  0.0933,  0.0454, -0.0208])),\n",
       "              ('decoder.layers.10.encoder_attn_layer_norm.weight',\n",
       "               tensor([0.6089, 0.5161, 0.5513,  ..., 0.5527, 0.5332, 0.6016])),\n",
       "              ('decoder.layers.10.encoder_attn_layer_norm.bias',\n",
       "               tensor([-0.1265,  0.0846, -0.0461,  ..., -0.0083, -0.1130,  0.0467])),\n",
       "              ('decoder.layers.10.fc1.weight',\n",
       "               tensor([[-0.2061, -0.2418,  0.0197,  ..., -0.0472,  0.0254, -0.0263],\n",
       "                       [ 0.2477, -0.0089,  0.3513,  ...,  0.0251,  0.1083, -0.1044],\n",
       "                       [-0.0602,  0.0910,  0.0632,  ..., -0.2520,  0.0918, -0.0394],\n",
       "                       ...,\n",
       "                       [-0.0605,  0.1633,  0.0217,  ...,  0.0576,  0.2542, -0.0216],\n",
       "                       [-0.1267, -0.0332,  0.0083,  ...,  0.0951,  0.0235, -0.0392],\n",
       "                       [-0.1181,  0.0314, -0.1649,  ..., -0.2783, -0.0179,  0.0278]])),\n",
       "              ('decoder.layers.10.fc1.bias',\n",
       "               tensor([-0.1478, -0.2688, -0.0543,  ..., -0.1265, -0.0660, -0.0278])),\n",
       "              ('decoder.layers.10.fc2.weight',\n",
       "               tensor([[-0.1598, -0.3230,  0.0770,  ..., -0.0908, -0.0422, -0.0062],\n",
       "                       [ 0.0427, -0.0438, -0.2568,  ..., -0.1692, -0.0556,  0.0366],\n",
       "                       [ 0.2186,  0.3013,  0.1053,  ..., -0.0064, -0.0417, -0.0352],\n",
       "                       ...,\n",
       "                       [ 0.1736, -0.2349,  0.1348,  ...,  0.0600, -0.3325,  0.2024],\n",
       "                       [-0.1385,  0.0913,  0.0686,  ...,  0.0748,  0.0330, -0.0986],\n",
       "                       [-0.0251,  0.3843,  0.1109,  ...,  0.1439,  0.0157,  0.0604]])),\n",
       "              ('decoder.layers.10.fc2.bias',\n",
       "               tensor([-0.0265,  0.1809,  0.2141,  ..., -0.0572,  0.0933,  0.0412])),\n",
       "              ('decoder.layers.10.final_layer_norm.weight',\n",
       "               tensor([0.6919, 0.6904, 0.6577,  ..., 0.7246, 0.7344, 0.7593])),\n",
       "              ('decoder.layers.10.final_layer_norm.bias',\n",
       "               tensor([-0.1842,  0.0024, -0.1041,  ...,  0.0250, -0.1345,  0.0723])),\n",
       "              ('decoder.layers.11.self_attn.k_proj.weight',\n",
       "               tensor([[-0.0311,  0.0232, -0.0620,  ..., -0.0697, -0.1467,  0.0804],\n",
       "                       [ 0.0234,  0.0393, -0.0275,  ..., -0.1188, -0.0586,  0.1904],\n",
       "                       [-0.1599,  0.1155,  0.1143,  ...,  0.0943, -0.0257,  0.0501],\n",
       "                       ...,\n",
       "                       [ 0.0322,  0.0009,  0.0285,  ..., -0.0203,  0.0025, -0.0398],\n",
       "                       [ 0.0161,  0.1122, -0.1514,  ..., -0.0122,  0.1625, -0.1248],\n",
       "                       [-0.1902, -0.0234, -0.0127,  ...,  0.1987, -0.0500,  0.1225]])),\n",
       "              ('decoder.layers.11.self_attn.k_proj.bias',\n",
       "               tensor([-0.2189,  0.0746,  0.2668,  ..., -0.9058, -0.4033,  0.0753])),\n",
       "              ('decoder.layers.11.self_attn.v_proj.weight',\n",
       "               tensor([[-0.1644,  0.3149, -0.0233,  ...,  0.2974,  0.1372, -0.0630],\n",
       "                       [ 0.2566, -0.5708, -0.2272,  ..., -0.0959,  0.0547, -0.1860],\n",
       "                       [ 0.0270, -0.0912,  0.1628,  ...,  0.0490, -0.1902, -0.2037],\n",
       "                       ...,\n",
       "                       [ 0.2269, -0.1803, -0.0197,  ..., -0.2391,  0.1874, -0.1064],\n",
       "                       [-0.1736,  0.0801,  0.0008,  ..., -0.0175, -0.1750,  0.0737],\n",
       "                       [ 0.2479,  0.1102,  0.2112,  ..., -0.0302, -0.0392,  0.0320]])),\n",
       "              ('decoder.layers.11.self_attn.v_proj.bias',\n",
       "               tensor([0.0494, 0.1074, 0.0541,  ..., 0.0446, 0.0357, 0.0085])),\n",
       "              ('decoder.layers.11.self_attn.q_proj.weight',\n",
       "               tensor([[ 0.0803, -0.2037, -0.0459,  ..., -0.0696,  0.0053, -0.0420],\n",
       "                       [ 0.0593,  0.2678, -0.0073,  ...,  0.0185, -0.0169, -0.1388],\n",
       "                       [ 0.0651,  0.1506, -0.0061,  ..., -0.1708, -0.0199, -0.0773],\n",
       "                       ...,\n",
       "                       [-0.0131,  0.0221, -0.0507,  ...,  0.1356,  0.0552,  0.0549],\n",
       "                       [-0.1649, -0.0898, -0.0399,  ...,  0.1159, -0.1899, -0.0184],\n",
       "                       [ 0.0167,  0.2139, -0.0685,  ...,  0.1147, -0.1294,  0.0266]])),\n",
       "              ('decoder.layers.11.self_attn.q_proj.bias',\n",
       "               tensor([-0.0056, -0.0359, -0.0298,  ...,  0.1447,  0.0967,  0.0009])),\n",
       "              ('decoder.layers.11.self_attn.out_proj.weight',\n",
       "               tensor([[-0.0248,  0.0385,  0.0082,  ..., -0.0114, -0.1081, -0.0277],\n",
       "                       [-0.1962,  0.4143, -0.0031,  ..., -0.1033,  0.0064, -0.0034],\n",
       "                       [-0.1183,  0.3511,  0.0874,  ...,  0.1388, -0.0865,  0.0226],\n",
       "                       ...,\n",
       "                       [-0.2222, -0.0865,  0.1315,  ..., -0.1398, -0.2004, -0.0724],\n",
       "                       [-0.3477, -0.2764,  0.0155,  ..., -0.2365, -0.1721, -0.0495],\n",
       "                       [-0.0140, -0.0395,  0.3284,  ..., -0.0874, -0.2161,  0.2776]])),\n",
       "              ('decoder.layers.11.self_attn.out_proj.bias',\n",
       "               tensor([ 0.1500, -0.0529,  0.1686,  ...,  0.0417, -0.0187,  0.0793])),\n",
       "              ('decoder.layers.11.self_attn_layer_norm.weight',\n",
       "               tensor([0.4707, 0.4363, 0.4343,  ..., 0.4453, 0.4509, 0.4507])),\n",
       "              ('decoder.layers.11.self_attn_layer_norm.bias',\n",
       "               tensor([-0.0614,  0.0108, -0.0153,  ...,  0.0008, -0.0301,  0.0199])),\n",
       "              ('decoder.layers.11.encoder_attn.k_proj.weight',\n",
       "               tensor([[-0.1304, -0.0321,  0.0478,  ..., -0.0381,  0.0660, -0.0055],\n",
       "                       [ 0.2227, -0.0471, -0.0439,  ...,  0.0676, -0.2062, -0.0257],\n",
       "                       [-0.2258, -0.2559,  0.1218,  ...,  0.0209,  0.0219,  0.0345],\n",
       "                       ...,\n",
       "                       [-0.1501,  0.1486, -0.0679,  ...,  0.0630, -0.1050,  0.0275],\n",
       "                       [ 0.0443,  0.0089,  0.1779,  ...,  0.0385, -0.0302, -0.0514],\n",
       "                       [ 0.3745,  0.1307, -0.0474,  ...,  0.0999, -0.0205, -0.0375]])),\n",
       "              ('decoder.layers.11.encoder_attn.k_proj.bias',\n",
       "               tensor([ 0.0865, -0.2139,  0.3071,  ..., -0.2881,  0.1841,  0.1315])),\n",
       "              ('decoder.layers.11.encoder_attn.v_proj.weight',\n",
       "               tensor([[-0.1141, -0.1598,  0.2563,  ..., -0.0434,  0.0227, -0.2485],\n",
       "                       [-0.0174, -0.3052, -0.1102,  ...,  0.0959,  0.0815,  0.2656],\n",
       "                       [ 0.0488,  0.0126, -0.0486,  ..., -0.1354, -0.0948, -0.4641],\n",
       "                       ...,\n",
       "                       [ 0.1709, -0.1153,  0.3108,  ...,  0.0282, -0.0751, -0.0654],\n",
       "                       [-0.1964, -0.0053, -0.1892,  ..., -0.1166, -0.0530,  0.0387],\n",
       "                       [-0.0199,  0.2430, -0.2001,  ..., -0.0438, -0.0515, -0.1160]])),\n",
       "              ('decoder.layers.11.encoder_attn.v_proj.bias',\n",
       "               tensor([ 0.1669, -0.1537,  0.0727,  ...,  0.0053, -0.2449, -0.0349])),\n",
       "              ('decoder.layers.11.encoder_attn.q_proj.weight',\n",
       "               tensor([[ 2.3468e-02,  1.9482e-01,  1.1719e-01,  ..., -1.2093e-02,\n",
       "                        -2.3108e-01,  1.2225e-01],\n",
       "                       [ 2.0035e-02,  6.3049e-02,  6.9214e-02,  ...,  6.3629e-03,\n",
       "                        -5.2571e-05,  9.1980e-02],\n",
       "                       [-1.5564e-01, -1.5698e-01,  2.9297e-02,  ...,  1.3721e-01,\n",
       "                        -3.3752e-02, -4.4403e-02],\n",
       "                       ...,\n",
       "                       [-1.0034e-01, -6.7017e-02, -2.7148e-01,  ...,  7.1777e-02,\n",
       "                         7.4310e-03,  1.7426e-02],\n",
       "                       [-6.2866e-02, -3.2043e-02,  8.4305e-03,  ...,  1.0571e-01,\n",
       "                        -2.8955e-01,  1.1787e-02],\n",
       "                       [ 7.3547e-02,  9.5581e-02,  1.4050e-01,  ...,  9.1248e-02,\n",
       "                        -7.7087e-02, -3.1860e-02]])),\n",
       "              ('decoder.layers.11.encoder_attn.q_proj.bias',\n",
       "               tensor([-0.0173, -0.0340,  0.0679,  ..., -0.1028,  0.0745, -0.0106])),\n",
       "              ('decoder.layers.11.encoder_attn.out_proj.weight',\n",
       "               tensor([[-0.0116,  0.2920,  0.2498,  ..., -0.0632,  0.3555, -0.0822],\n",
       "                       [ 0.1304, -0.2246, -0.0692,  ...,  0.0514, -0.0696, -0.0782],\n",
       "                       [-0.1393,  0.1255,  0.0162,  ...,  0.1658, -0.0964,  0.2032],\n",
       "                       ...,\n",
       "                       [-0.0435, -0.4192,  0.1514,  ..., -0.0546,  0.1699, -0.1720],\n",
       "                       [-0.0587, -0.0483, -0.0144,  ..., -0.0125, -0.1824,  0.0408],\n",
       "                       [-0.0537,  0.0923, -0.1003,  ..., -0.2355,  0.0036, -0.3567]])),\n",
       "              ('decoder.layers.11.encoder_attn.out_proj.bias',\n",
       "               tensor([ 0.0700,  0.1820,  0.0454,  ...,  0.2236, -0.0129, -0.0345])),\n",
       "              ('decoder.layers.11.encoder_attn_layer_norm.weight',\n",
       "               tensor([0.6079, 0.5640, 0.5464,  ..., 0.5542, 0.5752, 0.5732])),\n",
       "              ('decoder.layers.11.encoder_attn_layer_norm.bias',\n",
       "               tensor([-0.0594,  0.1659,  0.0405,  ...,  0.0990,  0.0314,  0.0922])),\n",
       "              ('decoder.layers.11.fc1.weight',\n",
       "               tensor([[-0.0349, -0.1503, -0.0524,  ...,  0.0479, -0.1549,  0.2598],\n",
       "                       [-0.0319, -0.1543,  0.0339,  ..., -0.2159, -0.2988, -0.0995],\n",
       "                       [-0.0219, -0.1683, -0.0637,  ...,  0.0686, -0.0329,  0.0720],\n",
       "                       ...,\n",
       "                       [ 0.0771,  0.0545, -0.0185,  ..., -0.0102, -0.1281,  0.1664],\n",
       "                       [ 0.0523, -0.0514, -0.0352,  ...,  0.0529, -0.1125, -0.0924],\n",
       "                       [-0.1017,  0.1903,  0.1927,  ...,  0.0482,  0.0374,  0.1102]])),\n",
       "              ('decoder.layers.11.fc1.bias',\n",
       "               tensor([-0.3159,  0.0602, -0.2179,  ..., -0.1796, -0.1187, -0.2791])),\n",
       "              ('decoder.layers.11.fc2.weight',\n",
       "               tensor([[ 0.3101,  0.2423,  0.5942,  ..., -0.6963,  0.5342,  0.1248],\n",
       "                       [ 0.3740, -0.2050,  0.0173,  ..., -0.0630,  0.0266, -0.0568],\n",
       "                       [-0.1079,  0.0905, -0.0637,  ...,  0.0929, -0.2175,  0.0008],\n",
       "                       ...,\n",
       "                       [ 0.1075, -0.0667,  0.0457,  ..., -0.2251, -0.0937, -0.0374],\n",
       "                       [-0.0973, -0.1064,  0.1205,  ...,  0.0011,  0.2695,  0.0764],\n",
       "                       [ 0.1796,  0.0248,  0.2380,  ...,  0.2076,  0.0961, -0.1064]])),\n",
       "              ('decoder.layers.11.fc2.bias',\n",
       "               tensor([-0.9331,  0.0604,  0.0362,  ..., -0.1333,  0.1284, -0.0795])),\n",
       "              ('decoder.layers.11.final_layer_norm.weight',\n",
       "               tensor([0.7827, 0.8521, 0.7954,  ..., 0.8345, 0.8647, 0.8643])),\n",
       "              ('decoder.layers.11.final_layer_norm.bias',\n",
       "               tensor([-0.2068, -0.1103, -0.0999,  ..., -0.0732, -0.2339,  0.0204])),\n",
       "              ('decoder.layer_norm.weight',\n",
       "               tensor([0.0234, 0.5469, 0.5410,  ..., 0.4502, 0.4543, 0.4636])),\n",
       "              ('decoder.layer_norm.bias',\n",
       "               tensor([-0.0114,  0.0809, -0.0495,  ...,  0.0028, -0.0488, -0.0056])),\n",
       "              ('decoder.output_projection.weight',\n",
       "               tensor([[-2.7542e-03, -6.4964e-03, -4.6921e-03,  ..., -3.9246e-02,\n",
       "                        -6.2714e-03, -3.5461e-02],\n",
       "                       [ 1.9897e-02, -2.8782e-03,  6.2823e-05,  ..., -3.4149e-02,\n",
       "                        -2.8900e-02, -1.1429e-02],\n",
       "                       [ 2.3499e-03,  1.6083e-02, -3.1586e-02,  ...,  5.2490e-02,\n",
       "                        -1.6565e-01,  6.2927e-02],\n",
       "                       ...,\n",
       "                       [-1.9388e-03,  7.3853e-03, -1.0155e-02,  ..., -4.6844e-03,\n",
       "                        -4.4891e-02, -3.9673e-03],\n",
       "                       [-1.6541e-02,  7.1573e-04, -1.6661e-03,  ..., -3.8483e-02,\n",
       "                        -1.0849e-02, -1.2779e-02],\n",
       "                       [ 7.7477e-03, -3.5492e-02, -3.5736e-02,  ..., -4.9561e-02,\n",
       "                        -1.4519e-02,  4.3068e-03]]))]),\n",
       " 'criterion': None,\n",
       " 'optimizer_history': [{'criterion_name': 'LabelSmoothedCrossEntropyCriterion',\n",
       "   'optimizer_name': 'FP16Optimizer',\n",
       "   'lr_scheduler_state': {'best': 3.988},\n",
       "   'num_updates': 11000},\n",
       "  {'criterion_name': 'LabelSmoothedCrossEntropyCriterion',\n",
       "   'optimizer_name': 'FP16Optimizer',\n",
       "   'lr_scheduler_state': {'best': 3.779},\n",
       "   'num_updates': 30000}],\n",
       " 'task_state': {},\n",
       " 'extra_state': {'metrics': OrderedDict([('default',\n",
       "                [(10,\n",
       "                  'loss',\n",
       "                  'AverageMeter',\n",
       "                  {'val': tensor(4.1204, dtype=torch.float64),\n",
       "                   'sum': tensor(1.8158e+09, dtype=torch.float64),\n",
       "                   'count': tensor(4.3410e+08, dtype=torch.float64),\n",
       "                   'round': 3}),\n",
       "                 (10,\n",
       "                  'nll_loss',\n",
       "                  'AverageMeter',\n",
       "                  {'val': tensor(2.0880, dtype=torch.float64),\n",
       "                   'sum': tensor(9.4069e+08, dtype=torch.float64),\n",
       "                   'count': tensor(4.3410e+08, dtype=torch.float64),\n",
       "                   'round': 3}),\n",
       "                 (10,\n",
       "                  'total',\n",
       "                  'AverageMeter',\n",
       "                  {'val': 40299.0,\n",
       "                   'sum': 434102817.0,\n",
       "                   'count': 11000,\n",
       "                   'round': None}),\n",
       "                 (10,\n",
       "                  'n_correct',\n",
       "                  'AverageMeter',\n",
       "                  {'val': 24910.0,\n",
       "                   'sum': 263742126.0,\n",
       "                   'count': 11000,\n",
       "                   'round': None}),\n",
       "                 (90,\n",
       "                  'wps',\n",
       "                  'TimeMeter',\n",
       "                  {'init': 48381.22070801002,\n",
       "                   'n': tensor(4.3407e+08, dtype=torch.float64),\n",
       "                   'round': 1}),\n",
       "                 (100,\n",
       "                  'ups',\n",
       "                  'TimeMeter',\n",
       "                  {'init': 48381.22185146308, 'n': 10999.0, 'round': 2}),\n",
       "                 (180,\n",
       "                  'wpb',\n",
       "                  'AverageMeter',\n",
       "                  {'val': tensor(40299., dtype=torch.float64),\n",
       "                   'sum': tensor(4.3410e+08, dtype=torch.float64),\n",
       "                   'count': 11000,\n",
       "                   'round': 1}),\n",
       "                 (190,\n",
       "                  'bsz',\n",
       "                  'AverageMeter',\n",
       "                  {'val': tensor(239., dtype=torch.float64),\n",
       "                   'sum': tensor(2374194., dtype=torch.float64),\n",
       "                   'count': 11000,\n",
       "                   'round': 1}),\n",
       "                 (200,\n",
       "                  'num_updates',\n",
       "                  'AverageMeter',\n",
       "                  {'val': 11000, 'sum': 0, 'count': 0, 'round': None}),\n",
       "                 (300,\n",
       "                  'lr',\n",
       "                  'AverageMeter',\n",
       "                  {'val': 7.037037037037038e-05,\n",
       "                   'sum': 0,\n",
       "                   'count': 0,\n",
       "                   'round': None}),\n",
       "                 (400,\n",
       "                  'gnorm',\n",
       "                  'AverageMeter',\n",
       "                  {'val': tensor(0.0948, dtype=torch.float64),\n",
       "                   'sum': tensor(1220.6716, dtype=torch.float64),\n",
       "                   'count': 11000,\n",
       "                   'round': 3}),\n",
       "                 (500,\n",
       "                  'clip',\n",
       "                  'AverageMeter',\n",
       "                  {'val': tensor(0., dtype=torch.float64),\n",
       "                   'sum': tensor(813400., dtype=torch.float64),\n",
       "                   'count': 11000,\n",
       "                   'round': 1}),\n",
       "                 (700,\n",
       "                  'loss_scale',\n",
       "                  'AverageMeter',\n",
       "                  {'val': 4.0, 'sum': 0, 'count': 0, 'round': 4}),\n",
       "                 (790,\n",
       "                  'wall',\n",
       "                  'StopwatchMeter',\n",
       "                  {'sum': 0, 'n': 0, 'round': 0}),\n",
       "                 (800,\n",
       "                  'train_wall',\n",
       "                  'StopwatchMeter',\n",
       "                  {'sum': 17094.268675681436, 'n': 0.0, 'round': 0}),\n",
       "                 (1500,\n",
       "                  'gb_free',\n",
       "                  'AverageMeter',\n",
       "                  {'val': 14.399511337280273,\n",
       "                   'sum': 0,\n",
       "                   'count': 0,\n",
       "                   'round': 1})]),\n",
       "               ('train',\n",
       "                [(10,\n",
       "                  'loss',\n",
       "                  'AverageMeter',\n",
       "                  {'val': tensor(4.0915, dtype=torch.float64),\n",
       "                   'sum': tensor(2.7644e+08, dtype=torch.float64),\n",
       "                   'count': tensor(68198436., dtype=torch.float64),\n",
       "                   'round': 3}),\n",
       "                 (10,\n",
       "                  'nll_loss',\n",
       "                  'AverageMeter',\n",
       "                  {'val': tensor(2.0491, dtype=torch.float64),\n",
       "                   'sum': tensor(1.3645e+08, dtype=torch.float64),\n",
       "                   'count': tensor(68198436., dtype=torch.float64),\n",
       "                   'round': 3}),\n",
       "                 (10,\n",
       "                  'total',\n",
       "                  'AverageMeter',\n",
       "                  {'val': 39631.0,\n",
       "                   'sum': 68198436.0,\n",
       "                   'count': 1728,\n",
       "                   'round': None}),\n",
       "                 (10,\n",
       "                  'n_correct',\n",
       "                  'AverageMeter',\n",
       "                  {'val': 24837.0,\n",
       "                   'sum': 43227030.0,\n",
       "                   'count': 1728,\n",
       "                   'round': None}),\n",
       "                 (90,\n",
       "                  'wps',\n",
       "                  'TimeMeter',\n",
       "                  {'init': 2726.304922681069,\n",
       "                   'n': tensor(68198436., dtype=torch.float64),\n",
       "                   'round': 1}),\n",
       "                 (100,\n",
       "                  'ups',\n",
       "                  'TimeMeter',\n",
       "                  {'init': 2726.304919249029, 'n': 1728.0, 'round': 2}),\n",
       "                 (180,\n",
       "                  'wpb',\n",
       "                  'AverageMeter',\n",
       "                  {'val': tensor(39631., dtype=torch.float64),\n",
       "                   'sum': tensor(68198436., dtype=torch.float64),\n",
       "                   'count': 1728,\n",
       "                   'round': 1}),\n",
       "                 (190,\n",
       "                  'bsz',\n",
       "                  'AverageMeter',\n",
       "                  {'val': tensor(256., dtype=torch.float64),\n",
       "                   'sum': tensor(372843., dtype=torch.float64),\n",
       "                   'count': 1728,\n",
       "                   'round': 1}),\n",
       "                 (200,\n",
       "                  'num_updates',\n",
       "                  'AverageMeter',\n",
       "                  {'val': 30000, 'sum': 0, 'count': 0, 'round': None}),\n",
       "                 (300,\n",
       "                  'lr',\n",
       "                  'AverageMeter',\n",
       "                  {'val': 0.0, 'sum': 0, 'count': 0, 'round': None}),\n",
       "                 (400,\n",
       "                  'gnorm',\n",
       "                  'AverageMeter',\n",
       "                  {'val': tensor(0.1018, dtype=torch.float64),\n",
       "                   'sum': tensor(201.6770, dtype=torch.float64),\n",
       "                   'count': 1728,\n",
       "                   'round': 3}),\n",
       "                 (500,\n",
       "                  'clip',\n",
       "                  'AverageMeter',\n",
       "                  {'val': tensor(100., dtype=torch.float64),\n",
       "                   'sum': tensor(158500., dtype=torch.float64),\n",
       "                   'count': 1728,\n",
       "                   'round': 1}),\n",
       "                 (700,\n",
       "                  'loss_scale',\n",
       "                  'AverageMeter',\n",
       "                  {'val': 8.0, 'sum': 0, 'count': 0, 'round': 4}),\n",
       "                 (800,\n",
       "                  'train_wall',\n",
       "                  'StopwatchMeter',\n",
       "                  {'sum': 2656.299202710972, 'n': 0.0, 'round': 0}),\n",
       "                 (1500,\n",
       "                  'gb_free',\n",
       "                  'AverageMeter',\n",
       "                  {'val': 14.378269672393799,\n",
       "                   'sum': 0,\n",
       "                   'count': 0,\n",
       "                   'round': 1})]),\n",
       "               ('train_inner',\n",
       "                [(10,\n",
       "                  'loss',\n",
       "                  'AverageMeter',\n",
       "                  {'val': None, 'sum': 0, 'count': 0, 'round': 3}),\n",
       "                 (10,\n",
       "                  'nll_loss',\n",
       "                  'AverageMeter',\n",
       "                  {'val': None, 'sum': 0, 'count': 0, 'round': 3}),\n",
       "                 (10,\n",
       "                  'total',\n",
       "                  'AverageMeter',\n",
       "                  {'val': None, 'sum': 0, 'count': 0, 'round': None}),\n",
       "                 (10,\n",
       "                  'n_correct',\n",
       "                  'AverageMeter',\n",
       "                  {'val': None, 'sum': 0, 'count': 0, 'round': None}),\n",
       "                 (90,\n",
       "                  'wps',\n",
       "                  'TimeMeter',\n",
       "                  {'init': 12.31575187202543, 'n': 0, 'round': 1}),\n",
       "                 (100,\n",
       "                  'ups',\n",
       "                  'TimeMeter',\n",
       "                  {'init': 12.315750880981795, 'n': 0, 'round': 2}),\n",
       "                 (180,\n",
       "                  'wpb',\n",
       "                  'AverageMeter',\n",
       "                  {'val': None, 'sum': 0, 'count': 0, 'round': 1}),\n",
       "                 (190,\n",
       "                  'bsz',\n",
       "                  'AverageMeter',\n",
       "                  {'val': None, 'sum': 0, 'count': 0, 'round': 1}),\n",
       "                 (200,\n",
       "                  'num_updates',\n",
       "                  'AverageMeter',\n",
       "                  {'val': None, 'sum': 0, 'count': 0, 'round': None}),\n",
       "                 (300,\n",
       "                  'lr',\n",
       "                  'AverageMeter',\n",
       "                  {'val': None, 'sum': 0, 'count': 0, 'round': None}),\n",
       "                 (400,\n",
       "                  'gnorm',\n",
       "                  'AverageMeter',\n",
       "                  {'val': None, 'sum': 0, 'count': 0, 'round': 3}),\n",
       "                 (500,\n",
       "                  'clip',\n",
       "                  'AverageMeter',\n",
       "                  {'val': None, 'sum': 0, 'count': 0, 'round': 1}),\n",
       "                 (700,\n",
       "                  'loss_scale',\n",
       "                  'AverageMeter',\n",
       "                  {'val': None, 'sum': 0, 'count': 0, 'round': 4}),\n",
       "                 (800,\n",
       "                  'train_wall',\n",
       "                  'StopwatchMeter',\n",
       "                  {'sum': 0, 'n': 0, 'round': 0}),\n",
       "                 (1500,\n",
       "                  'gb_free',\n",
       "                  'AverageMeter',\n",
       "                  {'val': None, 'sum': 0, 'count': 0, 'round': 1})]),\n",
       "               ('valid',\n",
       "                [(10,\n",
       "                  'loss',\n",
       "                  'AverageMeter',\n",
       "                  {'val': tensor(3.7884, dtype=torch.float64),\n",
       "                   'sum': tensor(1.7137e+08, dtype=torch.float64),\n",
       "                   'count': tensor(44354786., dtype=torch.float64),\n",
       "                   'round': 3}),\n",
       "                 (10,\n",
       "                  'nll_loss',\n",
       "                  'AverageMeter',\n",
       "                  {'val': tensor(1.6440, dtype=torch.float64),\n",
       "                   'sum': tensor(77067933.7171, dtype=torch.float64),\n",
       "                   'count': tensor(44354786., dtype=torch.float64),\n",
       "                   'round': 3}),\n",
       "                 (10,\n",
       "                  'total',\n",
       "                  'AverageMeter',\n",
       "                  {'val': 3294.0,\n",
       "                   'sum': 44354786.0,\n",
       "                   'count': 8500,\n",
       "                   'round': None}),\n",
       "                 (10,\n",
       "                  'n_correct',\n",
       "                  'AverageMeter',\n",
       "                  {'val': 2298.0,\n",
       "                   'sum': 30020132.0,\n",
       "                   'count': 8500,\n",
       "                   'round': None}),\n",
       "                 (90,\n",
       "                  'wps',\n",
       "                  'TimeMeter',\n",
       "                  {'init': 46829.14589851594,\n",
       "                   'n': tensor(44352539., dtype=torch.float64),\n",
       "                   'round': 1}),\n",
       "                 (180,\n",
       "                  'wpb',\n",
       "                  'AverageMeter',\n",
       "                  {'val': tensor(3294., dtype=torch.float64),\n",
       "                   'sum': tensor(44354786., dtype=torch.float64),\n",
       "                   'count': 8500,\n",
       "                   'round': 1}),\n",
       "                 (190,\n",
       "                  'bsz',\n",
       "                  'AverageMeter',\n",
       "                  {'val': tensor(5., dtype=torch.float64),\n",
       "                   'sum': tensor(292502., dtype=torch.float64),\n",
       "                   'count': 8500,\n",
       "                   'round': 1})])]),\n",
       "  'previous_training_time': tensor(48427.5081, dtype=torch.float64),\n",
       "  'train_iterator': {'version': 2,\n",
       "   'epoch': 5,\n",
       "   'iterations_in_epoch': 13864,\n",
       "   'shuffle': True},\n",
       "  'val_loss': 3.779,\n",
       "  'best': 3.779},\n",
       " 'last_optimizer_state': {'state': {0: {'step': 30000,\n",
       "    'exp_avg': tensor([-1.2519e-04,  3.6593e-05, -2.3508e-05,  ...,  2.6585e-05,\n",
       "             1.8354e-05,  1.5653e-05]),\n",
       "    'exp_avg_sq': tensor([1.2728e-07, 7.6436e-09, 6.9152e-09,  ..., 1.9678e-08, 2.5816e-08,\n",
       "            2.1253e-08])}},\n",
       "  'param_groups': [{'lr': 0.0,\n",
       "    'betas': [0.9, 0.999],\n",
       "    'eps': 1e-08,\n",
       "    'weight_decay': 0.0,\n",
       "    'amsgrad': False,\n",
       "    'params': [0]}],\n",
       "  'loss_scale': 8.0}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utut_ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2851dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y9/nm4qdmtn143d63hcl5r54xbr0000gn/T/ipykernel_14319/1375809416.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  unit2a_ckpt = torch.load(unit2av_path, map_location='cpu')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['en', 'es', 'fr', 'it', 'pt'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unit2av_path='/Users/jisu/Desktop/dev/cli/av2av/modelckpt/unit_av_renderer.pt'\n",
    "\n",
    "unit2a_ckpt = torch.load(unit2av_path, map_location='cpu')\n",
    "\n",
    "# 가중치 키 목록 중 상위 20개만 출력하여 언어 코드가 포함되어 있는지 확인\n",
    "# for key in list(unit2a_ckpt['model'].keys())[:20]:\n",
    "#     print(key) >>> KeyError: 'model'\n",
    "\n",
    "unit2a_ckpt['audio'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d656816f",
   "metadata": {},
   "source": [
    "오디오 CodeHiFiGANModel_spk 상속 구조:\n",
    "```\n",
    "CodeHiFiGANModel_spk\n",
    "  ↳ CodeHiFiGANModel\n",
    "    ↳ nn.Module\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68fd1043",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/av2av/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "/Users/jisu/Desktop/dev/cli/av2av/unit2av/model.py:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(checkpoint_path, map_location=torch.device(\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing weight norm...\n",
      "Unit2AV Vocoder param. size\n",
      "Trainable params: 50,066,805\n",
      "Total params:     50,066,805\n"
     ]
    }
   ],
   "source": [
    "# 보코더는 “fairseq 모델 1개”가 아니라, 여러 서브모델을 조합한 renderer/vocoder 파이프라인\n",
    "from fairseq import utils\n",
    "from unit2av.model import UnitAVRenderer\n",
    "from unit2av.model_speaker_encoder import SpeakerEncoder\n",
    "from util import save_video, extract_audio_from_video\n",
    "\n",
    "with open('/Users/jisu/Desktop/dev/cli/av2av/unit2av/config.json') as f:\n",
    "    vocoder_cfg = json.load(f)\n",
    "vocoder = UnitAVRenderer(unit2av_path, vocoder_cfg, 'en')\n",
    " \n",
    "model = vocoder\n",
    "trainable_params = sum(\n",
    "    p.numel() for p in model.parameters() if p.requires_grad\n",
    ")\n",
    "\n",
    "total_params = sum(\n",
    "    p.numel() for p in model.parameters()\n",
    ")\n",
    "\n",
    "print(\"Unit2AV Vocoder param. size\")\n",
    "print(f\"Trainable params: {trainable_params:,}\")\n",
    "print(f\"Total params:     {total_params:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9879690b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UnitAVRenderer(\n",
       "  (model): CodeHiFiGANModel_spk(\n",
       "    (conv_pre): Conv1d(256, 512, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "    (ups): ModuleList(\n",
       "      (0): ConvTranspose1d(512, 256, kernel_size=(11,), stride=(5,), padding=(3,))\n",
       "      (1): ConvTranspose1d(256, 128, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "      (2): ConvTranspose1d(128, 64, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "      (3): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "      (4): ConvTranspose1d(32, 16, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "    )\n",
       "    (resblocks): ModuleList(\n",
       "      (0): ResBlock(\n",
       "        (convs1): ModuleList(\n",
       "          (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "          (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0-2): 3 x Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        )\n",
       "      )\n",
       "      (1): ResBlock(\n",
       "        (convs1): ModuleList(\n",
       "          (0): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "          (2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0-2): 3 x Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "        )\n",
       "      )\n",
       "      (2): ResBlock(\n",
       "        (convs1): ModuleList(\n",
       "          (0): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "          (2): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0-2): 3 x Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "        )\n",
       "      )\n",
       "      (3): ResBlock(\n",
       "        (convs1): ModuleList(\n",
       "          (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "          (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0-2): 3 x Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        )\n",
       "      )\n",
       "      (4): ResBlock(\n",
       "        (convs1): ModuleList(\n",
       "          (0): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "          (2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0-2): 3 x Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "        )\n",
       "      )\n",
       "      (5): ResBlock(\n",
       "        (convs1): ModuleList(\n",
       "          (0): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "          (2): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0-2): 3 x Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "        )\n",
       "      )\n",
       "      (6): ResBlock(\n",
       "        (convs1): ModuleList(\n",
       "          (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "          (2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0-2): 3 x Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        )\n",
       "      )\n",
       "      (7): ResBlock(\n",
       "        (convs1): ModuleList(\n",
       "          (0): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "          (2): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0-2): 3 x Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "        )\n",
       "      )\n",
       "      (8): ResBlock(\n",
       "        (convs1): ModuleList(\n",
       "          (0): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "          (2): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0-2): 3 x Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "        )\n",
       "      )\n",
       "      (9): ResBlock(\n",
       "        (convs1): ModuleList(\n",
       "          (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "          (2): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0-2): 3 x Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        )\n",
       "      )\n",
       "      (10): ResBlock(\n",
       "        (convs1): ModuleList(\n",
       "          (0): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "          (2): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0-2): 3 x Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "        )\n",
       "      )\n",
       "      (11): ResBlock(\n",
       "        (convs1): ModuleList(\n",
       "          (0): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "          (2): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0-2): 3 x Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "        )\n",
       "      )\n",
       "      (12): ResBlock(\n",
       "        (convs1): ModuleList(\n",
       "          (0): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "          (2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0-2): 3 x Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        )\n",
       "      )\n",
       "      (13): ResBlock(\n",
       "        (convs1): ModuleList(\n",
       "          (0): Conv1d(16, 16, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          (1): Conv1d(16, 16, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "          (2): Conv1d(16, 16, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0-2): 3 x Conv1d(16, 16, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "        )\n",
       "      )\n",
       "      (14): ResBlock(\n",
       "        (convs1): ModuleList(\n",
       "          (0): Conv1d(16, 16, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          (1): Conv1d(16, 16, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "          (2): Conv1d(16, 16, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0-2): 3 x Conv1d(16, 16, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv_post): Conv1d(16, 1, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "    (dict): Embedding(1000, 128)\n",
       "    (spkr): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (dur_predictor): VariancePredictor(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout_module): FairseqDropout()\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (proj): Linear(in_features=128, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (face_model): FaceRenderer(\n",
       "    (face_encoder_blocks): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(\n",
       "          (conv_block): Sequential(\n",
       "            (0): Conv2d(6, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(\n",
       "          (conv_block): Sequential(\n",
       "            (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU()\n",
       "        )\n",
       "        (1): Conv2d(\n",
       "          (conv_block): Sequential(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU()\n",
       "        )\n",
       "        (2): Conv2d(\n",
       "          (conv_block): Sequential(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv2d(\n",
       "          (conv_block): Sequential(\n",
       "            (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU()\n",
       "        )\n",
       "        (1): Conv2d(\n",
       "          (conv_block): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU()\n",
       "        )\n",
       "        (2): Conv2d(\n",
       "          (conv_block): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU()\n",
       "        )\n",
       "        (3): Conv2d(\n",
       "          (conv_block): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): Conv2d(\n",
       "          (conv_block): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU()\n",
       "        )\n",
       "        (1): Conv2d(\n",
       "          (conv_block): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU()\n",
       "        )\n",
       "        (2): Conv2d(\n",
       "          (conv_block): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): Conv2d(\n",
       "          (conv_block): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU()\n",
       "        )\n",
       "        (1): Conv2d(\n",
       "          (conv_block): Sequential(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU()\n",
       "        )\n",
       "        (2): Conv2d(\n",
       "          (conv_block): Sequential(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): Conv2d(\n",
       "          (conv_block): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU()\n",
       "        )\n",
       "        (1): Conv2d(\n",
       "          (conv_block): Sequential(\n",
       "            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): Conv2d(\n",
       "          (conv_block): Sequential(\n",
       "            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU()\n",
       "        )\n",
       "        (1): Conv2d(\n",
       "          (conv_block): Sequential(\n",
       "            (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (unit_embed): Embedding(1000, 512)\n",
       "    (unit2lip): TransformerEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (face_decoder_blocks): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(\n",
       "          (conv_block): Sequential(\n",
       "            (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2dTranspose(\n",
       "          (conv_block): Sequential(\n",
       "            (0): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU()\n",
       "        )\n",
       "        (1): Conv2d(\n",
       "          (conv_block): Sequential(\n",
       "            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv2dTranspose(\n",
       "          (conv_block): Sequential(\n",
       "            (0): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU()\n",
       "        )\n",
       "        (1): Conv2d(\n",
       "          (conv_block): Sequential(\n",
       "            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU()\n",
       "        )\n",
       "        (2): Conv2d(\n",
       "          (conv_block): Sequential(\n",
       "            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): Conv2dTranspose(\n",
       "          (conv_block): Sequential(\n",
       "            (0): ConvTranspose2d(768, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU()\n",
       "        )\n",
       "        (1): Conv2d(\n",
       "          (conv_block): Sequential(\n",
       "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU()\n",
       "        )\n",
       "        (2): Conv2d(\n",
       "          (conv_block): Sequential(\n",
       "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): Conv2dTranspose(\n",
       "          (conv_block): Sequential(\n",
       "            (0): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU()\n",
       "        )\n",
       "        (1): Conv2d(\n",
       "          (conv_block): Sequential(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU()\n",
       "        )\n",
       "        (2): Conv2d(\n",
       "          (conv_block): Sequential(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): Conv2dTranspose(\n",
       "          (conv_block): Sequential(\n",
       "            (0): ConvTranspose2d(320, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU()\n",
       "        )\n",
       "        (1): Conv2d(\n",
       "          (conv_block): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU()\n",
       "        )\n",
       "        (2): Conv2d(\n",
       "          (conv_block): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): Conv2dTranspose(\n",
       "          (conv_block): Sequential(\n",
       "            (0): ConvTranspose2d(160, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU()\n",
       "        )\n",
       "        (1): Conv2d(\n",
       "          (conv_block): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU()\n",
       "        )\n",
       "        (2): Conv2d(\n",
       "          (conv_block): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (output_block): Sequential(\n",
       "      (0): Conv2d(\n",
       "        (conv_block): Sequential(\n",
       "          (0): Conv2d(80, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act): ReLU()\n",
       "      )\n",
       "      (1): Conv2d(32, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): Sigmoid()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23b1ffa",
   "metadata": {},
   "source": [
    "---\n",
    "### invest ckpts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e6b9066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checking: /home/2022113135/jjs/av2av/unit2unit/utut_finetune/unit_mbart.pt]\n",
      "Vocabulary Size (Dictionary): 1007\n",
      "Embedding Dim (Weight Matrix): 1024\n",
      "\n",
      "[Checking: /home/2022113135/jjs/av2av/unit2unit/utut_finetune/utut_ckpt/unit_mbart_multilingual_ft/en_ko/checkpoint_best.pt]\n",
      "Vocabulary Size (Dictionary): 1025\n",
      "Embedding Dim (Weight Matrix): 1024\n",
      "\n",
      "[Checking: /home/2022113135/jjs/av2av/ckpts/utut_sts_ft.pt]\n",
      "Vocabulary Size (Dictionary): 1024\n",
      "Embedding Dim (Weight Matrix): 1024\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def inspect_checkpoint(path):\n",
    "    print(f\"\\n[Checking: {path}]\")\n",
    "    # 모델 불러오기 (가중치 제외하고 메타데이터 위주로 로드)\n",
    "    ckpt = torch.load(path, map_location='cpu')\n",
    "    \n",
    "    # 1. 아키텍처 차원 확인 (BART/mBART 기준)\n",
    "    cfg = ckpt.get('cfg', None)\n",
    "    if cfg and hasattr(cfg, 'model'):\n",
    "        model_cfg = cfg.model\n",
    "        print(f\"Encoder Dim: {model_cfg.encoder_embed_dim}\")\n",
    "        print(f\"Decoder Dim: {model_cfg.decoder_embed_dim}\")\n",
    "        print(f\"Encoder Layers: {model_cfg.encoder_layers}\")\n",
    "        print(f\"Decoder Layers: {model_cfg.decoder_layers}\")\n",
    "        print(f\"Attention Heads: {model_cfg.encoder_attention_heads}\")\n",
    "    \n",
    "    # 2. 딕셔너리 크기 (임베딩 레이어의 행 개수로 파악)\n",
    "    # state_dict 혹은 model 키에서 추출\n",
    "    state_dict = ckpt.get('model', ckpt.get('state_dict', {}))\n",
    "    embed_weight = state_dict.get('encoder.embed_tokens.weight', None)\n",
    "    \n",
    "    if embed_weight is not None:\n",
    "        vocab_size, embed_dim = embed_weight.shape\n",
    "        print(f\"Vocabulary Size (Dictionary): {vocab_size}\")\n",
    "        print(f\"Embedding Dim (Weight Matrix): {embed_dim}\")\n",
    "    else:\n",
    "        print(\"Could not find embedding weights in checkpoint.\")\n",
    "\n",
    "# 두 모델 경로 입력\n",
    "original_path = \"/home/2022113135/jjs/av2av/unit2unit/utut_finetune/unit_mbart.pt\"\n",
    "finetuned_path = \"/home/2022113135/jjs/av2av/unit2unit/utut_finetune/utut_ckpt/unit_mbart_multilingual_ft/en_ko/checkpoint_best.pt\"\n",
    "\n",
    "official_utut = \"/home/2022113135/jjs/av2av/ckpts/utut_sts_ft.pt\"\n",
    "\n",
    "inspect_checkpoint(original_path)\n",
    "inspect_checkpoint(finetuned_path)\n",
    "\n",
    "inspect_checkpoint(official_utut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612284a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jisu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
