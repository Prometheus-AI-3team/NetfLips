## Data Preparation for UTUT Fine-tuning


<aside>

### ğŸ—£ Workflow Summary

1. a2a Parallel audio (en/*.wav, ko/*.wav)
â†“ [AV2Unit]
2. Unit text files (units/en/*.txt, units/ko/*.txt)
â†“ [Concatenate]
3. Raw text files (train.en, train.ko, valid.en, valid.ko)
â†“ [fairseq-preprocess]
4. Binarized data (*.bin, *.idx)
â†“ [finetune_en_ko.py]
5. Fine-tuned model
</aside>
<hr>



### Step 1. ë³‘ë ¬ ì˜¤ë””ì˜¤ ë°ì´í„° ì¤€ë¹„

ì˜ì–´-í•œêµ­ì–´ 1:1 ëŒ€ì‘ë˜ëŠ” ì˜¤ë””ì˜¤ íŒŒì¼ ìŒì´ í•„ìš”.

```bash
audio/
â”œâ”€â”€ en/
â”‚   â”œâ”€â”€ sample_001.wav
â”‚   â”œâ”€â”€ sample_002.wav
â”‚   â””â”€â”€ ...
â””â”€â”€ ko/
    â”œâ”€â”€ sample_001.wav â†en/sample_001.wavì˜ í•œêµ­ì–´ ë²ˆì—­ ìŒì„±
    â”œâ”€â”€ sample_002.wav
    â””â”€â”€ ...
```

- íŒŒì¼ëª…ì€ ë°˜ë“œì‹œ **ì–¸ì–´ ê°„ ë™ì¼í•˜ê²Œ ìœ ì§€**ë˜ì–´ì•¼ í•¨.
- ê° `(en, ko)` ì˜¤ë””ì˜¤ ìŒì´ í•˜ë‚˜ì˜ ë²ˆì—­ ìƒ˜í”Œì„ êµ¬ì„±.
- ìš°ë¦¬ íŒ€ì€ í•œêµ­ì–´ wavì— ëŒ€ì‘ë˜ëŠ” ì˜ì–´ wavë¥¼ ë³´ì´ìŠ¤ í´ë¡œë‹ ttsë¡œ êµ¬ì¶• !

### Step 2. AV2Unitì„ ì´ìš©í•œ ì˜¤ë””ì˜¤ â†’ Discrete Unit ì¶”ì¶œ

ê° ì˜¤ë””ì˜¤ íŒŒì¼ì„ mavHuBERT ê¸°ë°˜ AV2Unit ëª¨ë¸ë¡œ ì²˜ë¦¬í•˜ì—¬

ì •ìˆ˜ ì‹œí€€ìŠ¤(unit sequence)ë¡œ ë³€í™˜

- ì˜ì–´ ì˜¤ë””ì˜¤ ì²˜ë¦¬
    
    ```bash
    PYTHONPATH=fairseq python av2unit/inference.py \
        --in-vid-path audio/en/sample_001.wav \
        --out-unit-path units/en/sample_001.txt \
        --ckpt-path modelckpt/mavhubert_large_noise.pt \
        --modalities audio
    ```
    
- í•œêµ­ì–´ ì˜¤ë””ì˜¤ ì²˜ë¦¬
    
    ```bash
    PYTHONPATH=fairseq python av2unit/inference.py \
        --in-vid-path audio/ko/sample_001.wav \
        --out-unit-path units/ko/sample_001.txt \
        --ckpt-path modelckpt/mavhubert_large_noise.pt \
        --modalities audio
    ```
    
- ìƒì„± ê²°ê³¼ ì˜ˆì‹œ
    
    ```bash
    #units/en/sample_001.txt
    45 78 123 456 789 234 567 890 12 34 56 78
    
    #units/ko/sample_001.txt
    23 89 156 234 567 890 123 456 78 90 12
    ```
    
    - ê° ìˆ«ìëŠ” **quantized speech unit token**
    - í…ìŠ¤íŠ¸ ë²ˆì—­ì´ ì•„ë‹ˆë¼ **unit-to-unit translation** ë¬¸ì œë¡œ ë³€í™˜ë¨.
    - ìš°ë¦¬ëŠ” ê°€ì—° mavhubert_units ì¶”ì¶œ ì½”ë“œë¡œ ìë™í™”
        
### Step 3. Fairseqìš© Raw Text ë°ì´í„° êµ¬ì„±

Fairseq ì „ì²˜ë¦¬ë¥¼ ìœ„í•´, ê°œë³„ unit íŒŒì¼ë“¤ì„ **í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ë³‘í•©** (í•œ ì¤„ = í•˜ë‚˜ì˜ ìƒ˜í”Œ)

1. ë””ë ‰í† ë¦¬ ìƒì„±

    ```bash
    mkdir -p unit2unit/utut_finetune/raw_data
    ```

2. train.en ìƒì„± (ì˜ì–´ unit ì‹œí€€ìŠ¤) 

    ```bash
    for f in units/en/train_*.txt; do
        cat "$f"
        echo ""
    done > raw_data/train.en
    ```

    1. train.ko ìƒì„± (í•œêµ­ì–´ unit ì‹œí€€ìŠ¤)

    ```bash
    for f in units/ko/train_*.txt; do
        cat "$f"
        echo ""
    done > raw_data/train.ko
    ```

    ```bash
    # ì‹¤ì œë¡œ ì„œë²„ì—ì„œ ì‹¤í–‰ì‹œí‚¨ í„°ë¯¸ë„ ëª…ë ¹ì–´
    for f in /home/2022113135/datasets/final_unit2a_split/train/*.pt; do
        cat "$f"
        echo ""
    done > raw_data/train.ko
    ```

- `valid.en / valid.ko`, `test.en / test.ko`ë„ ë™ì¼ ë°©ì‹ìœ¼ë¡œ ìƒì„±

- ê²°ê³¼ íŒŒì¼ í˜•ì‹ ì˜ˆì‹œ

        ```bash
        # train.en
        45 78 123 456 789 234 567
        12 34 56 78 90 123 456 789
        ...

        # train.ko
        23 89 156 234 567 890
        78 90 12 34 56 78 90
        ...
        ```

âš ï¸ **ì¤‘ìš”**

- `train.en`ì˜ Në²ˆì§¸ ì¤„ â†” `train.ko`ì˜ Në²ˆì§¸ ì¤„ì€ **ë°˜ë“œì‹œ ë³‘ë ¬ ìŒ**
- ìˆœì„œê°€ ì–´ê¸‹ë‚˜ë©´ í•™ìŠµì´ ì˜ë¯¸ë¥¼ ìƒìŒ

---

### Step 4. fairseq-preprocess (Binarization)

Raw text ë°ì´í„°ë¥¼ **fairseq ë‚´ë¶€ì—ì„œ ì‚¬ìš©í•˜ëŠ” binary format**ìœ¼ë¡œ ë³€í™˜. 

    ```bash
    fairseq-preprocess \
    --source-lang en \
    --target-lang ko \
    --trainpref raw_data/train \
    --validpref raw_data/valid \
    --testpref raw_data/test \
    --destdir ./data/dataset_mbart_ft_bin_data/en/ko \
    --srcdict unit2unit/utut_pretrain/dataset/dict.txt \
    --tgtdict unit2unit/utut_pretrain/dataset/dict.txt \
    --workers 4
    ```


- (cf) dictëŠ” ì‚¬ì „í•™ìŠµ(pretraining) ë‹¨ê³„ì—ì„œ ì´ë¯¸ ë§Œë“¤ì–´ì§„ ê²ƒ(â†’utut_pretrain/dataset/dict) ì„ ì¬ì‚¬ìš©
- UTUT (unit-to-unit) **pretraining ë°ì´í„°ì…‹ì—ì„œ ìƒì„±ëœ vocabulary**
- mavHuBERT unit spaceì™€ **ì •í•©ëœ dict** (ì‚¬ì „í•™ìŠµ ëª¨ë¸ì˜ embedding í¬ê¸°ì™€ ì¼ì¹˜)
    - source / targetì´ ë™ì¼í•œ unit spaceì´ë¯€ë¡œ `srcdict == tgtdict` ê°€ ê°œë…ì ìœ¼ë¡œ ì¼ì¹˜
    
- ìƒì„±ë˜ëŠ” íŒŒì¼ë“¤

    ```
    data/dataset_mbart_ft_bin_data/en/ko/
    â”œâ”€â”€ dict.en.txt
    â”œâ”€â”€ dict.ko.txt
    â”œâ”€â”€ train.en-ko.en.bin
    â”œâ”€â”€ train.en-ko.en.idx
    â”œâ”€â”€ train.en-ko.ko.bin
    â”œâ”€â”€ train.en-ko.ko.idx
    â”œâ”€â”€ valid.en-ko.en.bin
    â”œâ”€â”€ valid.en-ko.en.idx
    â”œâ”€â”€ valid.en-ko.ko.bin
    â”œâ”€â”€ valid.en-ko.ko.idx
    â”œâ”€â”€ test.en-ko.en.bin
    â”œâ”€â”€ test.en-ko.en.idx
    â”œâ”€â”€ test.en-ko.ko.bin
    â””â”€â”€ test.en-ko.ko.idx
    ```

- (cf) TSV ManifestëŠ” ë‹¤ë¥¸ íƒœìŠ¤í¬ìš© ë°ì´í„° í¬ë§·
    
    
    | Configì˜ task ì„¤ì •ì— ë”°ë¼â€¦ | ìš”êµ¬ë˜ëŠ” ë°ì´í„° í¬ë§· |
    | --- | --- |
    | `translation_from_pretrained_bart` | **Binarized (.bin / .idx)** |
    | `utut_pretraining` | TSV manifest + raw unit files |
    
    av2av ì €ìë¶„ê»˜ ì „ë‹¬ë°›ì€ ìŠ¤í¬ë¦½íŠ¸ ê¸°ë°˜ì—ì„œëŠ” `translation_from_pretrained_bart` taskë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ **TSV í•„ìš” ì—†ë‹¤**.
    

---

## Finally run UTUT Fine-tuning

**To execute fine-tuning:**

```bash
cd /Users/jisu/Desktop/dev/cli/av2av/unit2unit/utut_finetune

CUDA_VISIBLE_DEVICES=0 PYTHONPATH=path/to/fairseq OMP_NUM_THREADS=1 python finetune_en_ko.py data/dataset_mbart_ft_bin_data/en/aihub_ko \
    --arch mbart_large \
    --task translation_from_pretrained_bart \
    --criterion focal_label_smoothed_cross_entropy \
    --user-dir ./

```